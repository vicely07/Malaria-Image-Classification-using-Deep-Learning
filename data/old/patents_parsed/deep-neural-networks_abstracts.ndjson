["A method for training a neural network includes receiving labeled training data at a master node, generating, by the master node, partitioned training data from the labeled training data and a held-out set of the labeled training data, determining a plurality of gradients for the partitioned training data, wherein the determination of the gradients is distributed across a plurality of worker nodes, determining a plurality of curvature matrix-vector products over the plurality of samples of the partitioned training data, wherein the determination of the plurality of curvature matrix-vector products is distributed across the plurality of worker nodes, and determining, by the master node, a second-order optimization of the plurality of gradients and the plurality of curvature matrix-vector products, producing a trained neural network configured to perform a structured classification task using a sequence-discriminative criterion.", "Training Deep Neural Network Acoustic Models Using Distributed Hessian-Free Optimization "]
[null, "Real-time face recognition method based on deep neural network "]
[null, "Method and device for data identification based on multitask deep neural network "]
["A neural network is trained using a training neural network having the same topology as the original network but having a differential network output and accepting also differential network inputs. This new training method enables deeper neural networks to be successfully trained by avoiding a problem occuring in conventional training methods in which errors vanish as they are propagated in the reverse direction through deep networks. An acceleration in convergence rate is achieved by adjusting the error used in training to compensate for the linkage between multiple training data points.", "Training a neural network using differential input "]
[null, "Non-restricted environment face verification method based on block depth neural network "]
["Systems and methods for sequence transcription with neural networks are provided. More particularly, a neural network can be implemented to map a plurality of training images received by the neural network into a probabilistic model of sequences comprising P(S|X) by maximizing log P(S|X) on the plurality of training images. X represents an input image and S represents an output sequence of characters for the input image. The trained neural network can process a received image containing characters associated with building numbers. The trained neural network can generate a predicted sequence of characters by processing the received image.", "Sequence transcription with deep neural networks "]
["A method and system for labeling a selected word of a sentence using a deep neural network includes, in one exemplary embodiment, determining an index term corresponding to each feature of the word, transforming the index term or terms of the word into a vector, and predicting a label for the word using the vector. The method and system, in another exemplary embodiment, includes determining, for each word in the sentence, an index term corresponding to each feature of the word, transforming the index term or terms of each word in the sentence into a vector, applying a convolution operation to the vector of the selected word and at least one of the vectors of the other words in the sentence, to transform the vectors into a matrix of vectors, each of the vectors in the matrix including a plurality of row values, constructing a single vector from the vectors in the matrix, and predicting a label for the selected word using the single vector.", "Deep Neural Networks and Methods for Using Same "]
["Described herein are various technologies pertaining to a multilingual deep neural network (MDNN). The MDNN includes a plurality of hidden layers, wherein values for weight parameters of the plurality of hidden layers are learned during a training phase based upon training data in terms of acoustic raw features for multiple languages. The MDNN further includes softmax layers that are trained for each target language separately, making use of the hidden layer values trained jointly with multiple source languages. The MDNN is adaptable, such that a new softmax layer may be added on top of the existing hidden layers, where the new softmax layer corresponds to a new target language.", "Multilingual deep neural network "]
["In a speech recognition system, deep neural networks (DNNs) are employed in phoneme recognition. While DNNs typically provide better phoneme recognition performance than other techniques, such as Gaussian mixture models (GMM), adapting a DNN to a particular speaker is a real challenge. According to at least one example embodiment, speech data and corresponding speaker data are both applied as input to a DNN. In response, the DNN generates a prediction of a phoneme based on the input speech data and the corresponding speaker data. The speaker data may be generated from the corresponding speech data.", "Method and Apparatus for Speech Recognition Using Neural Networks with Speaker Adaptation "]
["Systems and methods for training networks are provided. A method for training networks comprises receiving an input from each of a plurality of neural networks differing from each other in at least one of architecture, input modality, and feature type, connecting the plurality of neural networks through a common output layer, or through one or more common hidden layers and a common output layer to result in a joint network, and training the joint network.", "Method and system for joint training of hybrid neural networks for acoustic modeling in automatic speech recognition "]
["A method and system for is disclosed for speech synthesis using deep neural networks. A neural network may be trained to map input phonetic transcriptions of training-time text strings into sequences of acoustic feature vectors, which yield predefined speech waveforms when processed by a signal generation module. The training-time text strings may correspond to written transcriptions of speech carried in the predefined speech waveforms. Subsequent to training, a run-time text string may be translated to a run-time phonetic transcription, which may include a run-time sequence of phonetic-context descriptors, each of which contains a phonetic speech unit, data indicating phonetic context, and data indicating time duration of the respective phonetic speech unit. The trained neural network may then map the run-time sequence of the phonetic-context descriptors to run-time predicted feature vectors, which may in turn be translated into synthesized speech by the signal generation module.", "Speech synthesis using deep neural networks "]
["Deep Neural Network (DNN) training technique embodiments are presented that train a DNN while exploiting the sparseness of non-zero hidden layer interconnection weight values. Generally, a fully connected DNN is initially trained by sweeping through a full training set a number of times. Then, for the most part, only the interconnections whose weight magnitudes exceed a minimum weight threshold are considered in further training. This minimum weight threshold can be established as a value that results in only a prescribed maximum number of interconnections being considered when setting interconnection weight values via an error back-propagation procedure during the training. It is noted that the continued DNN training tends to converge much faster than the initial training.", "Exploiting sparseness in training deep neural networks "]
["The adaptation and personalization of a deep neural network (DNN) model for automatic speech recognition is provided. An utterance which includes speech features for one or more speakers may be received in ASR tasks such as voice search or short message dictation. A decomposition approach may then be applied to an original matrix in the DNN model. In response to applying the decomposition approach, the original matrix may be converted into multiple new matrices which are smaller than the original matrix. A square matrix may then be added to the new matrices. Speaker-specific parameters may then be stored in the square matrix. The DNN model may then be adapted by updating the square matrix. This process may be applied to all of a number of original matrices in the DNN model. The adapted DNN model may include a reduced number of parameters than those received in the original DNN model.", "Low-footprint adaptation and personalization for a deep neural network "]
["Deep convolutional neural networks receive local and global representations of images as inputs and learn the best representation for a particular feature through multiple convolutional and fully connected layers. A double-column neural network structure receives each of the local and global representations as two heterogeneous parallel inputs to the two columns. After some layers of transformations, the two columns are merged to form the final classifier. Additionally, features may be learned in one of the fully connected layers. The features of the images may be leveraged to boost classification accuracy of other features by learning a regularized double-column neural network.", "Image assessment using deep convolutional neural networks "]
["Discriminative pretraining technique embodiments are presented that pretrain the hidden layers of a Deep Neural Network (DNN). In general, a one-hidden-layer neural network is trained first using labels discriminatively with error back-propagation (BP). Then, after discarding an output layer in the previous one-hidden-layer neural network, another randomly initialized hidden layer is added on top of the previously trained hidden layer along with a new output layer that represents the targets for classification or recognition. The resulting multiple-hidden-layer DNN is then discriminatively trained using the same strategy, and so on until the desired number of hidden layers is reached. This produces a pretrained DNN. The discriminative pretraining technique embodiments have the advantage of bringing the DNN layer weights close to a good local optimum, while still leaving them in a range with a high gradient so that they can be fine-tuned effectively.", "Discriminative pretraining of deep neural networks "]
["A Deep Neural Network (DNN) model used in an Automatic Speech Recognition (ASR) system is restructured. A restructured DNN model may include fewer parameters compared to the original DNN model. The restructured DNN model may include a monophone state output layer in addition to the senone output layer of the original DNN model. Singular value decomposition (SVD) can be applied to one or more weight matrices of the DNN model to reduce the size of the DNN Model. The output layer of the DNN model may be restructured to include monophone states in addition to the senones (tied triphone states) which are included in the original DNN model. When the monophone states are included in the restructured DNN model, the posteriors of monophone states are used to select a small part of senones to be evaluated.", "Restructuring deep neural network acoustic models "]
["The use of a pipelined algorithm that performs parallelized computations to train deep neural networks (DNNs) for performing data analysis may reduce training time. The DNNs may be one of context-independent DNNs or context-dependent DNNs. The training may include partitioning training data into sample batches of a specific batch size. The partitioning may be performed based on rates of data transfers between processors that execute the pipelined algorithm, considerations of accuracy and convergence, and the execution speed of each processor. Other techniques for training may include grouping layers of the DNNs for processing on a single processor, distributing a layer of the DNNs to multiple processors for processing, or modifying an execution order of steps in the pipelined algorithm.", "Deep neural networks training for speech and pattern recognition "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for detecting objects in images. One of the methods includes receiving an input image. A full object mask is generated by providing the input image to a first deep neural network object detector that produces a full object mask for an object of a particular object type depicted in the input image. A partial object mask is generated by providing the input image to a second deep neural network object detector that produces a partial object mask for a portion of the object of the particular object type depicted in the input image. A bounding box is determined for the object in the image using the full object mask and the partial object mask.", "Object detection using deep neural networks "]
["A method and system for anatomical object detection using marginal space deep neural networks is disclosed. The pose parameter space for an anatomical object is divided into a series of marginal search spaces with increasing dimensionality. A respective deep neural network is trained for each of the marginal search spaces, resulting in a series of trained deep neural networks. Each of the trained deep neural networks can evaluate hypotheses in a current parameter space using discriminative classification or a regression function. An anatomical object is detected in a medical image by sequentially applying the series of trained deep neural networks to the medical image.", "Method and system for anatomical object detection using marginal space deep neural networks "]
["Various technologies described herein pertain to conservatively adapting a deep neural network (DNN) in a recognition system for a particular user or context. A DNN is employed to output a probability distribution over models of context-dependent units responsive to receipt of captured user input. The DNN is adapted for a particular user based upon the captured user input, wherein the adaption is undertaken conservatively such that a deviation between outputs of the adapted DNN and the unadapted DNN is constrained.", "Conservatively adapting a deep neural network in a recognition system "]
[null, "Polarization SAR image classification method based on deep neural network "]
["Technologies pertaining to training a deep neural network (DNN) for use in a recognition system are described herein. The DNN is trained using heterogeneous data, the heterogeneous data including narrowband signals and wideband signals. The DNN, subsequent to being trained, receives an input signal that can be either a wideband signal or narrowband signal. The DNN estimates the class posterior probability of the input signal regardless of whether the input signal is the wideband signal or the narrowband signal.", "Exploiting heterogeneous data in deep neural network-based speech recognition systems "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a deep neural network. One of the methods includes training a deep neural network with a first training set by adjusting values for each of a plurality of weights included in the neural network, and training the deep neural network to determine a probability that data received by the deep neural network has features similar to key features of one or more keywords or key phrases, the training comprising providing the deep neural network with a second training set and adjusting the values for a first subset of the plurality of weights, wherein the second training set includes data representing the key features of the one or more keywords or key phrases.", "Transfer learning for deep neural network based hotword detection "]
["Training large neural network models by providing training input to model training machines organized as multiple replicas that asynchronously update a shared model via a global parameter server is described herein. In at least one embodiment, a system including a model module storing a portion of a model and a deep learning training module that communicates with the model module are configured for asynchronously sending updates to shared parameters associated with the model. The techniques herein describe receiving and processing a batch of data items to calculate updates. Replicas of training machines communicate asynchronously with a global parameter server to provide updates to a shared model and return updated weight values. The model may be modified to reflect the updated weight values. The techniques described herein include computation and communication optimizations that improve system efficiency and scaling of large neural networks.", "Deep Learning Training System "]
["Systems and methods are disclosed to recognize human action from one or more video frames by performing 3D convolutions to capture motion information encoded in multiple adjacent frames and extracting features from spatial and temporal dimensions therefrom; generating multiple channels of information from the video frames, combining information from all channels to obtain a feature representation for a 3D CNN model; and applying the 3D CNN model to recognize human actions.", "3d convolutional neural networks for automatic human action recognition "]
["A tensor deep stacked neural (T-DSN) network for obtaining predictions for discriminative modeling problems. The T-DSN network and method use bilinear modeling with a tensor representation to map a hidden layer to the predication layer. The T-DSN network is constructed by stacking blocks of a single hidden layer tensor neural network (SHLTNN) on top of each other. The single hidden layer for each block then is separated or divided into a plurality of two or more sections. In some embodiments, the hidden layer is separated into a first hidden layer section and a second hidden layer section. These multiple sections of the hidden layer are combined using a product operator to obtain an implicit hidden layer having a single section. In some embodiments the product operator is a Khatri-Rao product. A prediction is made using the implicit hidden layer and weights, and the output prediction layer is consequently obtained.", "Tensor deep stacked neural network "]
[null, "Deep learning-based clustering method "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for identifying the language of a spoken utterance. One of the methods includes receiving input features of an utterance; and processing the input features using an acoustic model that comprises one or more convolutional neural network (CNN) layers, one or more long short-term memory network (LSTM) layers, and one or more fully connected neural network layers to generate a transcription for the utterance.", "Convolutional, long short-term memory, fully connected deep neural networks "]
["A method and system for anatomical object detection using marginal space deep neural networks is disclosed. The pose parameter space for an anatomical object is divided into a series of marginal search spaces with increasing dimensionality. A respective sparse deep neural network is trained for each of the marginal search spaces, resulting in a series of trained sparse deep neural networks. Each of the trained sparse deep neural networks is trained by injecting sparsity into a deep neural network by removing filter weights of the deep neural network.", "Method and System for Anatomical Object Detection Using Marginal Space Deep Neural Networks "]
[null, "Rapid target detection method based on convolutional neural network "]
["One or more aspects of the subject disclosure are directed towards performing a semantic parsing task, such as classifying text corresponding to a spoken utterance into a class. Feature data representative of input data is provided to a semantic parsing mechanism that uses a deep model trained at least in part via unsupervised learning using unlabeled data. For example, if used in a classification task, a classifier may use an associated deep neural network that is trained to have an embeddings layer corresponding to at least one of words, phrases, or sentences. The layers are learned from unlabeled data, such as query click log data.", "Deep learning for semantic parsing including semantic utterance classification "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a deep neural network. One of the methods includes generating a plurality of feature vectors that each model a different portion of an audio waveform, generating a first posterior probability vector for a first feature vector using a first neural network, determining whether one of the scores in the first posterior probability vector satisfies a first threshold value, generating a second posterior probability vector for each subsequent feature vector using a second neural network, wherein the second neural network is trained to identify the same key words and key phrases and includes more inner layer nodes than the first neural network, and determining whether one of the scores in the second posterior probability vector satisfies a second threshold value.", "Training multiple neural networks with different accuracy "]
["A method of adaptively selecting a configuration for a machine learning process includes determining current system resources and performance specifications of a current system. A new configuration for the machine learning process is determined based at least in part on the current system resources and the performance specifications. The method also includes dynamically selecting between a current configuration and the new configuration based at least in part on the current system resources and the performance specifications.", "Adaptive selection of artificial neural networks "]
["A method and system for approximating a deep neural network for anatomical object detection is discloses. A deep neural network is trained to detect an anatomical object in medical images. An approximation of the trained deep neural network is calculated that reduces the computational complexity of the trained deep neural network. The anatomical object is detected in an input medical image of a patient using the approximation of the trained deep neural network.", "Method and System for Approximating Deep Neural Networks for Anatomical Object Detection "]
["A deep tensor neural network (DTNN) is described herein, wherein the DTNN is suitable for employment in a computer-implemented recognition/classification system. Hidden layers in the DTNN comprise at least one projection layer, which includes a first subspace of hidden units and a second subspace of hidden units. The first subspace of hidden units receives a first nonlinear projection of input data to a projection layer and generates the first set of output data based at least in part thereon, and the second subspace of hidden units receives a second nonlinear projection of the input data to the projection layer and generates the second set of output data based at least in part thereon. A tensor layer, which can converted into a conventional layer of a DNN, generates the third set of output data based upon the first set of output data and the second set of output data.", "Computer-implemented deep tensor neural network "]
["A learning computer system may include a data processing system and a hardware processor and may estimate parameters and states of a stochastic or uncertain system. The system may receive data from a user or other source; process the received data through layers of processing units, thereby generating processed data; apply masks or filters to the processed data using convolutional processing; process the masked or filtered data to produce one or more intermediate and output signals; compare the output signals with reference signals to generate error signals; send and process the error signals back through the layers of processing units; generate random, chaotic, fuzzy, or other numerical perturbations of the received data, the processed data, or the output signals; estimate the parameters and states of the stochastic or uncertain system using the received data, the numerical perturbations, and previous parameters and states of the stochastic or uncertain system; determine whether the generated numerical perturbations satisfy a condition; and, if the numerical perturbations satisfy the condition, inject the numerical perturbations into the estimated parameters or states, the received data, the processed data, the masked or filtered data, or the processing units.", "Noise-enhanced convolutional neural networks "]
[null, "Face recognition method of deep convolutional neural network "]
[null, "Method for fusing full-color image and multispectral image based on deep neural network "]
["Embodiments of a computer-implemented method for training a convolutional neural network (CNN) that is pre-trained using a set of color images are disclosed. The method comprises receiving a training dataset including multiple multidimensional images, each multidimensional image including a color image and a depth image; performing a fine-tuning of the pre-trained CNN using the depth image for each of the plurality of multidimensional images; obtaining a depth CNN based on the pre-trained CNN, wherein the depth CNN is associated with a first set of parameters; replicating the depth CNN to obtain a duplicate depth CNN being initialized with the first set of parameters; and obtaining a depth-enhanced color CNN based on the duplicate depth CNN being fine-tuned using the color image for each of the plurality of multidimensional images, wherein the depth-enhanced color CNN is associated with a second set of parameters.", "Cross-trained convolutional neural networks using multimodal images "]
["According to an example, a digital image may be processed by an ensemble of convolutional neural networks (CNNs) to classify objects in the digital image. For each CNN, a candidate architecture and candidate parameters may be selected to build a plurality of CNNs. Once it is determined that a predetermined number of CNNs, each having different values for the selected candidate parameters, meet a validation threshold, an ensemble of CNNs may be generated from the predetermined number of CNNs. The predictions from the ensemble of CNNs may then be aggregated to accurately classify the objects in the digital image.", "Digital image processing using convolutional neural networks "]
["Technologies pertaining to slot filling are described herein. A deep neural network, a recurrent neural network, and/or a spatio-temporally deep neural network are configured to assign labels to words in a word sequence set forth in natural language. At least one label is a semantic label that is assigned to at least one word in the word sequence.", "Assignment of semantic labels to a sequence of words using neural network architectures "]
["A method of address translation of images and filters to virtual matrices to perform a convolution by matrix multiplication includes receiving an image and a filter. Each image and filter has a memory address. The method also includes mapping the memory addresses to virtual matrix addresses based on a calculated linearized image and a calculated linearized filter. The method further includes converting data in the virtual matrix to a predefined internal format. The method still further includes convolving the image by matrix multiplication of the data in the predefined internal format based on the virtual matrix addresses.", "Convolution matrix multiply with callback for deep tiling for deep convolutional neural networks "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network to detect object in images. One of the methods includes receiving a training image and object location data for the training image; providing the training image to a neural network and obtaining bounding box data for the training image from the neural network, wherein the bounding box data comprises data defining a plurality of candidate bounding boxes in the training image and a respective confidence score for each candidate bounding box in the training image; determining an optimal set of assignments using the object location data for the training image and the bounding box data for the training image, wherein the optimal set of assignments assigns a respective candidate bounding box to each of the object locations; and training the neural network on the training image using the optimal set of assignments.", "Training a neural network to detect objects in images "]
["An \u201cInterestingness Modeler\u201d uses deep neural networks to learn deep semantic models (DSM) of \u201cinterestingness.\u201d The DSM, consisting of two branches of deep neural networks or their convolutional versions, identifies and predicts target documents that would interest users reading source documents. The learned model observes, identifies, and detects naturally occurring signals of interestingness in click transitions between source and target documents derived from web browser logs. Interestingness is modeled with deep neural networks that map source-target document pairs to feature vectors in a latent space, trained on document transitions in view of a \u201ccontext\u201d and optional \u201cfocus\u201d of source and target documents. Network parameters are learned to minimize distances between source documents and their corresponding \u201cinteresting\u201d targets in that space. The resulting interestingness model has applicable uses, including, but not limited to, contextual entity searches, automatic text highlighting, prefetching documents of likely interest, automated content recommendation, automated advertisement placement, etc.", "Modeling interestingness with deep neural networks "]
["A system and method for applying a convolutional neural network (CNN) to speech recognition. The CNN may provide input to a hidden Markov model and has at least one pair of a convolution layer and a pooling layer. The CNN operates along the frequency axis. The CNN has units that operate upon one or more local frequency bands of an acoustic signal. The CNN mitigates acoustic variation.", "System and method for applying a convolutional neural network to speech recognition "]
["By way of example, the technology disclosed by this document receives image data; extracts a depth image and a color image from the image data; creates a mask image by segmenting the depth image; determines a first likelihood score from the depth image and the mask image using a layered classifier; determines a second likelihood score from the color image and the mask image using a deep convolutional neural network; and determines a class of at least a portion of the image data based on the first likelihood score and the second likelihood score. Further, the technology can pre-filter the mask image using the layered classifier and then use the pre-filtered mask image and the color image to calculate a second likelihood score using the deep convolutional neural network to speed up processing.", "Augmenting Layer-Based Object Detection With Deep Convolutional Neural Networks "]
["A method includes providing a deep neural network acoustic model, receiving audio data including one or more utterances of a speaker, extracting a plurality of speech recognition features from the one or more utterances of the speaker, creating a speaker identity vector for the speaker based on the extracted speech recognition features, and adapting the deep neural network acoustic model for automatic speech recognition using the extracted speech recognition features and the speaker identity vector.", "Speaker Adaptation of Neural Network Acoustic Models Using I-Vectors "]
[null, "Cascaded depth neural network-based face attribute recognition method "]
["A method and system for frame-level merging of HMM state predictions determined by different techniques is disclosed. An audio input signal may be transformed into a first and second sequence of feature vector, the sequences corresponding to each other and to a temporal sequence of frames of the audio input signal on a frame-by-frame basis. The first sequence may be processed by a neural network (NN) to determine NN-based state predictions, and the second sequence may be processed by a Gaussian mixture model (GMM) to determine GMM-based state predictions. The NN-based and GMM-based state predictions may be merged as weighted sums for each of a plurality of HMM state on a frame-by-frame basis to determine merged state predictions. The merged state predictions may then be applied to the HMMs to speech content of the audio input signal.", "Frame-level combination of deep neural network and gaussian mixture models "]
["Embodiments are directed towards classifying data using machine learning that may be incrementally refined based on expert input. Data provided to a deep learning model that may be trained based on a plurality of classifiers and sets of training data and/or testing data. If the number of classification errors exceeds a defined threshold classifiers may be modified based on data corresponding to observed classification errors. A fast learning model may be trained based on the modified classifiers, the data, and the data corresponding to the observed classification errors. And, another confidence value may be generated and associated with the classification of the data by the fast learning model. Report information may be generated based on a comparison result of the confidence value associated with the fast learning model and the confidence value associated with the deep learning model.", "Classifying data with deep learning neural records incrementally refined through expert input "]
[null, "Training system of back propagation neural network DNN (Deep Neural Network) "]
[null, "Tattoo image classification method based on deep learning "]
["Disclosed herein are devices, systems, and methods for detecting the presence and orientation of traffic lane markings. Deep convolutional neural networks are used with convolutional layers and max-pooling layers to generate fully connected nodes. After the convolutional and max-pooling layers, two sublayers are applied, one to determine presence and one to determine geometry. The presence of a lane marking segment as detected by the first sublayer can serve as a gate for the second sublayer by regulating the credit assignment for training the network. Only when the first sublayer predicts actual presence will the geometric layout of the lane marking segment contribute to the training of the overall network. This achieves advantages with respect to accuracy and efficiency and contributes to efficient robust model selection.", "Multi-task deep convolutional neural networks for efficient and robust traffic lane detection "]
["Deep recurrent neural networks applied to speech recognition. The deep recurrent neural networks (RNNs) are preferably implemented by stacked long short-term memory bidirectional RNNs. The RNNs are trained using end-to-end training with suitable regularization.", "System and method for speech recognition using deep recurrent neural networks "]
["The present embodiments relate to machine learning for multimodal image data. By way of introduction, the present embodiments described below include apparatuses and methods for learning a similarity metric using deep learning based techniques for multimodal medical images. A novel similarity metric for multi-modal images is provided using the corresponding states of pairs of image patches to generate a classification setting for each pair. The classification settings are used to train a deep neural network via supervised learning. A multi-modal stacked denoising auto encoder (SDAE) is used to pre-train the neural network. A continuous and smooth similarity metric is constructed based on the output of the neural network before activation in the last layer. The trained similarity metric may be used to improve the results of image fusion.", "Deep similarity learning for multimodal medical images "]
[null, "Image recognition method using deep learning analysis modular systems "]
["Technology is disclosed for inferring human attributes from images of people. The attributes can include, for example, gender, age, hair, and/or clothing. The technology uses part-based models, e.g., Poselets, to locate multiple normalized part patches from an image. The normalized part patches are provided into trained convolutional neural networks to generate feature data. Each convolution neural network applies multiple stages of convolution operations to one part patch to generate a set of fully connected feature data. The feature data for all part patches are concatenated and then provided into multiple trained classifiers (e.g., linear support vector machines) to predict attributes of the image.", "Pose-aligned networks for deep attribute modeling "]
["Techniques for learning front-end speech recognition parameters as part of training a neural network classifier include obtaining an input speech signal, and applying front-end speech recognition parameters to extract features from the input speech signal. The extracted features may be fed through a neural network to obtain an output classification for the input speech signal, and an error measure may be computed for the output classification through comparison of the output classification with a known target classification. Back propagation may be applied to adjust one or more of the front-end parameters as one or more layers of the neural network, based on the error measure.", "Learning front-end speech recognition parameters within neural network training "]
["Systems and methods are disclosed for detecting an object in an image by determining convolutional neural network responses on the image; mapping the responses back to their spatial locations in the image; and constructing features densely extract shift invariant activations of a convolutional neural network to produce dense features for the image.", "Regionlets with Shift Invariant Neural Patterns for Object Detection "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for image processing using deep neural networks. One of the methods includes receiving data characterizing an input image; processing the data characterizing the input image using a deep neural network to generate an alternative representation of the input image, wherein the deep neural network comprises a plurality of subnetworks, wherein the subnetworks are arranged in a sequence from lowest to highest, and wherein processing the data characterizing the input image using the deep neural network comprises processing the data through each of the subnetworks in the sequence; and processing the alternative representation of the input image through an output layer to generate an output from the input image.", "Processing images using deep neural networks "]
["Object detection remains a fundamental problem and bottleneck to be addressed for making vision algorithms practical. Despite the promise, deep learning methods have not been extensively investigated on object detection problems. In this disclosure, deep learning approaches are developed for object detection problems. Specifically, learning algorithms are developed that learn hierarchical features (e.g., object parts) that can provide useful discriminative information for object detection tasks. In addition, algorithms are developed to improve invariance and discriminative power of the learned features.", "Deep learning framework for generic object detection "]
[null, "Short-term wind speed multi-step prediction method based on deep learning method "]
["A method and system for determining fractional flow reserve (FFR) for a coronary artery stenosis of a patient is disclosed. In one embodiment, medical image data of the patient including the stenosis is received, a set of features for the stenosis is extracted from the medical image data of the patient, and an FFR value for the stenosis is determined based on the extracted set of features using a trained machine-learning based mapping. In another embodiment, a medical image of the patient including the stenosis of interest is received, image patches corresponding to the stenosis of interest and a coronary tree of the patient are detected, an FFR value for the stenosis of interest is determined using a trained deep neural network regressor applied directly to the detected image patches.", "Method and System for Machine Learning Based Assessment of Fractional Flow Reserve "]
[null, "Multi-camera system target matching method based on deep-convolution neural network "]
["We describe a method of reinforcement learning for a subject system having multiple states and actions to move from one state to the next. Training data is generated by operating on the system with a succession of actions and used to train a second neural network. Target values for training the second neural network are derived from a first neural network which is generated by copying weights of the second neural network at intervals.", "Methods and apparatus for reinforcement learning "]
[null, "Fault diagnosis method for rolling bearing based on deep learning and SVM (Support Vector Machine) "]
["A method for training a deep neural network, comprises receiving and formatting speech data for the training, preconditioning a system of equations to be used for analyzing the speech data in connection with the training by using a non-fixed point quasi-Newton preconditioning scheme, and employing flexible Krylov subspace solvers in response to variations in the preconditioning scheme for different iterations of the training.", "Systems and methods for accelerating hessian-free optimization for deep neural networks by implicit preconditioning and sampling "]
[null, "Valueless image removing method based on deep convolutional neural networks "]
["Methods and systems for processing multilingual DNN acoustic models are described. An example method may include receiving training data that includes a respective training data set for each of two or more or languages. A multilingual deep neural network (DNN) acoustic model may be processed based on the training data. The multilingual DNN acoustic model may include a feedforward neural network having multiple layers of one or more nodes. Each node of a given layer may connect with a respective weight to each node of a subsequent layer, and the multiple layers of one or more nodes may include one or more shared hidden layers of nodes and a language-specific output layer of nodes corresponding to each of the two or more languages. Additionally, weights associated with the multiple layers of one or more nodes of the processed multilingual DNN acoustic model may be stored in a database.", "Multilingual, acoustic deep neural networks "]
[null, "Traffic flow prediction method based on deep learning nerve network structure "]
["Speech recognition techniques are employed in a variety of applications and services serving large numbers of users. As such, there is an increasing demand for speech recognition systems with enhanced performance. Specifically, enhanced performance in large vocabulary continuous speech recognition (LVCSR) systems is a market demand. Herein, convolutional neural networks are explored as an alternative speech recognition approach and different CNN architectures are tested. According to at least one example embodiment, a method and corresponding apparatus for performing speech recognition comprise employing a CNN with at least two convolutional layers and at least two fully-connected layers in speech recognition. Using the CNN a textual representation of input audio data may be provided based on output data by the CNN.", "Method and Apparatus for Using Convolutional Neural Networks in Speech Recognition "]
[null, "Vehicle license plate recognition method based on deep neural network "]
["Systems and methods are provided for automatically scoring a constructed response. The constructed response is processed to generate a plurality of numerical vectors that is representative of the constructed response. A model is applied to the plurality of numerical vectors. The model includes an input layer configured to receive the plurality of numerical vectors, the input layer being connected to a following layer of the model via a first plurality of connections. Each of the connections has a first weight. An intermediate layer of nodes is configured to receive inputs from an immediately-preceding layer of the model via a second plurality of connections, each of the connections having a second weight. An output layer is connected to the intermediate layer via a third plurality of connections, each of the connections having a third weight. The output layer is configured to generate a score for the constructed response.", "Deep Convolutional Neural Networks for Automated Scoring of Constructed Responses "]
[null, "Deep-neural-network-based acoustic model training method, hosts and system "]
["A learning computer system may update parameters and states of an uncertain system. The system may receive data from a user or other source; process the received data through layers of processing units, thereby generating processed data; process the processed data to produce one or more intermediate or output signals; compare the one or more intermediate or output signals with one or more reference signals to generate information indicative of a performance measure of one or more of the layers of processing units; send information indicative of the performance measure back through the layers of processing units; process the information indicative of the performance measure in the processing units and in interconnections between the processing units; generate random, chaotic, fuzzy, or other numerical perturbations of the received data, the processed data, or the one or more intermediate or output signals; update the parameters and states of the uncertain system using the received data, the numerical perturbations, and previous parameters and states of the uncertain system; determine whether the generated numerical perturbations satisfy a condition; and if the numerical perturbations satisfy the condition, inject the numerical perturbations into one or more of the parameters or states, the received data, the processed data, or one or more of the processing units.", "Noise-boosted back propagation and deep learning neural networks "]
["A method of reducing image resolution in a deep convolutional network (DCN) includes dynamically selecting a reduction factor to be applied to an input image. The reduction factor can be selected at each layer of the DCN. The method also includes adjusting the DCN based on the reduction factor selected for each layer.", "Reducing image resolution in deep convolutional networks "]
[null, "Calculation apparatus and method for accelerator chip accelerating deep neural network algorithm "]
["A search engine is described herein for providing search results based on a context in which a query has been submitted, as expressed by context information. The search engine operates by ranking a plurality of documents based on a consideration of the query, and based, in part, on a context concept vector and a plurality of document concept vectors, both generated using a deep learning model (such as a deep neural network). The context concept vector is formed by a projection of the context information into a semantic space using the deep learning model. Each document concept vector is formed by a projection of document information, associated with a particular document, into the same semantic space using the deep learning model. The ranking operates by favoring documents that are relevant to the context within the semantic space, and disfavoring documents that are not relevant to the context.", "Context-Sensitive Search Using a Deep Learning Model "]
["Methods and systems for online incremental adaptation of neural networks using Gaussian mixture models in speech recognition are described. In an example, a computing device may be configured to receive an audio signal and a subsequent audio signal, both signals having speech content. The computing device may be configured to apply a speaker-specific feature transform to the audio signal to obtain a transformed audio signal. The speaker-specific feature transform may be configured to include speaker-specific speech characteristics of a speaker-profile relating to the speech content. Further, the computing device may be configured to process the transformed audio signal using a neural network trained to estimate a respective speech content of the audio signal. Based on outputs of the neural network, the computing device may be configured to modify the speaker-specific feature transform, and apply the modified speaker-specific feature transform to a subsequent audio signal.", "Online incremental adaptation of deep neural networks using auxiliary Gaussian mixture models in speech recognition "]
[null, "Image classification method capable of effectively preventing convolutional neural network from being overfit "]
["Systems and methods for speech recognition incorporating environmental variables are provided. The systems and methods capture speech to be recognized. The speech is then recognized utilizing a variable component deep neural network (DNN). The variable component DNN processes the captured speech by incorporating an environment variable. The environment variable may be any variable that is dependent on environmental conditions or the relation of the user, the client device, and the environment. For example, the environment variable may be based on noise of the environment and represented as a signal-to-noise ratio. The variable component DNN may incorporate the environment variable in different ways. For instance, the environment variable may be incorporated into weighting matrices and biases of the DNN, the outputs of the hidden layers of the DNN, or the activation functions of the nodes of the DNN.", "Variable-component deep neural network for robust speech recognition "]
["A network analysis tool receives network flow information and uses deep learning\u2014machine learning that models high-level abstractions in the network flow information\u2014to identify dependencies between network assets. Based on the identified dependencies, the network analysis tool can discover functional relationships between network assets. For example, a network analysis tool receives network flow information, identifies dependencies between multiple network assets based on evaluation of the network flow information, and outputs results of the identification of the dependencies. When evaluating the network flow information, the network analysis tool can pre-process the network flow information to produce input vectors, use deep learning to extract patterns in the input vectors, and then determine dependencies based on the extracted patterns. The network analysis tool can repeat this process so as to update an assessment of the dependencies between network assets on a near real-time basis.", "Extracting dependencies between network assets using deep learning "]
[null, "Deep learning-based method for analyzing medical data and intelligent analyzer thereof "]
[null, "Traffic sign classification method based on deep neural network "]
["Face hallucination using a bi-channel deep convolutional neural network (BCNN), which can adaptively fuse two channels of information. In one example, the BCNN is implemented to extract high level features from an input image. The extracted high level features are combined with low level details in the input image to produce the higher resolution image. Preferably, a proper coefficient is obtained to adaptively combine the high level features and the low level details.", "Face Hallucination Using Convolutional Neural Networks "]
[null, "Asymmetrical voice conversion method based on deep neural network feature mapping "]
[null, "Mobile ad hoc network intrusion detection method and device based on deep learning "]
[null, "Cross-media sorting method based on deep neural network "]
["Apparatuses and methods for image processing are provided. The image processing apparatus performs area classification and object detection in an image, and includes a feature map generator configured to generate the feature map of the input image using the neural network, and an image processor configured to classify the areas and to detect the objects in the image using the generated feature map.", "Image processing apparatus and method based on deep learning and neural network learning "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes generating, by a speech recognition system, a matrix from a predetermined quantity of vectors that each represent input for a layer of a neural network, generating a plurality of sub-matrices from the matrix, using, for each of the sub-matrices, the respective sub-matrix as input to a node in the layer of the neural network to determine whether an utterance encoded in an audio signal comprises a keyword for which the neural network is trained.", "Sub-matrix input for neural network layers "]
[null, "Automatic vehicle detection method based on deep learning "]
["Deep learning is used to identify specific, potential risks to an enterprise (of which litigation is the prime example) while such risks are still internal electronic communications. The system involves mining and using existing classifications of data (e.g., from a litigation database) to train one or more deep learning algorithms, and then examining the internal electronic communications with the trained algorithm, to generate a scored output that will enable enterprise personnel to be alerted to risks and take action in time to prevent the risks from resulting in harm to the enterprise or others.", "Using classified text and deep learning algorithms to identify risk and provide early warning "]
["Methods, including computer programs encoded on a computer storage medium, for enhancing the processing of audio waveforms for speech recognition using various neural network processing techniques. In one aspect, a method includes: receiving multiple channels of audio data corresponding to an utterance; convolving each of multiple filters, in a time domain, with each of the multiple channels of audio waveform data to generate convolution outputs, wherein the multiple filters have parameters that have been learned during a training process that jointly trains the multiple filters and trains a deep neural network as an acoustic model; combining, for each of the multiple filters, the convolution outputs for the filter for the multiple channels of audio waveform data; inputting the combined convolution outputs to the deep neural network trained jointly with the multiple filters; and providing a transcription for the utterance that is determined.", "Processing multi-channel audio waveforms "]
["Deep Neural Networks (DNNs) with many hidden layers and many units per layer are very flexible models with a very large number of parameters. As such, DNNs are challenging to optimize. To achieve real-time computation, embodiments disclosed herein enable fast DNN feature transformation via optimized memory bandwidth utilization. To optimize memory bandwidth utilization, a rate of accessing memory may be reduced based on a batch setting. A memory, corresponding to a selected given output neuron of a current layer of the DNN, may be updated with an incremental output value computed for the selected given output neuron as a function of input values of a selected few non-zero input neurons of a previous layer of the DNN in combination with weights between the selected few non-zero input neurons and the selected given output neuron, wherein a number of the selected few corresponds to the batch setting.", "Fast deep neural network feature transformation via optimized memory bandwidth utilization "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for classification using a neural network. One of the methods for processing an input through each of multiple layers of a neural network to generate an output, wherein each of the multiple layers of the neural network includes a respective multiple nodes includes for a particular layer of the multiple layers: receiving, by a classification system, an activation vector as input for the particular layer, selecting one or more nodes in the particular layer using the activation vector and a hash table that maps numeric values to nodes in the particular layer, and processing the activation vector using the selected nodes to generate an output for the particular layer.", "Large-scale classification in neural networks using hashing "]
["Automated feature construction for algorithm portfolios in machine learning is provided. A gray scale image is generated from a text representing a problem instance. The gray scale image is rescaled or reshaped to a predefined size that is smaller than an initial size of the gray scale image. The rescaled gray scale image represents features of the problem instance. The rescaled gray scale image is input as features to a machine learning-based convolutional neural network. Based on the rescaled gray scale image, the machine learning-based convolutional neural network is automatically trained to learn to automatically determine one or more problem solvers from a portfolio of problem solvers suited for solving the problem instance.", "Deep learning for algorithm portfolios "]
["Disclosed is a feature extraction and classification methodology wherein audio data is gathered in a target environment under varying conditions. From this collected data, corresponding features are extracted, labeled with appropriate filters (e.g., audio event descriptions), and used for training deep neural networks (DNNs) to extract underlying target audio events from unlabeled training data. Once trained, these DNNs are used to predict underlying events in noisy audio to extract therefrom features that enable the separation of the underlying audio events from the noisy components thereof.", "Deep neural net based filter prediction for audio event classification and extraction "]
["Systems and processes for generating complementary acoustic models for performing automatic speech recognition system combination are provided. In one example process, a deep neural network can be trained using a set of training data. The trained deep neural network can be a deep neural network acoustic model. A Gaussian-mixture model can be linked to a hidden layer of the trained deep neural network such that any feature vector outputted from the hidden layer is received by the Gaussian-mixture model. The Gaussian-mixture model can be trained via a first portion of the trained deep neural network and using the set of training data. The first portion of the trained deep neural network can include an input layer of the deep neural network and the hidden layer. The first portion of the trained deep neural network and the trained Gaussian-mixture model can be a Deep Neural Network-Gaussian-Mixture Model (DNN-GMM) acoustic model.", "Efficient generation of complementary acoustic models for performing automatic speech recognition system combination "]
["A method for training a neural network to perform assessments of image quality is provided. The method includes: inputting into the neural network at least one set of images, each set including an image and at least one degraded version of the image; performing comparative ranking of each image in the at least one set of images; and training the neural network with the ranking information. A neural network and image signal processing tuning system are disclosed.", "Label-free non-reference image quality assessment via deep neural network "]
["Systems and techniques are provided for a ranking approach to train deep neural nets for multilabel image annotation. Label scores may be received for labels determined by a neural network for training examples. Each label may be a positive label or a negative label for the training example. An error of the neural network may be determined based on a comparison, for each of the training examples, of the label scores for positive labels and negative labels for the training example and a semantic distance between each positive label and each negative label for the training example. Updated weights may be determined for the neural network based on a gradient of the determined error of the neural network. The updated weights may be applied to the neural network to train the neural network.", "Ranking approach to train deep neural nets for multilabel image annotation "]
["Systems and methods are disclosed for segregating target individuals represented in a probe digital image from background pixels in the probe digital image. In particular, in one or more embodiments, the disclosed systems and methods train a neural network based on two or more of training position channels, training shape input channels, training color channels, or training object data. Moreover, in one or more embodiments, the disclosed systems and methods utilize the trained neural network to select a target individual in a probe digital image. Specifically, in one or more embodiments, the disclosed systems and methods generate position channels, training shape input channels, and color channels corresponding the probe digital image, and utilize the generated channels in conjunction with the trained neural network to select the target individual.", "Utilizing deep learning for automatic digital image segmentation and stylization "]
[null, "Convolutional neural network-based license plate detection method and system "]
["Face representation is a crucial step of face recognition systems. An optimal face representation should be discriminative, robust, compact, and very easy to implement. While numerous hand-crafted and learning-based representations have been proposed, considerable room for improvement is still present. A very easy-to-implement deep learning framework for face representation is presented. The framework bases on pyramid convolutional neural network (CNN). The pyramid CNN adopts a greedy-filter-and-down-sample operation, which enables the training procedure to be very fast and computation efficient. In addition, the structure of Pyramid CNN can naturally incorporate feature sharing across multi-scale face representations, increasing the discriminative ability of resulting representation.", "Learning Deep Face Representation "]
["Aspects of the present disclosure are directed to techniques that improve performance of CNN systems through the effect of improved memory efficiencies for CNNs operating on GPUs. Aspects of the disclosure demonstrate that off-chip memory in such CNN systems is underutilized due to at least three characteristics namely, data layout, data locality and inter-kernel redundancy. Aspects of the disclosure examine the performance impact of different data layouts and then describe a method to produce data layout selection for various layers of the CNN including a fast transformation implementation. Disclosed are improvements to data locality from working set expansion, elimination of inter-kernel redundancy and increase of TLP using kernel reconstruction techniques including kernel fusion and thread injection. Disclosed experimental results show that our optimizations are very effective to boost the performance of CNNs by amounts up to 9.76 times for a single kernel and 2.05 times for a network.", "Memory efficiency for convolutional neural networks operating on graphics processing units "]
["Systems, methods, and computer media for implementing convolutional neural networks efficiently in hardware are disclosed herein. A memory is configured to store a sparse, frequency domain representation of a convolutional weighting kernel. A time-domain-to-frequency-domain converter is configured to generate a frequency domain representation of an input image. A feature extractor is configured to access the memory and, by a processor, extract features based on the sparse, frequency domain representation of the convolutional weighting kernel and the frequency domain representation of the input image. The feature extractor includes convolutional layers and fully connected layers. A classifier is configured to determine, based on extracted features, whether the input image contains an object of interest. Various types of memory can be used to store different information, allowing information-dense data to be stored in faster (e.g., faster access time) memory and sparse data to be stored in slower memory.", "Hardware-efficient deep convolutional neural networks "]
["A method and apparatus are disclosed for implementing a neural network having a sleep mode during which capacitively stored synaptic connectivity weights are refreshed. Each neuron outputs an analog activity level, represented in a preferred embodiment by the frequency of digital pulses. Feed-forward synaptic connection circuits couple the activity level outputs of first level neurons to inputs of second level neurons, and feed-back synaptic connection circuits couple outputs of second level neurons to inputs of first level neurons, the coupling being weighted according to connectivity weights stored on respective storage capacitors in each synaptic connection circuit. The network learns according to a learning algorithm under which the connections in both directions between a particular first level neuron and a particular second level neuron are strengthened to the extent of concurrence of high activity levels in both the first and second level neurons, and weakened to the extent of concurrence of a high activity level in the second level neuron and a low activity level in the first level neuron. The network is put to sleep by disconnecting all environmental inputs and providing a non-specific low activity level signal to each of the first level neurons. This causes the network to randomly traverse its state space with low intensity resonant firings, each state being visited with a probability responsive to the initial connectivity weights of the connections which abut the second level neuron representing such state. Refresh is accomplished since the learning algorithm remains active during sleep. Thus, the sleep refresh mechanism enhances the contrast in the connectivity terrain and strengthens connections that would otherwise wash out due to lack of visitation while the system is awake. A deep sleep mechanism is also provided for preventing runaway strengthening of favored states, and also to encourage Weber Law compliance.", "Sleep refreshed memory for neural network "]
[null, "Method and system for optimizing deep neural network "]
["A method for predicting a canonical form for an input text sequence includes predicting the canonical form with a neural network model. The model includes an encoder, which generates a first representation of the input text sequence based on a representation of n-grams in the text sequence and a second representation of the input text sequence generated by a first neural network. The model also includes a decoder which sequentially predicts terms of the canonical form based on the first and second representations and a predicted prefix of the canonical form. The canonical form can be used, for example, to query a knowledge base or to generate a next utterance in a discourse.", "Semantic parsing using deep neural networks for predicting canonical forms "]
["Technical solutions are described for implementing a convolutional neural network (CNN) using resistive processing unit (RPU) array. An example method includes configuring an RPU array corresponding to a convolution layer in the CNN based on convolution kernels of the layer. The method further includes performing forward pass computations via the RPU array by transmitting voltage pulses corresponding to input data to the RPU array, and storing values corresponding to output currents from the RPU arrays as output maps. The method further includes performing backward pass computations via the RPU array by transmitting voltage pulses corresponding to error of the output maps, and storing the output currents from the RPU arrays as backward error maps. The method further includes performing update pass computations via the RPU array by transmitting voltage pulses corresponding to the input data of the convolution layer and the error of the output maps to the RPU array.", "Convolutional neural networks using resistive processing unit array "]
["Systems and method are disclosed for determining complex interactions among system inputs by using semi-Restricted Boltzmann Machines (RBMs) with factorized gated interactions of different orders to model complex interactions among system inputs; applying semi-RBMs to train a deep neural network with high-order within-layer interactions for learning a distance metric and a feature mapping; and tuning the deep neural network by minimizing margin violations between positive query document pairs and corresponding negative pairs.", "High-Order Semi-RBMs and Deep Gated Neural Networks for Feature Interaction Identification and Non-Linear Semantic Indexing "]
["A system may comprise one or more processors and memory storing instructions that, when executed by one or more processors, configure one or more processors to perform a number of operations or tasks, such as receiving a query or a document, and mapping the query or the document into a lower dimensional representation by performing at least one operational layer that shares at least two disparate tasks.", "Representation Learning Using Multi-Task Deep Neural Networks "]
["A neural network can be used to determine edit operations for normalizing an electronic communication. For example, an electronic representation of multiple characters that form a noncanonical communication can be received. It can be determined that the noncanonical communication is mapped to at least two canonical terms in a database. A recurrent neural network can be used to determine one or more edit operations usable to convert the noncanonical communication into a normalized version of the noncanonical communication. In some examples, the one or more edit operations can include inserting a character into the noncanonical communication, deleting the character from the noncanonical communication, or replacing the character with another character in the noncanonical communication. The noncanonical communication can be transformed into the normalized version of the noncanonical communication by performing the one or more edit operations.", "Determining edit operations for normalizing electronic communications using a neural network "]
[null, "Convolution neural network parallel processing method based on large-scale high-performance cluster "]
[null, "Short-term wind speed forecasting method based on deep neural network transfer model "]
["Provided is a DNN learning method that can reduce DNN learning time using data belonging to a plurality of categories. The method includes the steps of training a language-independent sub-network 120 and language-dependent sub-networks 122 and 124 with training data of Japanese and English. This step includes: a first step of training a DNN obtained by connecting neurons in an output layer of the sub-network 120 with neurons in an input layer of sub-network 122 with Japanese training data; a step of forming a DNN by connecting the sub-network 124 in place of the sub-network 122 to the sub-network 120 and training it with English data; repeating these steps alternately until all training data ends; and after completion, separating the first sub-network 120 from other sub-networks and storing it as a category-independent sub-network in a storage medium.", "Deep neural network learning method and apparatus, and category-independent sub-network learning apparatus "]
[null, "Image inspection apparatus for manufactured articles using deep neural network training method and image inspection method of manufactured articles thereby "]
["A convolutional neural network (CNN) is trained for font recognition and font similarity learning. In a training phase, text images with font labels are synthesized by introducing variances to minimize the gap between the training images and real-world text images. Training images are generated and input into the CNN. The output is fed into an N-way softmax function dependent on the number of fonts the CNN is being trained on, producing a distribution of classified text images over N class labels. In a testing phase, each test image is normalized in height and squeezed in aspect ratio resulting in a plurality of test patches. The CNN averages the probabilities of each test patch belonging to a set of fonts to obtain a classification. Feature representations may be extracted and utilized to define font similarity between fonts, which may be utilized in font suggestion, font browsing, or font recognition applications.", "Font recognition and font similarity learning using a deep neural network "]
["A method and system for separating noise from speech in real time is provided to improve intelligibility of speech for a variety of communications devices and hearing aids. From a speech signal, a plurality of frame-level features are extracted and form the input to the classifier. The classifier is a deep neural network comprising multiple hidden layers and an output layer with multiple output units. The classifier classifies the speech into a plurality of time-frequency units simultaneously. The classifier output constitutes an estimated ideal binary mask from which a fast gammatone filter bank is used to resynthesize the separated speech into an enhanced speech waveform.", "Real-time method for implementing deep neural network based speech separation "]
["Different candidate windows in an image are identified, such as by sliding a rectangular or other geometric shape of different sizes over an image to identify portions of the image (groups of pixels in the image). The candidate windows are analyzed by a set of convolutional neural networks, which are cascaded so that the input of one convolutional neural network layer is based on the input of another convolutional neural network layer. Each convolutional neural network layer drops or rejects one or more candidate windows that the convolutional neural network layer determines does not include an object (e.g., a face). The candidate windows that are identified as including an object (e.g., a face) are analyzed by another one of the convolutional neural network layers. The candidate windows identified by the last of the convolutional neural network layers are the indications of the objects (e.g., faces) in the image.", "Object detection using cascaded convolutional neural networks "]
[null, "Continuous voice recognition method based on deep long and short term memory recurrent neural network "]
["In accordance with various embodiments of the disclosed subject matter, a method and a system for vision-centric deep-learning-based road situation analysis are provided. The method can include: receiving real-time traffic environment visual input from a camera; determining, using a ROLO engine, at least one initial region of interest from the real-time traffic environment visual input by using a CNN training method; verifying the at least one initial region of interest to determine if a detected object in the at least one initial region of interest is a candidate object to be tracked; using LSTMs to track the detected object based on the real-time traffic environment visual input, and predicting a future status of the detected object by using the CNN training method; and determining if a warning signal is to be presented to a driver of a vehicle based on the predicted future status of the detected object.", "Method and system for vision-centric deep-learning-based road situation analysis "]
[null, "Hierarchical neural network device, classifier learning method and determination method "]
["Described are systems, media, and methods for applying deep convolutional neural networks to medical images to generate a real-time or near real-time diagnosis.", "Computer-aided diagnosis system for medical images using deep convolutional neural networks "]
["It is disclosed a method comprising obtaining a target spectrum, obtaining a set of non-target spectra, the set of non-target spectra comprising one or more non-target spectra, summing the target spectrum and the set of non-target spectra to obtain a mixture spectrum, and training an artificial neural network by using the mixture spectrum as input of the neural network and by using a spectrum which is based on the target spectrum as desired output of the artificial neural network.", "Method, system and artificial neural network "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for inputting speech data that corresponds to a particular utterance to a neural network; determining an evaluation vector based on output at a hidden layer of the neural network; comparing the evaluation vector with a reference vector that corresponds to a past utterance of a particular speaker; and based on comparing the evaluation vector and the reference vector, determining whether the particular utterance was likely spoken by the particular speaker.", "Speaker verification using neural networks "]
["Systems and methods for reducing a number of training parameters in a deep belief network (DBN) are provided. A method for reducing a number of training parameters in a deep belief network (DBN) comprises determining a network architecture including a plurality of layers, using matrix factorization to represent a weight matrix of a final layer of the plurality of layers as a plurality of matrices, and training the DBN having the plurality of matrices.", "System and method for low-rank matrix factorization for deep belief network training with high-dimensional output targets "]
["A method for selecting bit widths for a fixed point machine learning model includes evaluating a sensitivity of model accuracy to bit widths at each computational stage of the model. The method also includes selecting a bit width for parameters, and/or intermediate calculations in the computational stages of the mode. The bit width for the parameters and the bit width for the intermediate calculations may be different. The selected bit width may be determined based on the sensitivity evaluation.", "Bit width selection for fixed point neural networks "]
["Provided are a signal processing algorithm-integrated deep neural network (DNN)-based speech recognition apparatus and a learning method thereof. A model parameter learning method in a deep neural network (DNN)-based speech recognition apparatus implementable by a computer includes converting a signal processing algorithm for extracting a feature parameter from a speech input signal of a time domain into signal processing deep neural network (DNN), fusing the signal processing DNN and a classification DNN, and learning a model parameter in a deep learning model in which the signal processing DNN and the classification DNN are fused.", "Signal processing algorithm-integrated deep neural network-based speech recognition apparatus and learning method thereof "]
["Described herein are systems and methods for generating and using attention-based deep learning architectures for visual question answering task (VQA) to automatically generate answers for image-related (still or video images) questions. To generate the correct answers, it is important for a model's attention to focus on the relevant regions of an image according to the question because different questions may ask about the attributes of different image regions. In embodiments, such question-guided attention is learned with a configurable convolutional neural network (ABC-CNN). Embodiments of the ABC-CNN models determine the attention maps by convolving image feature map with the configurable convolutional kernels determined by the questions semantics. In embodiments, the question-guided attention maps focus on the question-related regions and filters out noise in the unrelated regions.", "Systems and methods for attention-based configurable convolutional neural networks (abc-cnn) for visual question answering "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using neural networks. One of the methods includes receiving, by a neural network in a speech recognition system, first data representing a first raw audio signal and second data representing a second raw audio signal, the first raw audio signal and the second raw audio signal for the same period of time, generating, by a spatial filtering convolutional layer in the neural network, a spatial filtered output the first data and the second data, generating, by a spectral filtering convolutional layer in the neural network, a spectral filtered output using the spatial filtered output, and processing, by one or more additional layers in the neural network, the spectral filtered output to predict sub-word units encoded in both the first raw audio signal and the second raw audio signal.", "Multichannel raw-waveform neural networks "]
["Electronic communications can be normalized using neural networks. For example, an electronic representation of a noncanonical communication can be received. A normalized version of the noncanonical communication can be determined using a normalizer including a neural network. The neural network can receive a single vector at an input layer of the neural network and transform an output of a hidden layer of the neural network into multiple values that sum to a total value of one. Each value of the multiple values can be a number between zero and one and represent a probability of a particular character being in a particular position in the normalized version of the noncanonical communication. The neural network can determine the normalized version of the noncanonical communication based on the multiple values. Whether the normalized version should be output can be determined based on a result from a flagger including another neural network.", "Normalizing electronic communications using a neural-network normalizer and a neural-network flagger "]
["A neural network comprising a plurality of neurons in which any one of the plurality of neurons is able to associate with itself or another neuron in the plurality of neurons via active connections to a further neuron in the pluarlity of neurons.", "Neural networks with learning and expression capability "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing speaker verification. In one aspect, a method includes accessing a neural network having an input layer that provides inputs to a first hidden layer whose nodes are respectively connected to only a proper subset of the inputs from the input layer. Speech data that corresponds to a particular utterance may be provided as input to the input layer of the neural network. A representation of activations that occur in response to the speech data at a particular layer of the neural network that was configured as a hidden layer during training of the neural network may be generated. A determination of whether the particular utterance was likely spoken by a particular speaker may be made based at least on the generated representation. An indication of whether the particular utterance was likely spoken by the particular speaker may be provided.", "Speaker recognition using neural networks "]
[null, "Dialogue act identification method based on deep neural networks and conditional random fields "]
[null, "Deep neural network learning method, processor and deep neural network learning system "]
["This document generally describes systems, methods, devices, and other techniques related to speaker verification, including (i) training a neural network for a speaker verification model, (ii) enrolling users at a client device, and (iii) verifying identities of users based on characteristics of the users' voices. Some implementations include a computer-implemented method. The method can include receiving, at a computing device, data that characterizes an utterance of a user of the computing device. A speaker representation can be generated, at the computing device, for the utterance using a neural network on the computing device. The neural network can be trained based on a plurality of training samples that each: (i) include data that characterizes a first utterance and data that characterizes one or more second utterances, and (ii) are labeled as a matching speakers sample or a non-matching speakers sample.", "Neural Networks For Speaker Verification "]
[null, "Complex character recognition method based on deep learning "]
["Tasks such as object classification from image data can take advantage of a deep learning process using convolutional neural networks. These networks can include a convolutional layer followed by an activation layer, or activation unit, among other potential layers. Improved accuracy can be obtained by using a generalized linear unit (GLU) as an activation unit in such a network, where a GLU is linear for both positive and negative inputs, and is defined by a positive slope, a negative slope, and a bias. These parameters can be learned for each channel or a block of channels, and stacking those types of activation units can further improve accuracy.", "Activation layers for deep learning networks "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a deep neural network. One of the methods for training a deep neural network that includes a low rank hidden input layer and an adjoining hidden layer, the low rank hidden input layer including a first matrix A and a second matrix B with dimensions i\u00d7m and m\u00d7o, respectively, to identify a keyword includes receiving a feature vector including i values that represent features of an audio signal encoding an utterance, determining, using the low rank hidden input layer, an output vector including o values using the feature vector, determining, using the adjoining hidden layer, another vector using the output vector, determining a confidence score that indicates whether the utterance includes the keyword using the other vector, and adjusting weights for the low rank hidden input layer using the confidence score.", "Low-rank hidden input layer for speech recognition neural network "]
["This specification describes, among other things, a computer-implemented method. The method can include training a baseline neural network using a first set of training data. For each node in a subset of interconnected nodes in the baseline neural network, a rank-k approximation of a filter for the node can be computed. A subset of nodes in a rank-constrained neural network can then be initialized with the rank-k approximations of the filters from the baseline neural network. The subset of nodes in the rank-constrained neural network can correspond to the subset of nodes in the baseline neural network. After initializing, the rank-constrained neural network can be trained using a second set of training data while maintaining a rank-k filter topology for the subset of nodes in the rank-constrained neural network.", "Rank-constrained neural networks "]
["Aspects of the technology described herein relate to a new type of deep neural network (DNN). The new DNN is described herein as a deep neural support vector machine (DNSVM). Traditional DNNs use the multinomial logistic regression (softmax activation) at the top layer and underlying layers for training. The new DNN instead uses a support vector machine (SVM) as one or more layers, including the top layer. The technology described herein can use one of two training algorithms to train the DNSVM to learn parameters of SVM and DNN in the maximum-margin criteria. The first training method is a frame-level training. In the frame-level training, the new model is shown to be related to the multi-class SVM with DNN features. The second training method is the sequence-level training. The sequence-level training is related to the structured SVM with DNN features and HMM state transition features.", "Deep neural support vector machines "]
["Systems and methods for defection classification in a semiconductor process are provided. The system includes a communication line configured to receive a defect image of a wafer from the semiconductor process and a deep-architecture neural network in electronic communication with the communication line. The neural network has a first convolution layer of neurons configured to convolve pixels from the defect image with a filter to generate a first feature map. The neural network also includes a first subsampling layer configured to reduce the size and variation of the first feature map. A classifier is provided for determining a defect classification based on the feature map. The system may include more than one convolution layers and/or subsampling layers. A method includes extracting one or more features from a defect image using a deep-architecture neural network, for example a convolutional neural network.", "Automatic Defect Classification Without Sampling and Feature Selection "]
["The present invention is directed to a deep neural network (DNN) having a triplet network architecture, which is suitable to perform speaker recognition. In particular, the DNN includes three feed-forward neural networks, which are trained according to a batch process utilizing a cohort set of negative training samples. After each batch of training samples is processed, the DNN may be trained according to a loss function, e.g., utilizing a cosine measure of similarity between respective samples, along with positive and negative margins, to provide a robust representation of voiceprints.", "End-to-end speaker recognition using deep neural network "]
[null, "Speech synthesis method, apparatus and equipment "]
[null, "Speech recognition method using feature compensation based on deep neural network "]
[null, "Method and apparatus for conceal packet loss based on the deep neural network "]
["The present disclosure provides devices and systems for diagnosing and characterizing cancer in a subject. Devices include microfilters and microfiltration systems useful for the isolation and characterization of cells from a subject.", "Convolutional neural networks for cancer diagnosis "]
["Systems and methods for efficient implementation of a convolutional layer of a convolutional neural network are disclosed. In one aspect, weight values of kernels in a kernel stack of a convolutional layer can be reordered into a tile layout with tiles of runnels. Pixel values of input activation maps of the convolutional layer can be reordered into an interleaved layout comprising a plurality of clusters of input activation map pixels. The output activation maps can be determined using the clusters of the input activation map pixels and kernels tile by tile.", "Efficient data layouts for convolutional neural networks "]
["Methods and systems for processing computer game videos for virtual reality replay are disclosed. The method, when executed by a processor, comprises first receiving a video recorded using a virtual camera array during a game play of a source computer game. Next, upscaling the received video to a higher resolution, and interpolating neighboring video frames of the upscaled video for insertion into the upscaled video at a server. Finally, generating a spherical video from the interpolated video for replay in a virtual reality environment. The virtual camera array includes multiple virtual cameras each facing a different direction, and the video is recorded at a frame rate and a resolution lower than those of the source computer game. The spherical videos are provided on a video sharing platform. The present invention solves the chicken-and-egg problem of mass adoption of virtual reality technology by easily generating VR content from existing computer games.", "Methods and systems for game video recording and virtual reality replay "]
["Training neural networks by constructing a neural network model having neurons each associated with a quantized activation function adapted to output a quantized activation value. The neurons are arranged in layers and connected by connections associated quantized connection weight functions adapted to output quantized connection weight values. During a training process a plurality of weight gradients are calculated during backpropagation sub-processes by computing neuron gradients, each of an output of a respective the quantized activation function in one layer with respect to an input of the respective quantized activation function. Each neuron gradient is calculated such that when an absolute value of the input is smaller than a positive constant threshold value, the respective neuron gradient is set as a positive constant output value and when the absolute value of the input is smaller than the positive constant threshold value the neuron gradient is set to zero.", "Quantized neural network training and inference "]
[null, "Statistical Model-based Voice Activity Detection with Ensemble of Deep Neural Network Using Acoustic Environment Classification and Voice Activity Detection Method thereof "]
["A system and method of determining a neural network configuration may include receiving at least one neural network configuration, altering the received configuration for at least two iterations, calculating a first parameter of an altered configuration, calculating a second parameter of a consecutive altered configuration of the at least two iterations, comparing values of the calculated first parameter and second parameter, and determining a configuration having largest value of the calculated parameters.", "System and method for automatic selection of deep learning architecture "]
["Systems and methods for test object classification are provided in which the test object is docked with a target object in a plurality of different poses to form voxel maps. The maps are vectorized and fed into a convolutional neural network comprising an input layer, a plurality of individually weighted convolutional layers, and an output scorer. The convolutional layers include initial and final layers. Responsive to vectorized input, the input layer feeds values into the initial convolutional layer. Each respective convolutional layer, other than the final convolutional layer, feeds intermediate values as a function of the weights and input values of the respective layer into another of the convolutional layers. The final convolutional layer feeds values into one or more fully connected layers as a function of the final layer weights and input values. The one or more full connected layers feed values into the scorer which scores each input vector to thereby classify the test object.", "Systems and methods for applying a convolutional network to spatial data "]
["Techniques related to implementing neural networks for speech recognition systems are discussed. Such techniques may include implementing frame skipping with approximated skip frames and/or distances on demand such that only those outputs needed by a speech decoder are provided via the neural network or approximation techniques.", "Frame Skipping With Extrapolation and Outputs On Demand Neural Network For Automatic Speech Recognition "]
["An artificial neural network and methods for performing computations on an artificial neural network include multiple neurons, including a layer of input neurons, one or more layers of hidden neurons, and a layer of output neurons. Arrays of weights are configured to accept voltage pulses from a first layer of neurons and to output current to a second layer of neurons during a feed forward operation. Each array of weights includes multiple resistive processing units having respective settable resistances.", "Deep neural network training with native devices "]
[null, "Deep neural network-based SAR texture image classification method "]
[null, "Method and system for constructing deep neural network "]
["A method is provided for implementing a deep neural network on a server component that includes a host component including a CPU and a hardware acceleration component coupled to the host component. The deep neural network includes a plurality of layers. The method includes partitioning the deep neural network into a first segment and a second segment, the first segment including a first subset of the plurality of layers, the second segment including a second subset of the plurality of layers, configuring the host component to implement the first segment, and configuring the hardware acceleration component to implement the second segment.", "Deep neural network partitioning on servers "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for keyword spotting. One of the methods includes training, by a keyword detection system, a convolutional neural network for keyword detection by providing a two-dimensional set of input values to the convolutional neural network, the input values including a first dimension in time and a second dimension in frequency, and performing convolutional multiplication on the two-dimensional set of input values for a filter using a frequency stride greater than one to generate a feature map.", "Convolutional neural networks "]
["Techniques related to implementing neural networks for speech recognition systems are discussed. Such techniques may include processing a node of the neural network by determining a score for the node as a product of weights and inputs such that the weights are fixed point integer values, applying a correction to the score based a correction value associated with at least one of the weights, and generating an output from the node based on the corrected score.", "Improved fixed point integer implementations for neural networks "]
["A hardware acceleration component is provided for implementing a convolutional neural network. The hardware acceleration component includes an array of N rows and M columns of functional units, an array of N input data buffers configured to store input data, and an array of M weights data buffers configured to store weights data. Each of the N input data buffers is coupled to a corresponding one of the N rows of functional units. Each of the M weights data buffers is coupled to a corresponding one of the M columns of functional units. Each functional unit in a row is configured to receive a same set of input data. Each functional unit in a column is configured to receive a same set of weights data from the weights data buffer coupled to the row. Each of the functional units is configured to perform a convolution of the received input data and the received weights data, and the M columns of functional units are configured to provide M planes of output data.", "Convolutional neural networks on hardware accelerators "]
["A system for bit-serial computation in a neural network is described. The system may be embodied on an integrated circuit and include one or more bit-serial tiles for performing bit-serial computations in which each bit-serial tile receives input neurons and synapses, and communicates output neurons. Also included is an activation memory for storing the neurons and a dispatcher and a reducer. The dispatcher reads neurons and synapses from memory and communicates either the neurons or the synapses bit-serially to the one or more bit-serial tiles. The other of the neurons or the synapses are communicated bit-parallelly to the one or more bit-serial tiles, or according to a further embodiment, may also be communicated bit-serially to the one or more bit-serial tiles. The reducer receives the output neurons from the one or more tiles, and communicates the output neurons to the activation memory.", "Accelerator for deep neural networks "]
["Systems and methods for iris authentication are disclosed. In one aspect, a deep neural network (DNN) with a triplet network architecture can be trained to learn an embedding (e.g., another DNN) that maps from the higher dimensional eye image space to a lower dimensional embedding space. The DNN can be trained with segmented iris images or images of the periocular region of the eye (including the eye and portions around the eye such as eyelids, eyebrows, eyelashes, and skin surrounding the eye). With the triplet network architecture, an embedding space representation (ESR) of a person's eye image can be closer to the ESRs of the person's other eye images than it is to the ESR of another person's eye image. In another aspect, to authenticate a user as an authorized user, an ESR of the user's eye image can be sufficiently close to an ESR of the authorized user's eye image.", "Deep neural network for iris identification "]
["Methods and systems for real-time user extraction using deep learning networks. In one embodiment, user extraction comprises obtaining a given frame of color pixel data, checking whether a reset flag is cleared or set, and generating a trimap for the given frame. If the reset flag is cleared, generating the trimap comprises: obtaining a user-extraction contour based on a preceding frame; and generating the trimap based on the obtained user-extraction contour. If the reset flag is set, generating the trimap comprises: detecting at least one persona feature in the given frame; generating an alpha mask by aligning an intermediate contour with the detected persona feature(s), wherein the intermediate contour is based on a color-based flood-fill operation performed on a previous frame which was segmented by a machine-learning-segmentation process; and generating the trimap based on the generated alpha mask. The generated trimap is output for extracting a user persona.", "Methods and systems for real-time user extraction using deep learning networks "]
["The use of the alternating direction method of multipliers (ADMM) algorithm to train a classifier may reduce the amount of classifier training time with little degradation in classifier accuracy. The training involves partitioning the training data for training the classifier into multiple data blocks. The partitions may preserve the joint distribution of input features and an output class of the training data. The training may further include performing an ADMM iteration on the multiple data blocks in an initial order using multiple worker nodes. Subsequently, the training of the classifier is determined to be completed if a stop criterion is satisfied following the ADMM iteration. Otherwise, if the stop criterion is determined to be unsatisfied following the ADMM iteration, one or more additional ADMM iterations may be performed on different orders of the multiple data blocks until the stop criterion is satisfied.", "Deep learning using alternating direction method of multipliers "]
["A deep neural network to which data category information is added is established locally, to-be-identified data is input to an input layer of the deep neural network generated based on the foregoing data category information, and information of a category to which the to-be-identified data belongs is acquired, where the information of the category is output by an output layer of the deep neural network. A deep neural network is established based on data category information, such that category information of to-be-identified data is conveniently and rapidly obtained using the deep neural network, thereby implementing a category identification function of the deep neural network, and facilitating discovery of an underlying law of the to-be-identified data according to the category information of the to-be-identified data.", "Data Category Identification Method and Apparatus Based on Deep Neural Network "]
["Integrated deep learning and clinical image viewing and reporting are provided. In some embodiments, a clinical image is received. An annotated image is generated from the clinical image by application of a deep learning system. At least one clinical finding is generated from the clinical image by application of the deep learning system. The annotated image and the at least one clinical finding are provided to a user. A structured report is generated based on the annotated image and the at least one clinical finding.", "Integrated deep learning and clinical image viewing and reporting "]
["In one embodiment, a method includes training a deep neural network using a first set of network characteristics corresponding to a first time and a second set of network characteristics corresponding to a second time, generating, using the deep neural network, a predictive set of network characteristics corresponding to a future time, and assigning a task of a distributed application to a processing unit based on the predictive set of network characteristics.", "Deep Learning Application Distribution "]
[null, "Wind power field power prediction method based on deep neural network "]
["Methods and systems for audio source separation in real-time are described. In an embodiment, the present disclosure describes reading and decoding an audio source into PCM samples, fragmenting Pulse Code Modulation (PCM) samples into fragments, transforming fragments into spectrograms, performing audio source separation using a deep neural network (DNN) to generate an estimated magnitude spectrogram of the component(s) of the audio source, reconstructing the estimated time domain component signals, and streaming the component signals to a playback engine. In an embodiment, a semantic equalizer graphical user allows for real-time mixing of individual component signals.", "Real-time audio source separation using deep neural networks "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for compressing images using neural networks. One of the methods includes receiving an image; processing the image using an encoder neural network, wherein the encoder neural network is configured to receive the image and to process the image to generate an output defining values of a first number of latent variables that each represent a feature of the image; generating a compressed representation of the image using the output defining the values of the first number of latent variables; and providing the compressed representation of the image for use in generating a reconstruction of the image.", "Compressing images using neural networks "]
["A computer-implemented method, system, and computer program product is provided for video security. The method includes monitoring an area with a camera. The method also includes capturing, by the camera, live video to provide a live video stream. The method additionally includes detecting and identifying, by a processor using a recognition neural network feeding into a Siamese reconstruction network, a user in the live video stream by employing one or more pose-invariant features. The method further includes controlling, by the processor, an operation of a processor-based machine to change a state of the processor-based machine, responsive to the identified user in the live video stream.", "Video security system using a siamese reconstruction convolutional neural network for pose-invariant face recognition "]
["The technology described herein uses a modular model to process speech. A deep learning based acoustic model comprises a stack of different types of neural network layers. The sub-modules of a deep learning based acoustic model can be used to represent distinct non-phonetic acoustic factors, such as accent origins (e.g. native, non-native), speech channels (e.g. mobile, bluetooth, desktop etc.), speech application scenario (e.g. voice search, short message dictation etc.), and speaker variation (e.g. individual speakers or clustered speakers), etc. The technology described herein uses certain sub-modules in a first context and a second group of sub-modules in a second context.", "Modular deep learning model "]
["A system may comprise one or more processors and memory storing instructions that, when executed by one or more processors, configure one or more processors to perform a number of operations or tasks, such as receiving a query or a document, and mapping the query or the document into a lower dimensional representation by performing at least one operational layer that shares at least two disparate tasks.", "Representation learning using multi-task deep neural networks "]
["A method is provided for processing on an acceleration component a deep neural network. The method includes configuring the acceleration component to perform forward propagation and backpropagation stages of the deep neural network. The acceleration component includes an acceleration component die and a memory stack disposed in an integrated circuit package. The memory stack has a memory bandwidth greater than about 50 GB/sec and a power efficiency of greater than about 20 MB/sec/mW.", "Deep neural network processing on hardware accelerators with stacked memory "]
[null, "Deep neural network learning system and method for classifying threat signal of electronic warfare "]
["Deep neural networks can be visualized. For example, first values for a first layer of nodes in a neural network, second values for a second layer of nodes in the neural network, and/or third values for connections between the first layer of nodes and the second layer of nodes can be received. A quilt graph can be output that includes (i) a first set of symbols having visual characteristics representative of the first values and representing the first layer of nodes along a first axis; (ii) a second set of symbols having visual characteristics representative of the second values and representing the second layer of nodes along a second axis; and/or (iii) a matrix of blocks between the first axis and the second axis having visual characteristics representative of the third values and representing the connections between the first layer of nodes and the second layer of nodes.", "Visualizing deep neural networks "]
["A method of training a neural network model includes determining a specificity of multiple filters after a predetermined number of training iterations. The method also includes training each of the filters based on the specificity.", "Filter specificity as training criterion for neural networks "]
["A method, computer program product, and system perform computations using a sparse convolutional neural network accelerator. Compressed-sparse data is received for input to a processing element, wherein the compressed-sparse data encodes non-zero elements and corresponding multi-dimensional positions. The non-zero elements are processed in parallel by the processing element to produce a plurality of result values. The corresponding multi-dimensional positions are processed in parallel by the processing element to produce destination addresses for each result value in the plurality of result values. Each result value is transmitted to a destination accumulator associated with the destination address for the result value.", "Sparse convolutional neural network accelerator "]
["Systems and methods for cuboid detection and keypoint localization in images are disclosed. In one aspect, a deep cuboid detector can be used for simultaneous cuboid detection and keypoint localization in monocular images. The deep cuboid detector can include a plurality of convolutional layers and non-convolutional layers of a trained convolution neural network for determining a convolutional feature map from an input image. A region proposal network of the deep cuboid detector can determine a bounding box surrounding a cuboid in the image using the convolutional feature map. The pooling layer and regressor layers of the deep cuboid detector can implement iterative feature pooling for determining a refined bounding box and a parameterized representation of the cuboid.", "Deep learning system for cuboid detection "]
[null, "System and method for predicting disease inforamtion using deep neural network "]
[null, "Method and program for early detection of sepsis with deep neural networks "]
[null, "Voice activity detection method based on statistical model employing deep neural network and voice activity detection device performing the same "]
["Described is a system, integrated circuit and method for reducing ineffectual computations in the processing of layers in a neural network. One or more tiles perform computations where each tile receives input neurons, offsets and synapses, and where each input neuron has an associated offset. Each tile generates output neurons, and there is also an activation memory for storing neurons in communication with the tiles via a dispatcher and an encoder. The dispatcher reads neurons from the activation memory and communicates the neurons to the tiles and reads synapses from a memory and communicates the synapses to the tiles. The encoder receives the output neurons from the tiles, encodes them and communicates the output neurons to the activation memory. The offsets are processed by the tiles in order to perform computations only on non-zero neurons. Optionally, synapses may be similarly processed to skip ineffectual operations.", "Accelerator for deep neural networks "]
[null, "Energy storage battery management system based on deep learning network "]
["The present disclosure provides systems and methods that include or otherwise leverage a machine-learned neural synthesizer model. Unlike a traditional synthesizer which generates audio from hand-designed components like oscillators and wavetables, the neural synthesizer model can use deep neural networks to generate sounds at the level of individual samples. Learning directly from data, the neural synthesizer model can provide intuitive control over timbre and dynamics and enable exploration of new sounds that would be difficult or impossible to produce with a hand-tuned synthesizer. As one example, the neural synthesizer model can be a neural synthesis autoencoder that includes an encoder model that learns embeddings descriptive of musical characteristics and an autoregressive decoder model that is conditioned on the embedding to autoregressively generate musical waveforms that have the musical characteristics one audio sample at a time.", "Generating music with deep neural networks "]
["A method and apparatus for deep learning based automatic bone removal in medical images, such as computed tomography angiography (CTA) volumes, is disclosed. Bone structures are segmented in a 3D medical image of a patient by classifying voxels of the 3D medical image as bone or non-bone voxels using a deep neural network trained for bone segmentation. A 3D visualization of non-bone structures in the 3D medical image is generated by removing voxels classified as bone voxels from a 3D visualization of the 3D medical image.", "Deep Learning Based Bone Removal in Computed Tomography Angiography "]
[null, "Method and program for computing bone age by deep neural network "]
["Methods and apparatus for improved deep learning for image acquisition are provided. An imaging system configuration apparatus includes a training learning device including a first processor to implement a first deep learning network (DLN) to learn a first set of imaging system configuration parameters based on a first set of inputs from a plurality of prior image acquisitions to configure at least one imaging system for image acquisition, the training learning device to receive and process feedback including operational data from the plurality of image acquisitions by the at least one imaging system. The example apparatus includes a deployed learning device including a second processor to implement a second DLN, the second DLN generated from the first DLN of the training learning device, the deployed learning device configured to provide a second imaging system configuration parameter to the imaging system in response to receiving a second input for image acquisition.", "Deep learning medical systems and methods for image acquisition "]
[null, "Deep-convolution-neural-network-based CT pulmonary nodule detection method "]
["Approaches provide for identifying text represented in image data as well as determining a location or region of the image data that includes the text represented in the image data. For example, a camera of a computing device can be used to capture a live camera view of one or more items. The live camera view can be presented to the user on a display screen of the computing device. An application executing on the computing device or at least in communication with the computing device can analyze the image data of the live camera view to identify text represented in the image data as well as determine locations or regions of the image that include the representations. For example, one such recognition approach includes a region proposal process to generate a plurality of candidate bounding boxes, a region filtering process to determine a subset of the plurality of candidate bounding boxes, a region refining process to refine the bounding box coordinates to more accurately fit the identified text, a text recognizer process to recognize words in the refined bounding boxes, and a post-processing process to suppress overlapping bounding boxes to generate a final set of bounding boxes.", "Text recognition and localization with deep learning "]
["Method for performing speech enhancement using a Deep Neural Network (DNN)-based signal starts with training DNN offline by exciting a microphone using target training signal that includes signal approximation of clean speech. Loudspeaker is driven with a reference signal and outputs loudspeaker signal. Microphone then generates microphone signal based on at least one of: near-end speaker signal, ambient noise signal, or loudspeaker signal. Acoustic-echo-canceller (AEC) generates AEC echo-cancelled signal based on reference signal and microphone signal. Loudspeaker signal estimator generates estimated loudspeaker signal based on microphone signal and AEC echo-cancelled signal. DNN receives microphone signal, reference signal, AEC echo-cancelled signal, and estimated loudspeaker signal and generates a speech reference signal that includes signal statistics for residual echo or for noise. Noise suppressor generates a clean speech signal by suppressing noise or residual echo in the microphone signal based on speech reference signal. Other embodiments are described.", "System and method for performing speech enhancement using a deep neural network-based signal "]
["A method for personalized intelligent wake-up system based on multimodal deep neural network comprises monitoring a sleeping status of a user; obtaining a current sleeping-stage of the user within a current time frame and a prediction of a next sleeping-stage of the user for a next time frame; correcting the current sleeping-stage of the user through combining the current sleeping-stage and the prediction of the next sleeping-stage; determining a wake up strategy for the current time frame; determining a relationship between each of a plurality of alarm impulses adopted to wake up the user and a corresponding reaction of the user; identifying a change in the current sleeping-stage for the current time frame; determining an alarm impulse to be triggered for waking up the user; and triggering the determined alarm impulse.", "Personalized intelligent wake-up system and method based on multimodal deep neural network "]
[null, "Ensemble of Jointly Trained Deep Neural Network-based Acoustic Models for Reverberant Speech Recognition and Method for Recognizing Speech using the same "]
[null, "Image quality testing method based on deep convolutional neural network "]
[null, "System, method and program for analyzing blood flow by deep neural network "]
["A method is provided for training a Deep Neural Network (DNN) for acoustic modeling in speech recognition. The method includes reading central frames and side frames as input frames from a memory. The side frames are preceding side frames preceding the central frames and/or succeeding side frames succeeding the central frames. The method further includes executing pre-training for only the central frames or both the central frames and the side frames and fine-tuning for the central frames and the side frames so as to emphasize connections between acoustic features in the central frames and units of the bottom layer in hidden layer of the DNN.", "Training deep neural network for acoustic modeling in speech recognition "]
[null, "Deep learning system and learning method using of convolutional neural network based image patterning "]
[null, "Method of estimating coagulant injection rate in water treatment using deep neural network "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for correcting a corrupted data sample using a trained deep neural network, the method including obtaining a feature representation of a corrupted data sample; and modifying the feature representation of the corrupted data sample to generate a feature representation of a corrected data sample by iteratively processing a current version of the feature representation of the corrupted data sample using the trained deep neural network to generate a current corruption score for the current version of the feature representation of the corrupted data sample and generating a less-corrupted version of the feature representation by performing an iteration of gradient descent against the current version of the feature representation of the corrupted data sample to reduce the current corruption score.", "Artifact correction using neural networks "]
["A speech recognition apparatus based on a deep-neural-network (DNN) sound model includes a memory and a processor. As the processor executes a program stored in the memory, the processor generates sound-model state sets corresponding to a plurality of pieces of set training speech data included in multi-set training speech data, generates a multi-set state cluster from the sound-model state sets, and sets the multi-set training speech data as an input node and the multi-set state cluster as output nodes so as to learn a DNN structured parameter.", "Apparatus and method for recognizing speech based on a deep-neural-network (DNN) sound model "]
[null, "Method and apparatus for localizing sound source using deep learning "]
[null, "diagnostics system for cell using Deep Neural Network learning "]
["Interactive visualizations of a convolutional neural network are provided. For example, a graphical user interface (GUI) can include a matrix having symbols indicating feature-map values that represent likelihoods of particular features being present or absent at various locations in an input to a convolutional neural network. Each column in the matrix can have feature-map values generated by convolving the input to the convolutional neural network with a respective filter for identifying a particular feature in the input. The GUI can detect, via an input device, an interaction indicating that that the columns in the matrix are to be combined into a particular number of groups. Based on the interaction, the columns can be clustered into the particular number of groups using a clustering method. The matrix in the GUI can then be updated to visually represent each respective group of columns as a single column of symbols within the matrix.", "Interactive visualizations of a convolutional neural network "]
["Embodiments of an adaptive virtual intelligent agent (\u201cAVIA\u201d) service are disclosed. It may include the functions of a human administrative assistant for an enterprise including customer support, customer relationship management, and fielding incoming caller inquiries. It also has multi-modal applications for the home through interaction with AVIA implemented in the home. It may engage in free-form natural language dialogs. During a dialog, embodiments maintain the context and meaning of the ongoing dialog and provides information and services as needed by the domain of the application. Over time, the service automatically extends its knowledge of the domain (as represented in the Knowledge Tree Graphs) through interaction with external resources. Embodiments can intelligently understand and converse with users using free-form speech without pre-programmed deterministic sequences of questions and answers, can dynamically determine what it needs to know to converse meaningfully with users, and knows how to obtain information it needs.", "Adaptive Virtual Intelligent Agent "]
[null, "Method and device for reconstructing 3d face using neural network "]
[null, "Unmanned aerial vehicle flight control system and method using deep learning "]
["Systems and methods for providing convolutional neural network based image synthesis using localized loss functions is disclosed. A first image including desired content and a second image including a desired style are received. The images are analyzed to determine a local loss function. The first and second images are merged using the local loss function to generate an image that includes the desired content presented in the desired style. Similar processes can also be utilized to generate image hybrids and to perform on-model texture synthesis. In a number of embodiments, Condensed Feature Extraction Networks are also generated using a convolutional neural network previously trained to perform image classification, where the Condensed Feature Extraction Networks approximates intermediate neural activations of the convolutional neural network utilized during training.", "Systems and methods for providing convolutional neural network based image synthesis using stable and controllable parametric models, a multiscale synthesis framework and novel network architectures "]
[null, "Voice Activity Detection based on Deep Neural Network Using EVS Codec Parameter and Voice Activity Detection Method thereof "]
[null, "Dual-Microphone Voice Activity Detection Based on Deep Neural Network and Method thereof "]
[null, "A deep learning based image recognition method for CCTV "]
[null, "Voiced/Unvoiced Decision Method Using Deep Neural Network for Linear Predictive Coding-10e Vocoder "]
[null, "Method and apparatus of exploiting sparse activation in neural networks to reduce power consumption of synchronous integrated circuits "]
[null, "Differential classification with multiple neural networks "]
["In an approach to incident prediction and response, one or more computer processors receive one or more alerts corresponding to an incident. The one or more computer processors aggregate the one or more alerts with additional data corresponding to the incident. The one or more computer processors feed the aggregated data into a prediction model, where training of the prediction model uses associated independent stacked Restricted Boltzmann Machines utilizing one or more supervised methods and one or more unsupervised methods. The one or more computer processors determine, based, at least in part, on one or more calculations by the prediction model, at least one probability of the incident. The one or more computer processors determine whether the at least one probability exceeds a pre-defined threshold. In response to determining the at least one probability exceeds a pre-defined threshold, the one or more computer processors send at least one notification.", "Incident prediction and response using deep learning techniques and multimodal data "]
[null, "Search-by-image system based on convolutional neural network "]
["This disclosure describes systems and method for implementing a multi-view deep learning framework to map users and items to a latent space and determine similarities between users and preferred items. The multi-view deep learning framework can extract features from a domain space based at least in part on having an adequate interaction history to learn relevant user behavior patterns. The deep learning framework may leverage the learned user behavior patterns across multiple domain spaces to provide useful recommendations related to different domain spaces, including domain spaces of which a user has had little or no previous interaction. Example domain spaces include, but are not limited to, search engines, computing device applications, games, informational services, movie services, music services, and reading services.", "User recommendation using a multi-view deep learning framework "]
["A method of quantizing a floating point machine learning network to obtain a fixed point machine learning network using a quantizer may include selecting at least one moment of an input distribution of the floating point machine learning network. The method may also include determining quantizer parameters for quantizing values of the floating point machine learning network based at least in part on the at least one selected moment of the input distribution of the floating point machine learning network to obtain corresponding values of the fixed point machine learning network.", "Fixed point neural network based on floating point neural network quantization "]
["Methods and systems for training a neural network include pre-training a bi-linear, tensor-based network, separately pre-training an auto-encoder, and training the bi-linear, tensor-based network and auto-encoder jointly. Pre-training the bi-linear, tensor-based network includes calculating high-order interactions between an input and a transformation to determine a preliminary network output and minimizing a loss function to pre-train network parameters. Pre-training the auto-encoder includes calculating high-order interactions of a corrupted real network output, determining an auto-encoder output using high-order interactions of the corrupted real network output, and minimizing a loss function to pre-train auto-encoder parameters.", "Deep learning model for structured outputs with high-order interaction "]
["A system and method that identifies an object and a viewpoint from an image with a probability that satisfies a predefined criterion is described. An active view planning application receives a first image, performs recognition on the first image to determine an object, a viewpoint and a probability of recognition, determines a first expected gain in the probability of recognition when a first action is taken and a second expected gain in the probability of recognition when a second action is taken, and identifies a next action from the first action and the second action based on an increase in expected gains.", "Active view planning by deep learning "]
["A method for configuring a neural network is provided. The method includes: selecting a neural network including a plurality of layers, each of the layers including a plurality of neurons for processing an input and providing an output; and, incorporating at least one switch configured to randomly select and disable at least a portion of the neurons in each layer. Another method in the computer program product is disclosed.", "Method and apparatus of learning neural network via hierarchical ensemble learning "]
["A method and a system generate a time-series signal indicative of a variation of the environment in vicinity of the vehicle with respect to a motion of the vehicle and submit the time-series signal to the neural network to produce a reference trajectory as a function of time that satisfies time and spatial constraints on a position of the vehicle. The neural network is trained in to transform time-series signals to reference trajectories of the vehicle. The motion trajectory tracking the reference trajectory while satisfying constraints on the motion of the vehicle is determined and the motion of the vehicle is controlled to follow the motion trajectory.", "System and method for controlling vehicle using neural network "]
["The present invention is directed to systems and methods for detecting objects in a radar image stream. Embodiments of the invention can receive a data stream from radar sensors and use a deep neural network to convert the received data stream into a set of semantic labels, where each semantic label corresponds to an object in the radar data stream that the deep neural network has identified. Processing units running the deep neural network may be collocated onboard an airborne vehicle along with the radar sensor(s). The processing units can be configured with powerful, high-speed graphics processing units or field-programmable gate arrays that are low in size, weight, and power requirements. Embodiments of the invention are also directed to providing innovative advances to object recognition training systems that utilize a detector and an object recognition cascade to analyze radar image streams in real time. The object recognition cascade can comprise at least one recognizer that receives a non-background stream of image patches from a detector and automatically assigns one or more semantic labels to each non-background image patch. In some embodiments, a separate recognizer for the background analysis of patches may also be incorporated. There may be multiple detectors and multiple recognizers, depending on the design of the cascade. Embodiments of the invention also include novel methods to tailor deep neural network algorithms to successfully process radar imagery, utilizing techniques such as normalization, sampling, data augmentation, foveation, cascade architectures, and label harmonization.", "Systems and methods for recognizing objects in radar imagery "]
["A method of transfer learning includes receiving second data and generating, via a first network, second labels for the second data. In one configuration, the first network has been previously trained on first labels for first data. Additionally, the second labels are generated for training a second network.", "Transfer learning in neural networks "]
["A neural network model, such as a deep neural network (DNN), is trained using many speech examples to perform beam selection in a microphone array-based speech processing system. The DNN is trained using many different speech examples that are labeled with position or direction information relative to a training microphone array. The DNN may then be trained to recognize a direction of incoming speech so that at runtime the trained DNN may process input audio data from a microphone array and may output to a beam selector an indicator of the desired beam that may be selected for further processing. The DNN may be configured to output a beam index and/or coordinates (or other position data) corresponding to an estimated location of the detected speech. The DNN may also be configured to output acoustic unit data corresponding to speech units (for example corresponding to phonemes, senons, etc. such as those of a detected wakeword or other word).", "Neural network based beam selection "]
["The present disclosure provides an image capture, curation, and editing system that includes a resource-efficient mobile image capture device that continuously captures images. The mobile image capture device is operable to input an image into at least one neural network and to receive at least one descriptor of the desirability of a scene depicted by the image as an output of the at least one neural network. The mobile image capture device is operable to determine, based at least in part on the at least one descriptor of the desirability of the scene of the image, whether to store a second copy of such image in a non-volatile memory of the mobile image capture device or to discard a first copy of such image from a temporary image buffer without storing the second copy of such image in the non-volatile memory.", "Systems and methods that leverage deep learning to selectively store images at a mobile image capture device "]
[null, "Neural network circuit device, a neural network, the neural network processing method and a neural network executing program "]
["Techniques and constructs can reduce the time required to determine solutions to optimization problems such as training of neural networks. Modifications to a computational model can be determined by a plurality of nodes operating in parallel. Quantized modification values can be transmitted between the nodes to reduce the volume of data to be transferred. The quantized values can be as small as one bit each. Quantization-error values can be stored and used in quantizing subsequent modifications. The nodes can operate in parallel and overlap computation and data transfer to further reduce the time required to determine solutions. The quantized values can be partitioned and each node can aggregate values for a corresponding partition.", "Computing system for training neural networks "]
["Electronic communications can be normalized using a neural network. For example, a noncanonical communication that includes multiple terms can be received. The noncanonical communication can be preprocessed by (I) generating a vector including multiple characters from a term of the multiple terms; and (II) repeating a substring of the term in the vector such that a last character of the substring is positioned in a last position in the vector. The vector can be transmitted to a neural network configured to receive the vector and generate multiple probabilities based on the vector. A normalized version of the noncanonical communication can be determined using one or more of the multiple probabilities generated by the neural network. Whether the normalized version of the noncanonical communication should be outputted can also be determined using at least one of the multiple probabilities generated by the neural network.", "Normalizing electronic communications using a neural network "]
["Methods and systems for training a neural network are provided. One system includes one or more components executed by one or more computer subsystems. The one or more components include a neural network configured for determining inverted features of input images in a training set for a specimen input to the neural network, a forward physical model configured for reconstructing the input images from the inverted features thereby generating a set of output images corresponding to the input images in the training set, and a residue layer configured for determining differences between the input images in the training set and their corresponding output images in the set. The one or more computer subsystems are configured for altering one or more parameters of the neural network based on the determined differences thereby training the neural network.", "Systems and methods incorporating a neural network and a forward physical model for semiconductor applications "]
[null, "Deepening controlling method of underactuated automatic underwater vehicle based on neural network back stepping method "]
["Systems and methods for training a neural network to optimize network performance, including sampling an applied dropout rate for one or more nodes of the network to evaluate a current generalization performance of one or more training models. An optimized annealing schedule may be generated based on the sampling, wherein the optimized annealing schedule includes an altered dropout rate configured to improve a generalization performance of the network. A number of nodes of the network may be adjusted in accordance with a dropout rate specified in the optimized annealing schedule. The steps may then be iterated until the generalization performance of the network is maximized.", "Annealed dropout training of neural networks "]
["Hierarchical branching deep convolutional neural networks (HD-CNNs) improve existing convolutional neural network (CNN) technology. In a HD-CNN, classes that can be easily distinguished are classified in a higher layer coarse category CNN, while the most difficult classifications are done on lower layer fine category CNNs. Multinomial logistic loss and a novel temporal sparsity penalty may be used in HD-CNN training. The use of multinomial logistic loss and a temporal sparsity penalty causes each branching component to deal with distinct subsets of categories.", "Hierarchical deep convolutional neural network for image classification "]
[null, "Configuration of a sensor system with a neural network for a motor vehicle "]
["An artificial neural network, ANN, and method of training the ANN for inversion of logging tool signals into well logs of formation parameters is disclosed. Properly selected synthetic models of earth formations are used to train the ANN. The models include Oklahoma and chirp type of formations. In each model parameter contrasts of from 10 to 1 to about 100 to 1 are included. Models including maximum and minimum parameter values spanning the operating range of the selected logging tool are included. Parameter contrasts at interfaces are limited to realistic values found in earth formations. The selected models are used to generate synthetic tool signals, which are then used as inputs to the ANN for training. When the ANN coefficients are properly adjusted to produce an output matching the original models, the ANN can be used for inversion of any real signals from the selected logging tool.", "Processing well logging data with neural network "]
["A method of reducing computational complexity for a fixed point neural network operating in a system having a limited bit width in a multiplier-accumulator (MAC) includes reducing a number of bit shift operations when computing activations in the fixed point neural network. The method also includes balancing an amount of quantization error and an overflow error when computing activations in the fixed point neural network.", "Reduced computational complexity for fixed point neural network "]
["A client device configured with a neural network includes a processor, a memory, a user interface, a communications interface, a power supply and an input device, wherein the memory includes a trained neural network received from a server system that has trained and configured the neural network for the client device. A server system and a method of training a neural network are disclosed.", "Object recognition with reduced neural network weight precision "]
["An application provisioning system and method. A server provides an application provisioning service. A user of a client provides a schema defining an application. The application interacts with peripherals coupled to the client and receives input from sensors coupled to the peripherals. The sensor data is provided to the server for processing, including by neural networks. The application includes a workflow defining a finite state machine that traverses states at least partially based on the response to sensor data. The server may provide dynamic reallocation of compute resources to resolve demand for classifier training job requests; use of jurisdictional certificates to define data usage and sharing; and data fusion. Applications include manufacturing verification, medical diagnosis and treatment, genomics and viral detection.", "System and method for network based application development and implementation "]
["A knowledge graph is traversed by receiving a knowledge graph at a deep neural network, the knowledge graph including a plurality of nodes connected by a plurality of edges, each respective edge of the plurality of edges being associated with a corresponding distance representing embedded semantic information. The deep neural network is trained to capture the embedded semantic information. A path query is received at the deep neural network. A context is determined for the received path query at the deep neural network. The deep neural network performs the traversing of the knowledge graph in response to the received path query, based upon the determined context and the embedded semantic information.", "Determining context-aware distances using deep neural networks "]
["Deep machine learning methods and apparatus related to manipulation of an object by an end effector of a robot. Some implementations relate to training a deep neural network to predict a measure that candidate motion data for an end effector of a robot will result in a successful grasp of one or more objects by the end effector. Some implementations are directed to utilization of the trained deep neural network to servo a grasping end effector of a robot to achieve a successful grasp of an object by the grasping end effector. For example, the trained deep neural network may be utilized in the iterative updating of motion control commands for one or more actuators of a robot that control the pose of a grasping end effector of the robot, and to determine when to generate grasping control commands to effectuate an attempted grasp by the grasping end effector.", "Deep machine learning methods and apparatus for robotic grasping "]
[null, "SAR image terrain classification method based on depth RBF network "]
["A deep structured semantic module (DSSM) is described herein which uses a model that is discriminatively trained based on click-through data, e.g., such that a conditional likelihood of clicked documents, given respective queries, is maximized, and a condition likelihood of non-clicked documents, given the queries, is reduced. In operation, after training is complete, the DSSM maps an input item into an output item expressed in a semantic space, using the trained model. To facilitate training and runtime operation, a dimensionality-reduction module (DRM) can reduce the dimensionality of the input item that is fed to the DSSM. A search engine may use the above-summarized functionality to convert a query and a plurality of documents into the common semantic space, and then determine the similarity between the query and documents in the semantic space. The search engine may then rank the documents based, at least in part, on the similarity measures.", "Deep Structured Semantic Model Produced Using Click-Through Data "]
["Methods and apparatus for extending a neural network, reducing its dimension and processing input data are provided. The method of extending a neural network involves selecting, with a processor, a node of a neural network, adding a new node in a layer that includes the selected node, and setting connection weights of the new node based on connection weights of the selected node.", "Method and apparatus for extending neural network "]
["Deep Neural Networks (DNN) are time shifted relative to one another and trained. The time-shifted networks may then be combined to improve recognition accuracy. The approach is based on an automatic speech recognition (ASR) system using DNN and using time shifted features. Initially, a regular ASR model is trained to produce a first trained DNN. Then a top layer (e.g., SoftMax layer) and the last hidden layer (e.g., Sigmoid) are fine-tuned with same data set but with a feature window left- and right-shifted to create respective second and third left-shifted and right-shifted DNNs. From these three DNN networks, four combination networks may be generated: left- and right-shifted, left-shifted and centered, centered and right-shifted, and left-shifted, centered, and right-shifted. The centered networks are used to perform the initial (first-pass) ASR. Then the other six networks are used to perform rescoring. The resulting are combined using ROVER (recognizer output voting error reduction) or another technique to improve recognition performance as compared to the centered DNN by itself", "Centered, left- and right-shifted deep neural networks and their combinations "]
[null, "Neural Networks for selecting to be performed by a robot Agent Actions "]
["A method, system and computer program product for accelerating a deep neural network (DNN) in a field-programmable gate array (FPGA) are disclosed. The method includes receiving a DNN net file and weights, converting the received DNN net file to one or more source files, generating an executable FPGA bit file using the one or more source files, and downloading the executable FPGA bit file from the DNN conversion platform to the FPGA. Converting of the received DNN net file and the weights to the one or more source files can further include analyzing the DNN net file to identify a plurality of neural layers, decomposing one or more neural layers of the plurality of neural layers to one or more operation blocks, instantiating the one or more source files, based on the one or more operation blocks.", "Accelerate deep neural network in an fpga "]
["In one aspect, an example method includes a processor (1) applying a feature map network to an image to create a feature map comprising a grid of vectors characterizing at least one feature in the image and (2) applying a probability map network to the feature map to create a probability map assigning a probability to the at least one feature in the image, where the assigned probability corresponds to a likelihood that the at least one feature is an overlay. The method further includes the processor determining that the probability exceeds a threshold, and responsive to the processor determining that the probability exceeds the threshold, performing a processing action associated with the at least one feature.", "Recurrent Deep Neural Network System for Detecting Overlays in Images "]
["A neural network is structured with a plurality of levels of nodes. Each level has a level-specific stabilization parameter that adjusts a learning rate, at a corresponding level, during training.", "Self-stabilized deep neural network "]
["Techniques for training a deep neural network from user interaction workflow activities occurring among distributed computing devices are disclosed herein. In an example, processing of input data (such as input medical imaging data) is performed at a client computing device with the execution of an algorithm of a deep neural network. A set of updated training parameters are generated to update the algorithm of the deep neural network, based on user interaction activities (such as user acceptance and user modification in a graphical user interface) that occur with the results of the executed algorithm. The generation and collection of the updated training parameters at a server, received from a plurality of distributed client sites, can be used to refine, improve, and train the algorithm of the deep neural network for subsequent processing and execution.", "Distributed clinical workflow training of deep learning neural networks "]
["A computer-implemented method of creating a modified Deep Neural Network-DNN-comprises: carrying out a parallelization process to allocate computational and memory requirements of a selected layer or set of layers of the DNN across more than one computer process. The parallelization process comprises: selecting the number of computer processes to be used to execute the selected layer(s); determining if the selected number of computer processes is the same as the number of selected layers and, in dependence upon the result of the determination, assigning the selected layer(s) to the computer processes in accordance with a predetermined protocol; and modifying the DNN by: creating and adding to the DNN a first additional layer, to distribute input data from the selected layer(s) to the computer processes, and a second additional layer, to collate and combine output data from the computer processes; and setting connections between the first and second additional layers and the selected layer(s) in the DNN so as to arrange for parallel execution of the selected layer(s) by the computer processes.", "Method and apparatus for parallelizing layers of deep neural networks onto parallel computing systems "]
["In accordance with an example embodiment of the present invention, a method comprising: obtaining a plurality of training samples; employing a set of activation functions on a plurality of layers of a deep neural network, wherein the set of activation functions varies with the plurality of layers; and applying the activation functions on the plurality of training samples.", "Diverse activation functions for deep neural networks "]
["The technology disclosed proposes a novel asynchronous evaluation strategy (AES) that increases throughput of evolutionary algorithms by continuously maintaining a queue of K individuals ready to be sent to the worker nodes for evaluation and evolving the next generation once a fraction Mi of the K individuals have been evaluated by the worker nodes, where Mi<<K. A suitable value for Mi is determined experimentally, balancing diversity and efficiency. The technology disclosed is extended to coevolution of deep neural network supermodules and blueprints in the form of AES for cooperative evolution of deep neural networks (CoDeepNEAT-AES). Applied to image captioning domain, a threefold speedup is observed on 200 graphics processing unit (GPU) worker nodes, demonstrating that the disclosed AES and CoDeepNEAT-AES are promising techniques for evolving complex systems with long and variable evaluation times.", "Asynchronous Evaluation Strategy For Evolution Of Deep Neural Networks "]
["Methods and systems are provided for detecting and cataloging qualities in music. While both the data volume and heterogeneity of the digital music content is huge, it has become increasingly important and convenient to build a recommendation or search system to facilitate surfacing these content to the user or consumer community. Embodiments use deep convolutional neural network to imitate how human brain processes hierarchical structures in the auditory signals, such as music, speech, etc., at various timescales. This approach can be used to discover the latent factor models of the music based upon acoustic hyper-images that are extracted from the raw audio waves of music. These latent embeddings can be used either as features to feed to subsequent models, such as collaborative filtering, or to build similarity metrics between songs, or to classify music based on the labels for training such as genre, mood, sentiment, etc.", "Modeling of the latent embedding of music using deep neural network "]
["An apparatus and method are described for reducing the parameter density of a deep neural network (DNN). A layer-wise pruning module to prune a specified set of parameters from each layer of a reference dense neural network model to generate a second neural network model having a relatively higher sparsity rate than the reference neural network model; a retraining module to retrain the second neural network model in accordance with a set of training data to generate a retrained second neural network model; and the retraining module to output the retrained second neural network model as a final neural network model if a target sparsity rate has been reached or to provide the retrained second neural network model to the layer-wise pruning model for additional pruning if the target sparsity rate has not been reached.", "Method and apparatus for reducing parameter density of deep neural network (dnn) "]
["The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a compression method considering load balance for deep neural networks and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks in an efficient way so as to improve utilization of resources of the hardware platform.", "Compression method for deep neural networks with load balance "]
["A method of biasing a deep neural network includes determining whether an element has an increased probability of being present in an input to the network. The method also includes adjusting a bias of activation functions of neurons in the network to increase sensitivity to the element. In one configuration, the bias is adjusted without adjusting weights of the network. The method further includes adjusting an output of the network based on the biasing.", "Incorporating top-down information in deep neural networks via the bias term "]
["The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a compression method for deep neural networks with proper use of mask and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks while maintaining or even improving the accuracy of the neural networks after compression.", "Compression of deep neural networks with proper use of mask "]
["A deep neural network may be trained on the data of one or more entities, also know as Alices. An outside computing entity, also known as a Bob, may assist in these computations, without receiving access to Alices' data. Data privacy may be preserved by employing a \u201csplit\u201d neural network. The network may comprise an Alice part and a Bob part. The Alice part may comprise at least three neural layers, and the Bob part may comprise at least two neural layers. When training on data of an Alice, that Alice may input her data into the Alice part, perform forward propagation though the Alice part, and then pass output activations for the final layer of the Alice part to Bob. Bob may then forward propagate through the Bob part. Similarly, backpropagation may proceed backwards through the Bob part, and then through the Alice part of the network.", "Secure Training of Multi-Party Deep Neural Network "]
["The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a multi-iteration compression method for deep neural networks and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks without degrading the accuracy of the neural", "Multi-iteration compression for deep neural networks "]
["The present invention concerns a method of programming an analogue electronic neural network (1) comprising a plurality of layers of somas (3). Any two consecutive layers of somas (3) are connected by a matrix of synapses (5). The method comprises: applying (a) test signals to inputs of the neural network (1); measuring (b) at a plurality of measurement locations in the neural network (1) responses of at least some somas (3) and synapses (5) to the test signals; extracting (b) from the neural network (1), based on the responses, a first parameter set characterising the behaviour of the at least some somas (3); carrying out (c) a training of the neural network (1) by applying to a training algorithm the first parameter set and training data for obtaining a second parameter set; and programming (d) the neural network (1) by using the second parameter set. The invention also relates to the neural network (1) and to a method of operating it.", "An analogue electronic deep neural network "]
["Systems, methods, and apparatus, including computer programs encoded on a computer storage medium, for selecting an actions from a set of actions to be performed by an agent interacting with an environment. In one aspect, the system includes a dueling deep neural network. The dueling deep neural network includes a value subnetwork, an advantage subnetwork, and a combining layer. The value subnetwork processes a representation of an observation to generate a value estimate. The advantage subnetwork processes the representation of the observation to generate an advantage estimate for each action in the set of actions. The combining layer combines the value estimate and the respective advantage estimate for each action to generate a respective Q value for the action. The system selects an action to be performed by the agent in response to the observation using the respective Q values for the actions in the set of actions.", "Dueling deep neural networks "]
["System and method for layer-wise training of deep neural networks (DNNs) are disclosed. In an embodiment, multiple labelled images are received at a layer of multiple layers of a DNN. Further, the labelled images are pre-processed. The pre-processed images are then transformed based on a predetermined weight matrix to obtain feature representation of the pre-processed images at the layer, the feature representation comprise feature vectors and associated labels. Furthermore, kernel similarity between the feature vectors is determined based on a predefined kernel function. Moreover, a Gaussian kernel matrix is determined based on the kernel similarity. In addition, an error function is computed based on the predetermined weight matrix and the Gaussian kernel matrix. Also, a weight matrix associated with the layer is computed based on the error function and predetermined weight matrix, thereby training the layer of the multiple layers.", "System and method for layer-wise training of deep neural networks "]
["A method for extracting a representation from an image includes inputting an image to a pre-trained neural network. The gradient of a loss function is computed with respect to parameters of the neural network, for the image. A gradient representation is extracted for the image based on the computed gradients, which can be used, for example, for classification or retrieval.", "Extracting gradient features from neural networks "]
["A method of creating a modified Deep Neural Network (DNN) comprises carrying out a transformation process to transform an existing DNN in which a selected layer of neurons of the existing DNN is removed from the DNN and replaced by N replacement layers of neurons. Each replacement layer comprising a different sub-set of the set of neurons of the selected layer such that the N replacement layers, and logical connections set between the N replacement layers and the remainder of the DNN, are in aggregate functionally equivalent within the DNN to the selected layer. A weight initialization process is then carried out to initialise the weights of the transformed DNN, in which weights are generated locally and independently for each replacement layer such that each replacement layer is defined by the same statistical profile as the selected layer, whereby the N replacement layers are in aggregate statistically equivalent within the DNN to the selected layer.", "Method and apparatus to distribute memory requirements of deep neural networks "]
["An approach of hybrid frame, phone, diphone, morpheme, and word-level Deep Neural Networks (DNN) in model training and applications is described. The approach can be applied to many applications. The approach is based on a regular ASR system, which can be based on Gaussian Mixture Models (GMM) or DNN. In the first step, a regular ASR model is trained. All the training data (in the format of features) are aligned with the transcripts in terms of phonemes and words with the timing information. Feature normalization can be applied for these new features. Based on the alignment timing information, new features are formed in terms of phonemes, diphones, morphemes, and up to words. A first pass regular speech recognition is performed, and the result lattice is produced. In the lattice, there is the timing information for each word. A feature is then extracted and sent to the word-level DNN for scoring. If the word is not in the word-level DNN vocabulary, then a forced alignment is performed to get the timing information for each phoneme. Then features from these phonemes, diphones, and morphemes are sent to the corresponding DNNs for training. And these scores are combined to form the word level scores. In this way, the lattice is rescored, and a new recognition result is produced.", "Hybrid phoneme, diphone, morpheme, and word-level deep neural networks "]
["Automatic scaling is performed on a floating point implementation of a DNN to perform scaling to a fixed point implementation. The DNN includes multiple layers in an order from a starting to an ending layer. The automatic scaling includes determining a scaling factor for each of multiple ones of the layers during training of the DNN. The scaling factor converts floating point numbers used for calculations in a layer into integer numbers to be used in the calculations. A scaling factor is determined for a selected layer, which is at a position in the order, based on scaling factors used in layers in the order prior to the position of the selected layer. The automatic scaling includes outputting the scaling factors for the multiple layers to be used for implementing the fixed point implementation of the DNN that uses integer calculations instead of floating point calculations.", "Automatic scaling for fixed point implementation of deep neural networks "]
["A simulation application receives simulation parameters associated with a simulation to be generated. The simulation parameters include geometry associated with the simulation and corresponding boundary conditions. The simulation engine processes the simulation parameters and then, using a neural network, generates a solution estimate. Based on the estimated solution, the simulation engine then executes a finite element analysis solver using the solution estimate as a starting point. The FEA solver iterates until a converged solution is reached. The converged solution is then provided to the end-user.", "Techniques for warm starting finite element analyses with deep neural networks "]
["The mirror deep neural networks (DNNs) as described herein recognize patterns in an input signal. Mirror DNNs regularize to a linear function and train very quickly. Mirror DNNs employ a neural network pattern recognizer that receives a set of features extracted from an input signal and inputs the set of features into a multi-layer neural network. The multi-layer neural network has an input layer that receives the set of features, a plurality of intermediate layers, and an output layer that generates a set of output values that are indicative of a recognized pattern exhibited in the input signal. A first and second non-linear equation pair are chosen and applied to intermediate layers of the neural network so as to make the output values that are indicative of a pattern exhibited in the input signal linear.", "Mirror deep neural networks that regularize to linear networks "]
["A method for generating three-dimensional facial models and photorealistic textures from inferences using deep neural networks relies upon generating a low frequency and a high frequency albedo map of the full and partial face, respectively. Then, the high frequency albedo map may be used for comparison with correlation matrices generated by a neural network trained by a large scale, high-resolution facial dataset with simulated partial visibility. The corresponding correlation matrices of the complete facial textures can then be retrieved. Finally, a full facial texture map may be synthesized, using convex combinations of the correlation matrices. A photorealistic facial texture for the three-dimensional face rendering can be obtained through optimization using the deep neural network and a loss function that incorporates the blended target correlation matrices.", "Photorealistic Facial Texture Inference Using Deep Neural Networks "]
["The technology disclosed proposes using a combination of computationally cheap, less-accurate bag of words (BoW) model and computationally expensive, more-accurate long short-term memory (LSTM) model to perform natural processing tasks such as sentiment analysis. The use of cheap, less-accurate BoW model is referred to herein as \u201cskimming\u201d. The use of expensive, more-accurate LSTM model is referred to herein as \u201creading\u201d. The technology disclosed presents a probability-based guider (PBG). PBG combines the use of BoW model and the LSTM model. PBG uses a probability thresholding strategy to determine, based on the results of the BoW model, whether to invoke the LSTM model for reliably classifying a sentence as positive or negative. The technology disclosed also presents a deep neural network-based decision network (DDN) that is trained to learn the relationship between the BoW model and the LSTM model and to invoke only one of the two models.", "Deep Neural Network-Based Decision Network "]
["Deep belief networks are usually associated with a large number of parameters and high computational complexity. The large number of parameters results in a long and computationally consuming training phase. According to at least one example embodiment, low-rank matrix factorization is used to approximate at least a first set of parameters, associated with an output layer, with a second and a third set of parameters. The total number of parameters in the second and third sets of parameters is smaller than the number of sets of parameters in the first set. An architecture of a resulting artificial neural network, when employing low-rank matrix factorization, may be characterized with a low-rank layer, not employing activation function(s), and defined by a relatively small number of nodes and the second set of parameters. By using low rank matrix factorization, training is faster, leading to rapid deployment of the respective system.", "Method and Apparatus of Processing Data Using Deep Belief Networks Employing Low-Rank Matrix Factorization "]
["A computing unit is disclosed, comprising a first memory bank for storing input activations and a second memory bank for storing parameters used in performing computations. The computing unit includes at least one cell comprising at least one multiply accumulate (\u201cMAC\u201d) operator that receives parameters from the second memory bank and performs computations. The computing unit further includes a first traversal unit that provides a control signal to the first memory bank to cause an input activation to be provided to a data bus accessible by the MAC operator. The computing unit performs one or more computations associated with at least one element of a data array, the one or more computations being performed by the MAC operator and comprising, in part, a multiply operation of the input activation received from the data bus and a parameter received from the second memory bank.", "Neural network compute tile "]
["A processing unit topology of a neural network including a plurality of processing units is determined. The neural network includes at least one machine in which each machine includes a plurality of nodes, and wherein each node includes at least one of the plurality of processing units. One or more of the processing units are grouped into a first group according to a first affinity. The first group is configured, using a processor and a memory, to use a first aggregation procedure for exchanging model parameters of a model of the neural network between the processing units of the first group. One or more of the processing units are grouped into a second group according to a second affinity. The second group is configured to use a second aggregation procedure for exchanging the model parameters between the processing units of the second group.", "Hybrid aggregation for deep learning neural networks "]
["The invention describes a method of training a deep neural network (N) to perform a specific image processing task, which method comprises the steps of extracting a plurality of pseudo-targets (101PS, ..., 105PS) from a non-annotated set (DBna) of medical images; performing supervised pre-training on an initialized network (Ninit) to obtain a pre-trained network (Npre) with a pseudo-task specific top layer (LPTS) ; replacing the pseudo-task specific layer (LPTS) by a task-specific layer (LTS); and performing supervised training on the pre-trained network (Npre) using an annotated set (DB) of medical images.", "Method of training a deep neural network "]
["According to one embodiment, a system includes a sensor component and a detection component. The sensor component is configured to obtain a plurality of sensor frames, wherein the plurality of sensor frames comprise a series of sensor frames captured over time. The detection component is configured to detect objects or features within a sensor frame using a neural network. The neural network comprises a recurrent connection that feeds forward an indication of an object detected in a first sensor frame into one or more layers of the neural network for a second, later sensor frame.", "Recurrent Deep Convolutional Neural Network For Object Detection "]
["A method for representing an input image includes the steps of applying a trained neural network on the input image, selecting a plurality of feature maps, determining a location of each of the plurality of feature maps in an image space of the input image, defining a plurality of interest points of the input image, and employing the plurality of interest points for representing the input image for performing a visual task. The plurality of feature maps are selected of an output of at least one selected layer of the trained neural network according to values attributed to the plurality of feature maps by the trained neural network. The plurality of interest points of the input image are defined based on the locations corresponding to the plurality of feature maps.", "Neural network image representation "]
["A method, computer readable medium, and system are disclosed for classifying video image data. The method includes the steps of processing training video image data by at least a first layer of a convolutional neural network (CNN) to extract a first set of feature maps and generate classification output data for the training video image data. Spatial classification accuracy data is computed based on the classification output data and target classification output data and spatial discrimination factors for the first layer are computed based on the spatial classification accuracies and the first set of feature maps.", "Fusing multilayer and multimodal deep neural networks for video classification "]
["The technology disclosed relates to evolving a deep neural network based solution to a provided problem. In particular, it relates to providing an improved cooperative evolution technique for deep neural network structures. It includes creating blueprint structures that include a plurality of supermodule structures. The supermodule structures include a plurality of modules. The modules are neural networks. A first loop of evolution executes at the blueprint level. A second loop of evolution executes at the supermodule level. Further, multiple mini-loops of evolution execute at each of the subpopulations of the supermodules. The first loop, the second loop, and the mini-loops execute in parallel.", "Cooperative evolution of deep neural network structures "]
["The inventors have developed a clinical decision support system (\u201cCDSS\u201d) and associated devices to diagnose chronic diseases in patients using a large number of biomarkers. The inventors have utilized a process for identifying thousands of biomarkers that could be relevant to potential diseases. Once these biomarkers are identified, the ones that have the most affinity for relevant biomarkers are retained. Then, a clinical decision support system can utilize the thousands of biomarkers, and apply a DNN based machine learning algorithm to diagnose chronic diseases.", "Clinical decision support system utilizing deep neural networks for diagnosis of chronic diseases "]
["A device, system, product and method of controlling resistive processing units (RPUs), includes applying an input voltage signal to each node of an array of resistive processing units, and controlling a learning rate of the array of resistive processing units by varying an amplitude of the input voltage signal to the array of resistive processing units. A conductance state of the array of resistive processing units is varied according to the amplitude received at each of the resistive processing units of the array of resistive processing units. The controlling of the amplitude of input voltage signal is according to a processor of a control device.", "Voltage control of learning rate for rpu devices for deep neural network training "]
["A system and method for processing speech includes receiving a first information stream associated with speech, the first information stream comprising micro-modulation features and receiving a second information stream associated with the speech, the second information stream comprising features. The method includes combining, via a non-linear multilayer perceptron, the first information stream and the second information stream to yield a third information stream. The system performs automatic speech recognition on the third information stream. The third information stream can also be used for training HMMs.", "System and method of using neural transforms of robust audio features for speech processing "]
["Method for assisting a driver to drive a vehicle or for driving a vehicle, the method comprising a learning phase and a driving phase, the learning phase comprising the steps of:\n- taking a series of pictures of followed path from a driver's point of view, during at least one journey where a vehicle is driven by a human driver,\n- recording during said at least one journey driving conditions including at least a steering angle and/or a vehicle acceleration,\n- for each picture taken in the series of pictures, linking to said picture the driving conditions recorded at the instant when said picture was taken,\n- supplying to a deep neural network said pictures and the linked driving conditions, to associate:\n- images and/or driving conditions at a given instant Ti and/or at a prior time,\nwith\n- driving conditions at a later instant than said given instant Ti.", "Driving prediction with a deep neural network "]
["A method for implementing spiking neural network computations, the method including defining a dynamic node response function that exhibits spikes, where spikes are temporal nonlinearities for representing state over time; defining a static representation of said node response function; and using the static representation of the node response function to train a neural network. A system for implementing the method is also disclosed.", "Methods and systems for implementing deep spiking neural networks "]
["A method and system for anatomical landmark detection in medical images using deep neural networks is disclosed. For each of a plurality of image patches centered at a respective one of a plurality of voxels in the medical image, a subset of voxels within the image patch is input to a trained deep neural network based on a predetermined sampling pattern. A location of a target landmark in the medical image is detected using the trained deep neural network based on the subset of voxels input to the trained deep neural network from each of the plurality of image patches.", "Method and system for landmark detection in medical images using deep neural networks "]
[null, "Neural networks based on the depth of the memristive device "]
["Input image data having a plurality of pixel values represented in a two-dimensional matrix form of columns and rows is received. The input image data is transformed into a plurality of input rows. The pixel values in each input row correspond to the pixel values in a predetermined subset of the columns of the input image data and all of the rows of each column of the subset of columns. A plurality of subsets of pixel values in the plurality of input rows is determined. The number of pixel values in each row of a subset of pixel values equal in number to a number of filter values in a filter. Each input row of each subset of pixel values is convolved with the filter values of the filter to determine a corresponding output value and stored in a memory.", "Memory efficient convolution operations in deep learning neural networks "]
["A method for generating synthetic behavior samples with a behavior generator includes drawing, at the behavior generator, a vector from a probability distribution obtained from behavior data of a plurality of users. The method also includes generating, with an artificial neural network decoder of the behavior generator, a synthetic behavior sample based on the vector. The method further includes tuning a model, which identifies a device user, using the generated synthetic behavior sample.", "Deep convolution neural network behavior generator "]
["A computer-implemented method according to one embodiment includes estimating a speaker dependent acoustic model utilizing test speech data and maximum likelihood linear regression (MLLR), transforming labeled speech data to create transformed speech data, utilizing the speaker dependent acoustic model and a linear transformation, and adjusting a deep neural network (DNN) acoustic model, utilizing the transformed speech data.", "Adjusting a deep neural network acoustic model "]
["In a data center, neural network evaluations can be included for services involving image or speech recognition by using a field programmable gate array (FPGA) or other parallel processor. The memory bandwidth limitations of providing weighted data sets from an external memory to the FPGA (or other parallel processor) can be managed by queuing up input data from the plurality of cores executing the services at the FPGA (or other parallel processor) in batches of at least two feature vectors. The at least two feature vectors can be at least two observation vectors from a same data stream or from different data streams. The FPGA (or other parallel processor) can then act on the batch of data for each loading of the weighted datasets.", "Memory bandwidth management for deep learning applications "]
["Systems and methods for obtaining vehicle operational data and driving context data from one or more monitoring systems, including converting the obtained vehicle operational data and driving context data into sequential vehicle operational feature data and sequential driving context feature data, calibrating the sequential vehicle operational feature data and the sequential driving context feature data temporally to form calibrated sequential vehicle operational feature data and calibrated sequential driving context feature data, constructing a sequence table of temporal sample points based on the calibrated sequential vehicle operational feature data and the calibrated sequential driving context feature data, feeding the sequence table into a deep neural network model for applying network learning to form a trained deep neural network model, extracting driving behavior features from the trained deep neural network model and analyzing the extracted driving behavior features to determine driving behavior characteristics of the driver.", "Method of effective driving behavior extraction using deep learning "]
["A method for creating an interpretable model for healthcare predictions includes training, by a deep learning processor, a neural network to predict health information by providing training data, including multiple combinations of measured or observed health metrics and corresponding medical results, to the neural network. The method also includes determining, by the deep learning processor and using the neural network, prediction data including predicted results for the measured or observed health metrics for each of the multiple combinations of the measured or observed health metrics based on the training data. The method also includes training, by the deep learning processor or a learning processor, an interpretable machine learning model to make similar predictions as the neural network by providing mimic data, including combinations of the measured or observed health metrics and corresponding predicted results of the prediction data, to the interpretable machine learning model.", "Interpretable deep learning framework for mining and predictive modeling of health care data "]
[null, "Construction Method and system for depth neural networks for speech recognition "]
[null, "A traffic sign recognition method asymmetric convolutional neural network "]
["A computer-implemented method of recognizing dental information associated with a dental model of dentition includes training a deep neural network to map a plurality of training dental models representing at least a portion of each one of a plurality of patients' dentitions to a probability vector including probability of the at least a portion of the dentition belonging to each one of a set of multiple categories. The category of the at least a portion of the dentition represented by the training dental model corresponds to the highest probability in the probability vector. The method includes receiving a dental model representing at least a portion of a patient's dentition and recognizing dental information associated with the dental model by applying the trained deep neural network to determine a category of the at least a portion of the patient's dentition represented by the received dental model.", "Dental cad automation using deep learning "]
["The present disclosure provides an improved approach to implement structure learning of neural networks by exploiting correlations in the data/problem the networks aim to solve. A greedy approach is described that finds bottlenecks of information gain from the bottom convolutional layers all the way to the fully connected layers. Rather than simply making the architecture deeper, additional computation and capacitance is only added where it is required.", "Structure learning in convolutional neural networks "]
["In social data networks, it is difficult for a computing system to automatically identify demographic attributes associated with user accounts because of incorrect, incomplete or non-existent data associated with the user account profile. Therefore, a computing system is provided that retrieves user account data and related text data, and that uses Deep Learning computations to infer demographic attributes about a given user based on the text data that they generate. The text is processed, and then inputted into a bi-gram neural network to generate an initial feature vector. This initial feature vector is inputted into a Deep Learning neural network in order to generate a secondary feature vector. The secondary feature vector is inputted into a forward neural network to generate one or more values indicating a specific demographic attribute associated with the given user account.", "Computing System for Inferring Demographics Using Deep Learning Computations and Social Proximity on a Social Data Network "]
["Technologies for machine learning with convolutional neural networks (CNNs) and support vector machines (SVMs) include a computing device that may train a deep CNN on a training data set to recognize features of the training data set. The computing device processes the training data set with the CNN after training to extract feature vectors. The computing device trains a multiclass SVM on the feature vectors. The computing device may train a CNN on a training data set to classify the training data set. After training, the computing device may exchange a layer of the CNN with a multiclass SVM. The computing device may use the weights of the exchanged layer to generate the SVM. The computing device may convert the multiclass SVM to a series of binary SVMs. The computing device may generate a reduced set model for each of the binary SVMs. Other embodiments are described and claimed.", "Technologies for deep machine learning with convolutional neural networks and reduced set support vector machines "]
["Operations of computing devices are managed using one or more deep neural networks (DNNs), which may receive, as DNN inputs, data from sensors, instructions executed by processors, and/or outputs of other DNNs. One or more DNNs, which may be generative, can be applied to the DNN inputs to generate DNN outputs based on relationships between DNN inputs. The DNNs may include DNN parameters learned using one or more computing workloads. The DNN outputs may be, for example, control signals for managing operations of computing devices, predictions for use in generating control signals, warnings indicating an acceptable state is predicted, and/or inputs to one or more neural networks. The signals enhance performance, efficiency, and/or security of one or more of the computing devices. DNNs can be dynamically trained to personalize operations by updating DNN weights or other parameters.", "Systems and methods for optimizing operations of computing devices using deep neural networks "]
["Aspects of the present disclosure describe techniques for training a convolutional neural network using an inconsistent stochastic gradient descent (ISGD) algorithm. Training effort for training batches used by the ISGD algorithm are dynamically adjusted according to a determined loss for a given training batch which are classified into two sub states\u2014well-trained or under-trained. The ISGD algorithm provides more iterations for under-trained batches while reducing iterations for well-trained ones.", "Accelerating deep neural network training with inconsistent stochastic gradient descent "]
["Convolutional neural networks can be visualized. For example, a graphical user interface (GUI) can include a matrix of symbols indicating feature-map values that represent a likelihood of a particular feature being present or absent in an input to a convolutional neural network. The GUI can also include a node-link diagram representing a feed forward neural network that forms part of the convolutional neural network. The node-link diagram can include a first row of symbols representing an input layer to the feed forward neural network, a second row of symbols representing a hidden layer of the feed forward neural network, and a third row of symbols representing an output layer of the feed forward neural network. Lines between the rows of symbols can represent connections between nodes in the input layer, the hidden layer, and the output layer of the feed forward neural network.", "Visualizing convolutional neural networks "]
["The disclosed system incorporates a new learning module, the Learning Kernel Activation Module (LKAM), at least serving the purpose of enforcing the utilization of less convolutional kernels by learning kernel activation rules and by actually controlling the engagement of various computing elements: The exemplary module activates/deactivates a sub-set of filtering kernels, groups of kernels, or groups of full connected neurons, during the inference phase, on-the-fly for every input image depending on the input image content and the learned activation rules.", "Parsimonious inference on convolutional neural networks "]
["The technology disclosed provides a so-called \u201cjoint many-task neural network model\u201d to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called \u201csuccessive regularization\u201d technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.", "Deep Neural Network Model for Processing Data Through Mutliple Linguistic Task Hiearchies "]
["Disclosed are systems and methods for image segmentation using convolutional networks. Image data comprising an image hypervolume can be received. The image hypervolume can be provided to a trained convolutional neural network (CNN). The CNN can output a segmentation of the image hypervolume.", "System And Method For N-Dimensional Image Segmentation Using Convolutional Neural Networks "]
[null, "Cell -phone cell convolutional neural network accelerator "]
["A system for providing a personalized recommendation of products or services to a user includes at least one user communication device, at least one seller communication device, at least one server configured to communicate with the at least one user communication device and the at least one seller communication device, a memory containing machine readable medium comprising machine executable code having stored thereon instructions for tracking the movements of the at least one object, and a control system comprising at least one processor coupled to the memory, the control system configured to execute the machine executable code to cause the control system to receive at least one image or at least one video pertaining to a products/services from sellers, extract metrics from the at least one image or the at least one video received from the seller, receive at least one image or at least one video from the user, extract metrics from the at least one image or the at least one video received from the user, match the metrics extracted from the at least one image or the at least one video received from the seller with the metrics extracted from the at least one image or the at least one video, rank the product/service based on the match results, and provide recommendation to the user based on the rank.", "Methods, apparatuses and systems for computer vision and deep learning "]
[null, "Metal coins based on depth identification method and apparatus Neural Network "]
["A computer-implemented method according to one embodiment includes estimating a speaker dependent acoustic model utilizing test speech data and a hybrid estimation technique, transforming labeled speech data to create transformed speech data, utilizing the speaker dependent acoustic model and a nonlinear transformation, and adjusting a deep neural network (DNN) acoustic model, utilizing the transformed speech data.", "Adjusting a deep neural network acoustic model "]
["Apparatuses and methods of manufacturing same, systems, and methods for object detection using a region-based deep learning model are described. In one aspect, a method is provided, in which a region proposal network (RPN) is used to identify regions of interest (RoI) in an image by assigning a confidence levels, the assigned confidence levels of the RoIs are used to boost the background score assigned by the downstream classifier to each RoI, and the background scores are used in a softmax function to calculate the final class probabilities for each object class.", "System and method for a deep learning machine for object detection "]
[null, "Cell convolutional neural network intelligent vision pays accelerator "]
["A method and system for anatomical object detection using marginal space deep neural networks is disclosed. The pose parameter space for an anatomical object is divided into a series of marginal search spaces with increasing dimensionality. A respective deep neural network is trained for each of the marginal search spaces, resulting in a series of trained deep neural networks. Each of the trained deep neural networks can evaluate hypotheses in a current parameter space using discriminative classification or a regression function. An anatomical object is detected in a medical image by sequentially applying the series of trained deep neural networks to the medical image.", "Method and system for anatomical object pose detection using marginal space deep neural networks "]
["A user portrait representation learning system based on a deep neural network, comprising: an intention recognition module (102) used for recognizing a use function of a user according to a received statement; a feature vector extraction module (103) used for modeling the context relation of a text or the relationship between entities by means of deep learning, and then extracting feature information of the user by means of text information input by the user; and a user portrait learning module (104) used for continually updating a user portrait by means of iterative training of the feature information and supervisory information. By means of learning a user portrait in a deep learning mode, the features of the user portrait can be abstractly extracted, the feature representation is more concise and accurate, and a deep level of implicit information can be extracted.", "User portrait representation learning system and method based on deep neural network "]
["Methods and apparatus for automated medical image analysis using deep learning networks are disclosed. In a method of automatically performing a medical image analysis task on a medical image of a patient, a medical image of a patient is received. The medical image is input to a trained deep neural network. An output model that provides a result of a target medical image analysis task on the input medical image is automatically estimated using the trained deep neural network. The trained deep neural network is trained in one of a discriminative adversarial network or a deep image-to-image dual inverse network.", "Adversarial and Dual Inverse Deep Learning Networks for Medical Image Analysis "]
[null, "Kinds of online content recommendation method based on neural network depth "]
[null, "Device and method for generating a group equivariant convolutional neural network. "]
["The present disclosure provides systems and methods to reduce computational costs associated with convolutional neural networks. In addition, the present disclosure provides a class of efficient models termed \u201cMobileNets\u201d for mobile and embedded vision applications. MobileNets are based on a straight-forward architecture that uses depthwise separable convolutions to build light weight deep neural networks. The present disclosure further provides two global hyper-parameters that efficiently trade-off between latency and accuracy. These hyper-parameters allow the entity building the model to select the appropriately sized model for the particular application based on the constraints of the problem. MobileNets and associated computational cost reduction techniques are effective across a wide range of applications and use cases.", "Efficient Convolutional Neural Networks and Techniques to Reduce Associated Computational Costs "]
["Provided is a method for operating a convolutional neural network. The method includes performing learning on weights between neural network nodes by using input data, removing an adaptive parameter that performs learning using the input data after removing a weight having a size less than a threshold value among weights, and mapping remaining weights in the removing of the adaptive parameter to a plurality of representative values.", "Convolutional neural network system using adaptive pruning and weight sharing and operation method thereof "]
["The present invention provides a computer implemented method, system, and computer program product of deep learning via dynamic root solvers. In an embodiment, the present invention includes (1) forming an initial set of GPUs into an initial binary tree architecture, where the initial set includes initially idle GPUs and an initial root solver GPU as the root of the initial binary tree architecture, (2) calculating initial gradients and initial adjusted weight data, (3) choosing a first currently idle GPU as a current root solver GPU, (4) forming a current set of GPUs into a current binary tree architecture, where the current set includes the additional currently idle GPUs and the current root solver GPU as the root of the current binary tree architecture, (5) calculating current gradients and current adjusted weight data, and (6) transmitting an initial update to the weight data to the available GPUs.", "Deep learning via dynamic root solvers "]
["Described herein are systems and methods for creating and using Convolutional Recurrent Neural Networks (CRNNs) for small-footprint keyword spotting (KWS) systems. Inspired by the large-scale state-of-the-art speech recognition systems, in embodiments, the strengths of convolutional layers to utilize the structure in the data in time and frequency domains are combined with recurrent layers to utilize context for the entire processed frame. The effect of architecture parameters were examined to determine preferred model embodiments given the performance versus model size tradeoff. Various training strategies are provided to improve performance. In embodiments, using only \u02dc230 k parameters and yielding acceptably low latency, a CRNN model embodiment demonstrated high accuracy and robust performance in a wide range of environments.", "Convolutional recurrent neural networks for small-footprint keyword spotting "]
["A method for training a deep learning network includes defining a loss function corresponding to the network. Training samples are received and current parameter values are set to initial parameter values. Then, a computing platform is used to perform an optimization method which iteratively minimizes the loss function. Each iteration comprises the following steps. An eigCG solver is applied to determine a descent direction by minimizing a local approximated quadratic model of the loss function with respect to current parameter values and the training dataset. An approximate leftmost eigenvector and eigenvalue is determined while solving the Newton system. The approximate leftmost eigenvector is used as negative curvature direction to prevent the optimization method from converging to saddle points. Curvilinear and adaptive line-searches are used to guide the optimization method to a local minimum. At the end of the iteration, the current parameter values are updated based on the descent direction.", "Efficient calculations of negative curvature in a hessian free deep learning framework "]
["A keypoint detection system includes: a camera system including at least one camera; and a processor and memory, the processor and memory being configured to: receive an image captured by the camera system; compute a plurality of keypoints in the image using a convolutional neural network including: a first layer implementing a first convolutional kernel; a second layer implementing a second convolutional kernel; an output layer; and a plurality of connections between the first layer and the second layer and between the second layer and the output layer, each of the connections having a corresponding weight stored in the memory; and output the plurality of keypoints of the image computed by the convolutional neural network.", "Systems and methods for keypoint detection with convolutional neural networks "]
["After input data has been classified by a convolutional neural network - CNN -, a labelling process is carried out in respect of a convolutional filter of the CNN which contributed directly or indirectly to classification of input data. The labelling process comprises inputting an output of the convolutional filter, and/or an output of a max-pooling filter associated with the convolutional filter, into a filter classifier which employs an input data classification process to assign a label to a feature represented by the convolutional filter. The labelling process is repeated in respect of each individual convolutional filter of the CNN which contributed directly or indirectly to classification of the input data. The CNN is then translated into a neural-symbolic network in association with the assigned labels, and a knowledge extraction method is used to extract from the neural-symbolic network knowledge relating to the classification of the input data by the CNN. A summary, comprising the input data, the classification of the input data assigned by the CNN, and the extracted knowledge, may be generated and output. Alternatively, or in addition, an alert indicating that performance of an action or task, using the extracted knowledge and classified input data, is required may be generated and output", "Knowledge extraction from a convolutional neural network "]
["Apparatuses and methods of manufacturing same, systems, and methods for training deep learning machines are described. In one aspect, candidate units, such as detection bounding boxes in images or phones of an input audio feature, are classified using soft labelling, where at least label has a range of possible values between 0 and 1 based, in the case of images, on the overlap of a detection bounding box and one or more ground-truth bounding boxes for one or more classes.", "System and method for training deep learning classification networks "]
[null, "Cell convolutional neural network intelligent vision driving fatigue monitors accelerator "]
["Classification techniques are disclosed that take into account the \u201ccost\u201d of each type of classification error for minimizing total cost of errors. In one example embodiment, a pre-trained cost-sensitive auto-encoder can be used in combination with a training (fine-tuning) stage for cost-sensitive deep learning. Thus, cost information is effectively combined with deep learning by modifying the objective function in the pre-training phase. By minimizing the modified objective function, the auto-encoder not only tries to capture underlying pattern, it further \u201clearns\u201d the cost information and \u201cstores\u201d it in the structure. By later fine-tuning at the training stage, the classification system yields improved performance (lower cost) than a typical classification system that does not take cost information into account during pre-training.", "Cost-sensitive classification with deep learning using cost-aware pre-training "]
["Various methods are provided for training and subsequently utilizing a convolutional neural network (CNN) to detect small pedestrians (e.g., pedestrians located away a large distance). One example method may comprise performing a first training stage in which a first CNN is trained to detect objects of a first size, the first CNN trained using a first set of images comprised of objects of the first size, and configured to output a first set of parameters, performing a second training stage in which a second CNN is trained using a second set of images, the second set of images comprising objects of a second size, and the first CNN is initialized with the first set of parameters and is re-trained using the second set of images, and determining parameters of the first CNN by minimizing error between the first CNN and the second CNN.", "Method and apparatus for detecting small objects with an enhanced deep neural network "]
["Systems and methods for providing reinforcement learning for a deep learning network are disclosed. A reinforcement learning process that provides deep exploration is provided by a bootstrap that applied to a sample of observed and artificial data to facilitate deep exploration via a Thompson sampling approach.", "Systems and Methods for Providing Reinforcement Learning in a Deep Learning System "]
["Embodiments described herein provide various examples of an age and gender estimation system capable of performing age and gender classifications on face images having sizes greater than the maximum number of input pixels supported by a given small-scale hardware convolutional neutral network (CNN) module. In some embodiments, the proposed age and gender estimation system can first divide a high-resolution input face image into a set of image patches with judiciously designed overlaps among neighbouring patches. Each of the image patches can then be processed with a small-scale CNN module, such as the built-in CNN module in Hi3519 SoC. The outputs corresponding to the set of image patches can be subsequently merged to obtain the output corresponding to the input face image, and the merged output can be further processed by subsequent layers in the age and gender estimation system to generate age and gender classifications for the input face image.", "Age and gender estimation using small-scale convolutional neural network (cnn) modules for embedded systems "]
["A method of computation in a deep neural network includes discretizing input signals and computing a temporal difference of the discrete input signals to produce a discretized temporal difference. The method also includes applying weights of a first layer of the deep neural network to the discretized temporal difference to create an output of a weight matrix. The output of the weight matrix is temporally summed with a previous output of the weight matrix. An activation function is applied to the temporally summed output to create a next input signal to a next layer of the deep neural network.", "Temporal difference estimation in an artificial neural network "]
["Systems and methods of implementing a more efficient and less resource-intensive CNN are disclosed herein. In particular, applications of CNN in the analog domain using Sampled Analog Technology (SAT) methods are disclosed. Using a CNN design with SAT results in lower power usage and faster operation as compared to a CNN design with digital logic and memory. The lower power usage of a CNN design with SAT can allow for sensor devices that also detect features at very low power for isolated operation.", "Convolutional neural network "]
["In accordance with an example embodiment of the present invention, a method comprising: obtaining a plurality of training cases; initializing a filter corresponding to each convolutional layer in a convolutional neural network, wherein the convolutional neural network comprises at least one convolutional layer; applying a squashing function on the filter; computing convolutions of patches from the plurality of training images and the filter which has applied the squashing function; and obtaining parameters of the squashing function and parameters of the filter based on the computed convolutions.", "Deep convolutional neural networks with squashed filters "]
["Embodiments of the present disclosure include a method for extracting symbols from a digitized object. The method includes processing the word block against a dictionary. The method includes comparing the word block against a word in the dictionary, the comparison providing a confidence factor. The method includes outputting a prediction equal to the word when the confidence factor is greater than a predetermined threshold. The method includes evaluating properties of the word block when the confidence factor is less than the predetermined threshold. The method includes predicting a value of the word block based on the properties of the word block. The method further includes determining an error rate for the predicted value of the word block. The method includes outputting a value for the word block, the output equal to a calculated value corresponding to a value of the word block having the lowest error rate.", "System and method of character recognition using fully convolutional neural networks "]
["A bit-depth optimization engine reduces the hardware cost of a neural network. When training data is applied to a neural network during training routines, accuracy cost and hardware costs are generated. A hardware complexity cost generator generates costs for weights near bit-depth steps where the number of binary bits required to represent a weight decreases, such as from 2N to 2N\u20131, where one less binary bit is required. Gradients are generated from costs for each weight, and weights near bit-depth steps are easily selected since they have a large gradient, while weights far away from a bit-depth step have near-zero gradients. The selected weights are reduced during optimization. Over many cycles of optimization, a low-bit-depth neural network is generated that uses fewer binary bits per weight, resulting in lower hardware costs when the low-bit-depth neural network is manufactured on an Application-Specific Integrated Circuit (ASIC).", "Method and system for bit-depth reduction in artificial neural networks "]
["A system and method is provided that utilizes deep learning, including convolutional neural networks, to identify subject objects in unconstrained user images such as unknown pills. An image of, e.g., a pill, may be captured and subsequently processed using deep learning models to identify the pill. The deep learning models may be optimized to have a small footprint (in terms of computational and memory resources) suitable for a resource-limited device such as a smartphone while retaining a high object recognition accuracy. Each such model may also be run on modified versions of the unconstrained image, for example on color, greyscale, and gradient images, to focus the models on different distinguishing features of the object.", "Deep learning system for recognizing pills in images "]
[null, "Because cell neural network or convolution neural network's user identification system in advertising media input terminal "]
[null, "Remote Sensing Target Species Based on Neural Network depth "]
["A construction method for a deep long short-term memory recurrent neural network acoustic model based on a selective attention principle. Change of an instant function of neurons of an auditory cortex is represented by adding an attention gate (103) unit in the deep long short-term memory recurrent neural network acoustic model, and the attention gate (103) unit is different from other gate units in that: the other gate units correspond to a time sequence on a one-to-one basis, but the attention gate (103) unit shows a short-term plasticity effect, thereby having intervals on the time sequence; extraction of robust features about Cross-talk noise and construction of a robust acoustic model are realized via the recurrent neural network acoustic model obtained by training a large amount of voice data containing the Cross-talk noise, and the purpose of increasing the robustness about the acoustic model can be achieved by restraining the influence of a non-target stream against the extraction of the features; the method can be extensively applied to the field of a plurality of machine learning related to speaker recognition and keyword recognition in voice recognition, human-machine interaction and the like.", "Construction method for deep long short-term memory recurrent neural network acoustic model based on selective attention principle "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for asynchronous deep reinforcement learning. One of the systems includes a plurality of workers, wherein each worker is configured to operate independently of each other worker, and wherein each worker is associated with a respective actor that interacts with a respective replica of the environment during the training of the deep neural network.", "Asynchronous deep reinforcement learning "]
["Embodiments of the present disclosure include a method that obtains a digital image. The method includes extracting a word block from the digital image. The method includes processing the word block by evaluating a value of the word block against a dictionary. The method includes outputting a prediction equal to a common word in the dictionary when a confidence factor is greater than a predetermined threshold. The method includes processing the word block and assigning a descriptor to the word block corresponding to a property of the word block. The method includes processing the word block using the descriptor to prioritize evaluation of the word block. The method includes concatenating a first output and a second output. The method includes predicting a value of the word block.", "System and method of character recognition using fully convolutional neural networks with attention "]
[null, "Method and apparatus for depth of training the neural network model for speech synthesis "]
["A neural network system that includes: multiple subnetworks that includes: a first subnetwork including multiple first modules, each first module including: a pass-through convolutional layer configured to process the subnetwork input for the first subnetwork to generate a pass-through output; an average pooling stack of neural network layers that collectively processes the subnetwork input for the first subnetwork to generate an average pooling output; a first stack of convolutional neural network layers configured to collectively process the subnetwork input for the first subnetwork to generate a first stack output; a second stack of convolutional neural network layers that are configured to collectively process the subnetwork input for the first subnetwork to generate a second stack output; and a concatenation layer configured to concatenate the pass-through output, the average pooling output, the first stack output, and the second stack output to generate a first module output for the first module.", "Image classification neural networks "]
["The present disclosure provides systems and methods that leverage machine-learned models (e.g., neural networks) to provide enhanced communication assistance. In particular, the systems and methods of the present disclosure can include or otherwise leverage a machine-learned communication assistance model to detect problematic statements included in a communication and/or provide suggested replacement statements to respectively replace the problematic statements. In one particular example, the communication assistance model can include a long short-term memory recurrent neural network that detects an inappropriate tone or unintended meaning within a user-composed communication and provides one or more suggested replacement statements to replace the problematic statements.", "Enhanced Communication Assistance with Deep Learning "]
["A connection between a user device and a network server is established. Via the connection, a deep learning network is formed for a processing task. A first portion of the deep learning network operates on the user device and a second portion of the deep learning network operates on the network server. Based on cooperation between the user device and the network server, a boundary between the first portion and the second portion of the deep learning network is dynamically modified based on a change in a performance indicator that could affect the processing task", "Dynamically modifying a boundary of a deep learning network "]
["Techniques related to compressing a pre-trained dense deep neural network to a sparsely connected deep neural network for efficient implementation are discussed. Such techniques may include iteratively pruning and splicing available connections between adjacent layers of the deep neural network and updating weights corresponding to both currently disconnected and currently connected connections between the adjacent layers.", "Dynamic neural network surgery "]
["Methods and systems for performing diagnostic functions for a deep learning model are provided. One system includes one or more components executed by one or more computer subsystems. The one or more components include a deep learning model configured for determining information from an image generated for a specimen by an imaging tool. The one or more components also include a diagnostic component configured for determining one or more causal portions of the image that resulted in the information being determined and for performing one or more functions based on the determined one or more causal portions of the image.", "Diagnostic systems and methods for deep learning models configured for semiconductor applications "]
["Provided in the present invention are a neural network-based method and device for face feature extraction and modeling, and face recognition. The method comprises: acquiring face image triplets from a training set of a predetermined application scenario; acquiring a trained face recognition neural network, and determining, according to the face recognition neural network, a triplet deep neural network; employing the face image triplets as an input of the triplet deep neural network, and determining a loss function value; training, according to the loss function value and training parameters, the triplet deep neural network with the training set; and performing, by means of a test set of the predetermined application scenario, a face recognition test on the triplet deep neural network, determining, according to the test result, test accuracy, and determining, according to the test accuracy and the triplet deep neural network, a target face feature extraction model. The method and device of the present invention provide an advantageous effect of superior face recognition accuracy when a face feature model obtained via modeling is applied to a specific face recognition application scenario. Also provided in the present invention are a face recognition method and device.", "Neural network-based method and device for face feature extraction and modeling, and face recognition "]
["The present invention provides a method for detecting image steganography based on deep learning, which comprises: filtering images having steganographic class label or true class label in a training set with a high-pass filter to obtain a training set including steganographic class residual images and true class residual images; training a deep network model on said training set to obtain a trained deep model for steganalysis; filtering the image to be detected with said high-pass filter to obtain a residual image to be detected; detecting said residual image to be detected on said deep model so as to determine whether said residual image to be detected is a steganographic image. The method for detecting image steganography in the present invention can create an automatic blind steganalysis model through feature learning and can identify steganographic images accurately.", "Image Steganalysis Based on Deep Learning "]
["A recognition apparatus based on a deep neural network, a training apparatus and methods thereof. The deep neural network is obtained by inputting training samples comprising positive samples and negative samples into an input layer of the deep neural network and training. The apparatus includes: a judging unit configured to judge that a sample to be recognized is a suspected abnormal sample when confidences of positive sample classes in a classification result outputted by an output layer of the deep neural network are all less than a predefined threshold value. Hence, reliability of a confidence of a classification result outputted by the deep neural network may be efficiently improved.", "Recognition apparatus based on deep neural network, training apparatus and methods thereof "]
[null, "Method and system parameters depth training model neural network "]
["A knowledge acquisition system and artificial cognitive declarative memory model to store and retrieve massive student learning datasets. A Deep Academic Learning Intelligence system for machine learning-based student services provides monitoring and aggregating performance information and student communications data in an online group learning course. The system uses communication activity, social activity, and the academic achievement data to present a set of recommendations and uses responses and post-recommendation data as feedback to further train the machine learning-based system.", "Deep academic learning intelligence and deep neural language network system and interfaces "]
["According to an example aspect of the present invention, there is provided a method, comprising: resizing a convolutional layer input of an artificial neural network with at least two different scales to obtain multiple groups of intermediate features maps, convolving the intermediate feature maps with a filter, resizing the convolution results to the size of the layer input, and concatenating the resized convolution results to form an output of the convolutional layer.", "Artificial neural network "]
["Synthesizing a neural network from a plurality of component neural networks is disclosed. The method comprises mapping each component network to a respective graph node where each node is first labelled in accordance with the structure of a corresponding layer of the component network and a distance of the node from one of a given input or output. The graphs for each component network are merged into a single merged graph by merging nodes from component network graphs having the same first structural label. Each node of the merged graph is second labelled in accordance with the structure of the corresponding layer of the component network and a distance of the node from the other of a given input or output. The merged graph is contracted by merging nodes of the merged graph having the same second structural label. The contracted-merged graph is mapped to a synthesized neural network.", "Method for synthesizing a neural network "]
["The present discussion relates to the use of deep learning techniques to accelerate iterative reconstruction of images, such as CT, PET, and MR images. The present approach utilizes deep learning techniques so as to provide a better initialization to one or more steps of the numerical iterative reconstruction algorithm by learning a trajectory of convergence from estimates at different convergence status so that it can reach the maximum or minimum of a cost function faster.", "Deep learning based acceleration for iterative tomographic reconstruction "]
["Systems and methods may automatically generate code for deep learning networks. The systems methods may provide a code generation framework for generating target specific code. The code generation framework may include one or more predefined class hierarchies for constructing objects of the generated code. The objects of the class hierarchies may provide an interface to predefined libraries of deep learning functions optimized for use on a target platform. The systems and methods may perform one or more optimizations on the code being generated.", "Systems and methods for automatically generating code for deep learning systems "]
["Four-dimensional (4D) weather forecast data is received which includes a plurality of weather features. The 4D weather forecast data is processed using a chain of a plurality of processing blocks of a neural network to derive one or more of the plurality of weather features. Each of the plurality of processing blocks includes a convolutional layer, an activation layer, and a pooling layer. The convolution layer associates at least one filter to a region of the 4D weather forecast data across a plurality of layers in the 4D weather forecast data. A solar power forecast is determined for a predetermined location based upon the one or more derived weather features.", "Solar power forecasting with volumetric convolutional neural network "]
[null, "Medical science video identification diagnostic system based on cell neural network or convolution neural network "]
["Disclosed is the reduction of parameters in fully connected layers of neural networks. For a layer whose output is defined by y=Wx, where y is the output vector, x is the input vector, and W is a matrix of connection parameters, vectors uij and vij are defined and submatrices Wi,j are computed as the outer product of uij and vij, so that Wi,j= vij\u2297uij, and W is obtained by appending submatrices Wi,j.", "Reduction of parameters in fully connected layers of neural networks "]
["A head-mounted augmented reality (AR) device can include a hardware processor programmed to receive different types of sensor data from a plurality of sensors (e.g., an inertial measurement unit, an outward-facing camera, a depth sensing camera, an eye imaging camera, or a microphone); and determining an event of a plurality of events using the different types of sensor data and a hydra neural network (e.g., face recognition, visual search, gesture identification, semantic segmentation, object detection, lighting detection, simultaneous localization and mapping, relocalization).", "Augmented reality display device with deep learning sensors "]
["Provided are an apparatus and method for compressing a deep neural network (DNN). The DNN compression method includes receiving a matrix of a hidden layer or an output layer of a DNN, calculating a matrix representing a nonlinear structure of the hidden layer or the output layer, and decomposing the matrix of the hidden layer or the output layer using a constraint imposed by the matrix representing the nonlinear structure.", "Deep neural network compression apparatus and method "]
[null, "Intelligent electrocardiogram diagnosis method based on deep neural network "]
[null, "Training apparatus and method for neural networks and neural network system "]
[null, "Non-uniform image motion blur removing method based on deep neural network "]
[null, "Secondary protein structureprediction method based on deep neural network "]
["Conversion of a large-footprint DNN to a small-print DNN is performed using a variety of techniques, including split-vector quantization. The small-foot print DNN may be distributed to a variety of devices, including mobile devices. Further, the small-footprint DNN may aid a digital assistant on a device in interpreting speech input.", "Small-footprint deep neural network "]
[null, "Deep neural network based biomedical text serialization labeling system and method "]
["The present disclosure is drawn to the reduction of parameters in fully connected layers of neural networks. For a layer whose output is defined by y=Wx, where y \u2208 Rm is the output vector, x \u2208 Rn is the input vector, and W \u2208 Rmxn is a matrix of connection parameters, matrices Uij and Vij are defined and submatrices Wij are computed as the product of Uij and Vij, so that Wij=VijUij, and W is obtained by appending submatrices Wi,j.", "Reduction of parameters in fully connected layers of neural networks by low rank factorizations "]
["A method, computer program product, and system perform computations using a processor. A first instruction including a first index vector operand and a second index vector operand is received and the first index vector operand is decoded to produce first coordinate sets for a first array, each first coordinate set including at least a first coordinate and a second coordinate of a position of a non-zero element in the first array. The second index vector operand is decoded to produce second coordinate sets for a second array, each second coordinate set including at least a third coordinate and a fourth coordinate of a position of a non-zero element in the second array. The first coordinate sets are summed with the second coordinate sets to produce output coordinate sets and the output coordinate sets are converted into a set of linear indices.", "Sparse convolutional neural network accelerator "]
[null, "Voice recongintion system and methode based on deep neural network "]
["[Object] An object is to provide a statistical acoustic model adaptation method capable of efficient adaptation of an acoustic model using DNN with training data under a specific condition and achieving higher accuracy. [Solution] A method of speaker adaptation of an acoustic model using DNN includes the steps of: storing speech data 90 to 98 of different speakers separately in a first storage device; preparing speaker-by-speaker hidden layer modules 112 to 120; performing preliminary learning of all layers 42, 44, 110, 48, 50, 52 and 54 of a DNN 80 by switching and selecting the speech data 90 to 98 while dynamically replacing a specific layer 110 with hidden layer modules 112 to 120 corresponding to the selected speech data; replacing the specific layer 110 of the DNN that has completed the preliminary learning with an initial hidden layer; and training the DNN with speech data of a specific speaker while fixing parameters of layers other than the initial hidden layer.", "Statistical acoustic model adaptation method, acoustic model learning method suitable for statistical acoustic model adaptation, storage medium storing parameters for building deep neural network, and computer program for adapting statistical acoustic model "]
["Disclosed is a learning method based on a stochastic-based deep learning model having a non-consecutive stochastic neural. The learning method includes configuring a non-consecutive stochastic feedforward neural network (NCSFNN) having non-consecutive stochastic neuron as a leaning model including a plurality of hidden layers; and allowing the NCSFNN to learn.", "Learning method based on deep learning model having non-consecutive stochastic neuron and knowledge transfer, and system thereof "]
[null, "Method for stabilizing deep neural network using residual network "]
["Described herein are systems and methods that exploit hierarchical Recurrent Neural Networks (RNNs) to tackle the video captioning problem; that is, generating one or multiple sentences to describe a realistic video. Embodiments of the hierarchical framework comprise a sentence generator and a paragraph generator. In embodiments, the sentence generator produces one simple short sentence that describes a specific short video interval. In embodiments, it exploits both temporal- and spatial-attention mechanisms to selectively focus on visual elements during generation. In embodiments, the paragraph generator captures the inter-sentence dependency by taking as input the sentential embedding produced by the sentence generator, combining it with the paragraph history, and outputting the new initial state for the sentence generator.", "Systems and methods for video paragraph captioning using hierarchical recurrent neural networks "]
["A computer-implemented method that includes receiving, by a processing unit, an instruction that specifies data values for performing a tensor computation. In response to receiving the instruction, the method may include, performing, by the processing unit, the tensor computation by executing a loop nest comprising a plurality of loops, wherein a structure of the loop nest is defined based on one or more of the data values of the instruction. The tensor computation can be at least a portion of a computation of a neural network layer. The data values specified by the instruction may comprise a value that specifies a type of the neural network layer, and the structure of the loop nest can be defined at least in part by the type of the neural network layer.", "Neural network instruction set architecture "]
[null, "Vehicle type recognition method based on rapid R-CNN deep neural network "]
[null, "Deep neural network-based baby cry identification method and system "]
[null, "Method for constructing deep convolution neural network model "]
["A method of operating neural networks such as convolutional neural networks including, e.g., an input layer, an output layer and at least one intermediate layer between the input layer and the output layer, with the network layers including operating circuits performing arithmetic operations on input data to provide output data. The method includes: selecting a set of operating circuits in the network layers, performing arithmetic operations in operating circuits in the selected set of operating circuits by performing Residue Number System or RNS operations on RNS-converted input data by obtaining RNS output data in the Residue Number System, backward converting from the Residue Number System the RNS output data resulting from the RNS operations.", "Method of operating neural networks, corresponding network, apparatus and computer program product "]
[null, "Deep neural network training method based on multiple pre-training "]
["Features are disclosed for reducing the dynamic range of an approximated trained artificial neural network weight matrix in an automatic speech recognition system. The weight matrix may be approximated as two low-rank matrices using a decomposition technique. This approximation technique may insert an additional layer between the two original layers connected by the weight matrix. The dynamic range of the low-rank decomposition may be reduced by applying the square root of singular values, combining them with both low-rank matrices, and utilizing a random rotation matrix to further compress the low-rank matrices. Reduction of dynamic range may make fixed point scoring more effective due to smaller quantization error, as well as make the neural network system more favorable for retraining after approximating a neural network weight matrix. Features are also disclosed for adjusting the learning rate during retraining to account for the low-rank approximations.", "Reducing dynamic range of low-rank decomposition matrices "]
[null, "Psychologist robot system based on neural network deep learning "]
[null, "Apparatus and method for predicting electricity demand based on deep neural networks "]
[null, "Vein recognition system based on depth neural network "]
[null, "Operating system for deep neural network and operating method "]
[null, "Incremental Training Based Knowledge Transfer Method for Training Large Deep Neural Networks and Apparatus Therefor "]
[null, "FPGA-based deep convolution neural network realizing method "]
[null, "Deep convolutional neural network method based on deterministic discarding connection "]
[null, "Algorithm for determining video key area based on deep neural network "]
[null, "Deep learning-based adaptive ultrasound image enhancement method "]
[null, "Cross-line counting method, deep neural network training method, devices and electronic apparatus "]
[null, "Utterance Verification Method using Deep Neural Network "]
[null, "Apparatus and method for image analysis using virtual three-dimensional deep neural network "]
["Disclosed are systems and methods for localization and segmentation of organs (especially abnormally shaped, deformable, and/or smaller organs, such as the pancreas and lymph nodes) based on data from 3D medical imaging (e.g., CT and MRI scans) using holistically-nested convolutional neural networks (\"HNNs\"). Using as an example CT scan data and the pancreas, the methods can include localizing an organ from an entire 3D CT scan, providing a reliable bounding box for the more refined segmentation step. The methods can further comprise introducing a fully deep-learning approach, based on an efficient application of HNNs on the three orthogonal views. The resulting HNN per-pixel probability maps can then be fused using pooling to reliably produce a 3D bounding box of the pancreas that maximizes the recall. An introduced localizer compares favorably to both a conventional non-deep-learning method and a hybrid approach based on spatial aggregation of superpixels using random forest classification. The segmentation phase can operate within the computed bounding box and can integrate semantic mid-level cues of deeply-learned organ interior and boundary maps, obtained by two additional and separate realizations pf HNNs. By integrating these two mid-level cues, the disclosed methods are capable of generating boundary-preserving pixel-wise class label maps that result in exceptional final organ segmentations.", "Spatial aggregation of holistically-nested convolutional neural networks for automated organ localization and segmentation in 3d medical scans "]
["Systems and methods for analyzing perfusion-weighted medical imaging using deep neural networks are provided. In some aspects, a method includes receiving perfusion-weighted imaging data acquired from a subject using a magnetic resonance (\"MR\") imaging system and modeling at least one voxel associated with the perfusion- weighted imaging data using a four-dimensional (\"4D\") convolutional neural network. The method also includes extracting spatio-temporal features for each modeled voxel and estimating at least one perfusion parameter for each modeled voxel based on the extracted spatio-temporal features. The method further includes generating a report using the at least one perfusion parameter indicating perfusion in the subject.", "Systems and methods for analyzing perfusion-weighted medical imaging using deep neural networks "]
[null, "Training method of deep neural network model and equipment thereof "]
[null, "Voice recognition system based on deep neural network "]
[null, "Method and apparatus for speech recognition using deep neural network "]
[null, "Apparatus and method for learning deep neural network "]
["A mechanism for compiling a generative description of an inference task into a neural network. First, an arbitrary generative probabilistic model from the exponential family is specified (or received). The model characterizes a conditional probability distribution for measurement data given a set of latent variables. A factor graph is generated for the generative probabilistic model. Each factor node of the factor graph is expanded into a corresponding sequence of arithmetic operations, based on a specified inference task and a kind of message passing algorithm. The factor graph and the sequences of arithmetic operations specify the structure of a neural network for performance of the inference task. A learning algorithm is executed, to determine values of parameters of the neural network. The neural network is then ready for performing inference on operational measurements.", "Automated Compilation of Probabilistic Task Description into Executable Neural Network Specification "]
["A system for training a neural network model, the neural network model comprising a plurality of layers including a first hidden layer associated with a first set of weights, the system comprising at least one computer hardware processor programmed to perform: obtaining training data; selecting a unitary rotational representation for representing a matrix of the first set weights, the selected unitary rotational representation comprising a plurality of parameters; training the neural network model using the training data using an iterative neural network training algorithm to obtain a trained neural network model, each iteration of the iterative neural network training algorithm comprising: updating values of the plurality of parameters in the selected unitary rotational representation for representing the matrix of the set of weights for the at least one hidden layer, and saving the trained neural network model.", "Systems and methods for training neural networks "]
["Embodiments of the present disclosure include a method that obtains a digital image. The method includes extracting a word block from the digital image. The method includes processing the word block by evaluating a value of the word block against a dictionary. The method includes outputting a prediction equal to a common word in the dictionary when a confidence factor is greater than a predetermined threshold. The method includes processing the word block and assigning a descriptor to the word block corresponding to a property of the word block. The method includes processing the word block using the descriptor to prioritize evaluation of the word block. The method includes concatenating a first output and a second output. The method includes predicting a value of the word block.", "System and method of character recognition using fully convolutional neural networks with attention "]
["Hyper-parameters are selected for training a deep convolutional network by selecting a number of network architectures as part of a database. Each of the network architectures includes one or more local logistic regression layer and is trained to generate a corresponding validation error that is stored in the database. A threshold error for identifying a good set of network architectures and a bad set of network architectures may be estimated based on validation errors in the database. The method also includes choosing a next potential hyper-parameter, corresponding to a next network architecture, based on a metric that is a function of the good set of network architectures. The method further includes selecting a network architecture, from among next network architectures, with a lowest validation error.", "Hyper-parameter selection for deep convolutional networks "]
["Deep scattering spectral features are extracted from an acoustic input signal to generate a deep scattering spectral feature representation of the acoustic input signal. The deep scattering spectral feature representation is input to a speech recognition engine. The acoustic input signal is decoded based on at least a portion of the deep scattering spectral feature representation input to a speech recognition engine.", "Deep scattering spectrum in acoustic modeling for speech recognition "]
["A method and apparatus for automatically performing medical image analysis tasks using deep image-to-image network (DI2IN) learning. An input medical image of a patient is received. An output image that provides a result of a target medical image analysis task on the input medical image is automatically generated using a trained deep image-to-image network (DI2IN). The trained DI2IN uses a conditional random field (CRF) energy function to estimate the output image based on the input medical image and uses a trained deep learning network to model unary and pairwise terms of the CRF energy function. The DI2IN may be trained on an image with multiple resolutions. The input image may be split into multiple parts and a separate DI2IN may be trained for each part. Furthermore, the multi-scale and multi-part schemes can be combined to train a multi-scale multi-part DI2IN.", "Deep image-to-image network learning for medical image analysis "]
[null, "Neural network processor based on weight compression, design method, and chip "]
[null, "Facial image face score calculating method based on convolutional neural network "]
[null, "Endpoint detection method of speech using deep neural network and apparatus thereof "]
["In order to compare high-dimensional, multi-modal data for a patient to data for other patients, deep learning is used to encode original, multi-modal data for a patient into a compact signature. The compact signature is compared to predetermined compact signatures generated for other patients, and similar predetermined compact signatures are identified based on the comparison. A clinical outcome may be predicted based on the similar predetermined compact signatures that are identified.", "Case-based reasoning in the cloud using deep learning "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating parse trees for input text segments. One of the methods includes obtaining an input text segment, processing the input text segment using a first long short term memory (LSTM) neural network to convert the input text segment into an alternative representation for the input text segment, and processing the alternative representation for the input text segment using a second LSTM neural network to generate a linearized representation of a parse tree for the input text segment.", "Generating parse trees of text segments using neural networks "]
[null, "Convolutional neural network processing method and apparatus "]
["A system for training a neural network includes a first set of neural network units and a second set of neural networking units. Each neural network unit in the first set is configured to compute parameter update data for one of a plurality of instances of a first portion of the neural network. Each neural network unit in the first set includes a communication interface for communicating its parameter update data for combination with parameter update data from another neural network unit in the first set. Each neural network unit in the second set is configured to compute parameter update data for one of a plurality of instances of a second portion of the neural network. Each neural network unit in the second set includes a communication interface for communicating its parameter update data for combination with parameter update data from another neural network unit in the second set.", "Systems, methods and devices for neural network communications "]
["Techniques related to implementing distributed neural networks for data analytics are discussed. Such techniques may include generating sensor data at a device including a sensor, implementing one or more lower level convolutional neural network layers at the device, optionally implementing one or more additional lower level convolutional neural network layers at another device such as a gateway, and generating a neural network output label at a computing resource such as a cloud computing resource based on optionally implementing one or more additional lower level convolutional neural network layers and at least implementing a fully connected portion of the neural network.", "Distributed neural networks for scalable real-time analytics "]
["Presented herein are embodiments of state-of-the-art speech recognition systems developed using end-to-end deep learning. In embodiments, the model architecture is significantly simpler than traditional speech systems, which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments. In contrast, embodiments of the system do not need hand-designed components to model background noise, reverberation, or speaker variation, but instead directly learn a function that is robust to such effects. A phoneme dictionary, nor even the concept of a \u201cphoneme,\u201d is needed. Embodiments include a well-optimized recurrent neural network (RNN) training system that can use multiple GPUs, as well as a set of novel data synthesis techniques that allows for a large amount of varied data for training to be efficiently obtained. Embodiments of the system can also handle challenging noisy environments better than widely used, state-of-the-art commercial speech systems.", "Systems and methods for speech transcription "]
["Systems and methods using a neural network based portable absorption spectrometer system for real-time automatic evaluation of tissue injury are described. An apparatus includes an electromagnetic signal generator; an optical fiber connected to the electromagnetic signal generator; a fiber optic probe connected to the optical fiber; a broad band spectrometer connected to the fiber optic probe; and a hybrid neural network connected to the broad band spectrometer. The hybrid neural network includes a principle component analyzer of broad band spectral data obtained from said broad band spectrometer.", "Accurate tissue injury assessment using hybrid neural network analysis "]
["A neural network may be utilized for autonomously driving a self-driving vehicle (SDV). The neural network can establish a destination location in local coordinates relative to the SDV. The neural network may then identify one or more navigation points in a forward operational direction of the SDV, and process sensor data from a sensor system of the SDV, the sensor data providing a sensor view of the forward operational direction of the SDV. Utilizing the sensor data, the neural network can operate acceleration, braking, and steering systems of the SDV to continuously follow the one or more navigation points along an established route to the destination location.", "Neural network system for autonomous vehicle control "]
["Methods and systems for performing a sequence of machine learning tasks. One system includes a sequence of deep neural networks (DNNs), including: a first DNN corresponding to a first machine learning task, wherein the first DNN comprises a first plurality of indexed layers, and each layer in the first plurality of indexed layers is configured to receive a respective layer input and process the layer input to generate a respective layer output; and one or more subsequent DNNs corresponding to one or more respective machine learning tasks, wherein each subsequent DNN comprises a respective plurality of indexed layers, and each layer in a respective plurality of indexed layers with index greater than one receives input from a preceding layer of the respective subsequent DNN, and one or more preceding layers of respective preceding DNNs, wherein a preceding layer is a layer whose index is one less than the current index.", "Progressive neural networks "]
["An apparatus for in-depth three dimensional tumor mapping including (A) a light source; (B) a multi-fiber bundle including at least one illumination fiber and at least two receiving fibers, the at least one illumination fiber being connected to the light source; (C) a spectrometer connected to the at least two receiving fibers; and (D) a hybrid neural network connected to the spectrometer, said hybrid neural network including a principle component analysis processor and a neural network classifier.", "Hybrid neural network and multiple fiber probe for in-depth 3-D mapping "]
["A first set of attributes (e.g., style) is generated through pre-trained single column neural networks and leveraged to regularize the training process of a regularized double-column convolutional neural network (RDCNN). Parameters of the first column (e.g., style) of the RDCNN are fixed during RDCNN training Parameters of the second column (e.g., aesthetics) are fine-tuned while training the RDCNN and the learning process is supervised by the label identified by the second column (e.g., aesthetics). Thus, features of the images may be leveraged to boost classification accuracy of other features by learning a RDCNN.", "Learning image categorization using related attributes "]
["The claimed subject matter includes a system and method for recognizing mixed speech from a source. The method includes training a first neural network to recognize the speech signal spoken by the speaker with a higher level of a speech characteristic from a mixed speech sample. The method also includes training a second neural network to recognize the speech signal spoken by the speaker with a lower level of the speech characteristic from the mixed speech sample. Additionally, the method includes decoding the mixed speech sample with the first neural network and the second neural network by optimizing the joint likelihood of observing the two speech signals considering the probability that a specific frame is a switching point of the speech characteristic.", "Mixed speech recognition "]
["Disclosed are systems and methods that implement efficient engines for computation-intensive tasks such as neural network deployment. Various embodiments of the invention provide for high-throughput batching that increases throughput of streaming data in high-traffic applications, such as real-time speech transcription. In embodiments, throughput is increased by dynamically assembling into batches and processing together user requests that randomly arrive at unknown timing such that not all the data is present at once at the time of batching. Some embodiments allow for performing steaming classification using pre-processing. The gains in performance allow for more efficient use of a compute engine and drastically reduce the cost of deploying large neural networks at scale, while meeting strict application requirements and adding relatively little computational latency so as to maintain a satisfactory application experience.", "Systems and methods for efficient neural network deployments "]
["A method includes determining object class probabilities of pixels in a first input image by examining the first input image in a forward propagation direction through layers of artificial neurons of an artificial neural network. The object class probabilities indicate likelihoods that the pixels represent different types of objects in the first input image. The method also includes selecting, for each of two or more of the pixels, an object class represented by the pixel by comparing the object class probabilities of the pixels with each other, determining an error associated with the object class that is selected for each pixel of the two or more pixels, determining one or more image perturbations by back-propagating the errors associated with the object classes selected for the pixels of the first input image through the layers of the neural network without modifying the neural network, and modifying a second input image by applying the one or more image perturbations to one or more of the first input image or the second input image prior to providing the second input image to the neural network for examination by the neurons in the neural network for automated object recognition in the second input image.", "Image analysis neural network systems "]
["Systems and method for computing yield values through a neural network from a plurality of different data inputs are disclosed. In an embodiment, a server computer system receives a particular dataset relating to one or more agricultural fields wherein the particular data set comprises particular crop identification data, particular environmental data, and particular management practice data. Using a first neural network, the server computer system computes a crop identification effect on crop yield from the particular crop identification data. Using a second neural network, the server computer system computes an environmental effect on crop yield from the particular environmental data. Using a third neural network, the server computer system computes a management practice effect on crop yield from the management practice data. Using a master neural network, the server computer system computes one or more predicted yield values from the crop identification effect on crop yield, the environmental effect on crop yield, and the management practice effect on crop yield.", "Crop yield estimation using agronomic neural network "]
["A method and computer system for managing a neural network. Data is sent into an input layer in a portion of layers of nodes in the neural network. The data moves on an encode path through the portion such that an output layer in the portion outputs encoded data. The encoded data is sent into the output layer on a decode path through the portion back to the input layer to obtain a reconstruction of the data by the input layer. A determination is made as to whether an undesired amount of error has occurred in the output layer based on the data sent into the input layer and the reconstruction of the data. A number of new nodes is added to the output layer when a determination is present that the undesired amount of the error occurred, enabling reducing the error using the number of the new nodes.", "Adaptive neural network management system "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing sequences using convolutional neural networks. One of the methods includes, for each of the time steps: providing a current sequence of audio data as input to a convolutional subnetwork, wherein the current sequence comprises the respective audio sample at each time step that precedes the time step in the output sequence, and wherein the convolutional subnetwork is configured to process the current sequence of audio data to generate an alternative representation for the time step; and providing the alternative representation for the time step as input to an output layer, wherein the output layer is configured to: process the alternative representation to generate an output that defines a score distribution over a plurality of possible audio samples for the time step.", "Processing sequences using convolutional neural networks "]
["An apparatus comprising circuitry that implements an artificial neural network training algorithm that uses weight tying.", "Apparatus and method implementing an artificial neural network training algorithm using weight tying "]
["A system is provided for multi-methodology, multi-user, self-optimizing Machine Learning as a Service for that automates and optimizes the model training process. The system uses a large-scale distributed architecture and is compatible with cloud services. The system uses a hybrid optimization technique to select between multiple machine learning approaches for a given dataset. The system can also use datasets to transferring knowledge of how one modeling methodology has previously worked over to a new problem.", "Distributed, multi-model, self-learning platform for machine learning "]
["A computer-based method includes receiving an input signal at a neuron in a computer-based neural network that includes a plurality of neuron layers, applying a first non-linear transform to the input signal at the neuron to produce a plain signal, and calculating a weighted sum of a first component of the input signal and the plain signal at the neuron. In a typical implementation, the first non-linear transform is a function of the first component of the input signal and at least a second component of the input signal.", "Highly trainable neural network configuration "]
["A speech synthesis method based on recurrent neural networks specifically comprises the following steps of: acquiring context information of a text to be synthesized; generating an acoustic statistical parameter sequence according to the context information of the text; according to the acoustic statistical parameter sequence generated from the context information, using a recurrent neural network to generate an acoustic parameter sequence of a speech to be synthesized; and synthesizing the speech according to the acoustic parameter sequence of the speech to be synthesized. Compared with traditional statistical parameter speech synthesis methods, the method gives the synthesized speech better naturalness and has good real-time property.", "Speech synthesis method based on recurrent neural networks "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a Q network used to select actions to be performed by an agent interacting with an environment. One of the methods includes obtaining a plurality of experience tuples and training the Q network on each of the experience tuples using the Q network and a target Q network that is identical to the Q network but with the current values of the parameters of the target Q network being different from the current values of the parameters of the Q network.", "Training reinforcement learning neural networks "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for improving operational efficiency within a data center by modeling data center performance and predicting power usage efficiency. An example method receives a state input characterizing a current state of a data center. For each data center setting slate, the state input and the data center setting slate are processed through an ensemble of machine learning models. Each machine learning model is configured to receive and process the state input and the data center setting slate to generate an efficiency score that characterizes a predicted resource efficiency of the data center if the data center settings defined by the data center setting slate are adopted t. The method selects, based on the efficiency scores for the data center setting slates, new values for the data center settings.", "Optimizing data center controls using neural networks "]
["Systems and processes for performing unit-selection text-to-speech synthesis are provided. In one example process, a sequence of target units can represent a spoken pronunciation of text. A set of predicted acoustic model parameters of a second target unit can be determined using a set of acoustic features of a first candidate speech segment of a first target unit and a set of linguistic features of the second target unit. A likelihood score of the second candidate speech segment with respect to the first candidate speech segment can be determined using the set of predicted acoustic model parameters of the second target unit and a set of acoustic features of the second candidate speech segment of the second target unit. The second candidate speech segment can be selected for speech synthesis based on the determined likelihood score. Speech corresponding to the received text can be generated using the selected second candidate speech segment.", "Unit-selection text-to-speech synthesis using concatenation-sensitive neural networks "]
["Training a target neural network comprises providing a first batch of samples of a given class to respective instances of a generative neural network, each instance providing a variant of the sample in accordance with the parameters of the generative network. Each variant produced by the generative network is compared with another sample of the class to provide a first loss function for the generative network. A second batch of samples is provided to the target neural network, at least some of the samples comprising variants produced by the generative network. A second loss function is determined for the target neural network by comparing outputs of instances of the target neural network to one or more targets for the neural network. The parameters for the target neural network are updated using the second loss function and the parameters for the generative network are updated using the first and second loss functions.", "Method of training a neural network "]
["Generating responses to input utilizing an ontology-crowd-relevance methodology is described. The techniques described herein access a plurality of data items and determine an ontology associated with the plurality of data items. The ontology includes one or more ontological elements. Furthermore, the techniques describe sending, to a plurality of devices, a request to generate response templates based on the one or more ontological elements and receiving, from the plurality of devices, the response templates directed to the one or more ontological elements.", "Ontology-Crowd-Relevance Deep Response Generation "]
["A method and system for domain adaptation based on multi-layer fusion in a convolutional neural network architecture for feature extraction and a two-step training and fine-tuning scheme. The architecture concatenates features extracted at different depths of the network to form a fully connected layer before the classification step. First, the network is trained with a large set of images from a source domain as a feature extractor. Second, for each new domain (including the source domain), the classification step is fine-tuned with images collected from the corresponding site. The features from different depths are concatenated with and fine-tuned with weights adjusted for a specific task. The architecture is used for classifying high occupancy vehicle images.", "Multi-layer fusion in a convolutional neural network for image classification "]
["A disclosed facial recognition system (and method) includes face parsing. In one approach, the face parsing is based on hierarchical interlinked multiscale convolutional neural network (HIM) to identify locations and/or footprints of components of a face image, The HIM generates multiple levels of image patches from different resolution images of the face image, where image patches for different levels have different resolutions. Moreover, the HIM integrates the image patches for different levels to generate interlinked image patches for different levels, where interlinked image patches for different levels have different resolutions. Furthermore, the HIM combines the interlinked image patches to identify refined locations and/or footprints of components.", "Hierarchical Interlinked Multi-scale Convolutional Network for Image Parsing "]
["Image classification and related imaging tasks performed using machine learning tools may be accelerated by using one or more of such tools to associate an image with a cluster of such labels or categories, and then to select one of the labels or categories of the cluster as associated with the image. The clusters of labels or categories may comprise labels that are mutually confused for one another, e.g., two or more labels or categories that have been identified as associated with a single image. By defining clusters of labels or categories, and configuring a machine learning tool to associate an image with one of the clusters, processes for identifying labels or categories associated with images may be accelerated because computations associated with labels or categories not included in the cluster may be omitted.", "Cluster-trained machine learning for image processing "]
["A method and device for effecting vehicle control is presented. The method includes receiving driving map data, which includes vehicle target data relative to a vehicle location data. The driving map data is processed to produce desired vehicle operational data, the desired vehicle operational data facilitates a vehicle to traverse a travel route. From the desired vehicle operational data vehicle, corresponding actuator control data is produced, and transmitted to effect vehicle control in either of the autonomous or driver-assisted modes.", "Method and device for producing vehicle operational data based on deep learning techniques "]
["Apparatuses and methods of manufacturing same, systems, and methods for performing network parameter quantization in deep neural networks are described. In one aspect, diagonals of a second-order partial derivative matrix (a Hessian matrix) of a loss function of network parameters of a neural network are determined and then used to weight (Hessian-weighting) the network parameters as part of quantizing the network parameters. In another aspect, the neural network is trained using first and second moment estimates of gradients of the network parameters and then the second moment estimates are used to weight the network parameters as part of quantizing the network parameters. In yet another aspect, network parameter quantization is performed by using an entropy-constrained scalar quantization (ECSQ) iterative algorithm. In yet another aspect, network parameter quantization is performed by quantizing the network parameters of all layers of a deep neural network together at once.", "Method and apparatus for neural network quantization "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for detecting voice activity. In one aspect, a method include actions of receiving, by a neural network included in an automated voice activity detection system, a raw audio waveform, processing, by the neural network, the raw audio waveform to determine whether the audio waveform includes speech, and provide, by the neural network, a classification of the raw audio waveform indicating whether the raw audio waveform includes speech.", "Voice Activity Detection "]
["A method for peptide binding prediction includes receiving a peptide sequence descriptor and descriptors of contacting amino acids on major histocompatibility complex (MHC) protein-peptide interaction structure; generating a model with an ensemble of high order neural network; pre-training the model by high order semi-restricted Boltzmann machine (RBM) or high-order denoising autoencoder; and generating a prediction as a binary output or continuous output with initial model parameters pre-trained using binary output data if available. A systematic learning method for leveraging high-order interactions/associations among items for better collaborative filtering and item recommendation.", "High-order semi-Restricted Boltzmann Machines and Deep Models for accurate peptide-MHC binding prediction "]
[null, "Fabric defect detection method based on B-spline wavelets and deep neural network "]
["A spoken language understanding (SLU) system receives a sequence of words corresponding to one or more spoken utterances of a user, which is passed through a spoken language understanding module to produce a sequence of intentions. The sequence of words are passed through a first subnetwork of a multi-scale recurrent neural network (MSRNN), and the sequence of intentions are passed through a second subnetwork of the multi-scale recurrent neural network (MSRNN). Then, the outputs of the first subnetwork and the second subnetwork are combined to predict a goal of the user.", "Method for using a Multi-Scale Recurrent Neural Network with Pretraining for Spoken Language Understanding Tasks "]
["The technology disclosed introduces a concept of training a neural network to create an embedding space. The neural network is trained by providing a set of K+2 training documents, each training document being represented by a training vector x, the set including a target document represented by a vector xt, a favored document represented by a vector xs, and K>1 unfavored documents represented by vectors xi u, each of the vectors including input vector elements, passing the vector representing each document set through the neural network to derive an output vectors yt, ys and yi u, each output vector including output vector elements, the neural network including adjustable parameters which dictate an amount of influence imposed on each input vector element to derive each output vector element, adjusting the parameters of the neural network to reduce a loss, which is an average over all of the output vectors yi u of [D(yt,ys)\u2212D(yt,yi u)].", "Content embedding using deep metric learning algorithms "]
["A pose-aware feature learning system includes an object tracker which tracks an object on a subject in a plurality of video frames, a pose estimator which estimates a pose of the subject in a track of the plurality of video frames, an image pair generator which extracts a plurality of image pairs from the track of the plurality of video frames, and labels the plurality of image pairs with the estimated pose and as depicting the same or different object, and a neural network trainer which trains a neural network based on the labeled plurality of image pairs, to predict whether an image pair depicts the same or different object and a pose difference for the image pair.", "System and method for pose-aware feature learning "]
["A system and method for labelling aerial images. A neural network generates predicted map data. The parameters of the neural network are trained by optimizing an objective function which compensates for noise in the map images. The function compensates both omission noise and registration noise.", "System and method for labelling aerial images "]
["A method for transforms input signals, by first defining a model for transforming the input signals, wherein the model is specified by constraints and a set of model parameters. An iterative inference procedure is derived from the model and the set of model parameters and unfolded into a set of layers, wherein there is one layer for each iteration of the procedure, and wherein a same set of network parameters is used by all layers. A neural network is formed by untying the set of network parameters such that there is one set of network parameters for each layer and each set of network parameters is separately maintainable and separately applicable to the corresponding layer. The neural network is trined to obtain a trained neural network, and then input signals are transformed using the trained neural network to obtain output signals.", "Neural Networks for Transforming Signals "]
["A method and device for voiceprint recognition, include: establishing a first-level Deep Neural Network (DNN) model based on unlabeled speech data, the unlabeled speech data containing no speaker labels and the first-level DNN model specifying a plurality of basic voiceprint features for the unlabeled speech data; obtaining a plurality of high-level voiceprint features by tuning the first-level DNN model based on labeled speech data, the labeled speech data containing speech samples with respective speaker labels, and the tuning producing a second-level DNN model specifying the plurality of high-level voiceprint features; based on the second-level DNN model, registering a respective high-level voiceprint feature sequence for a user based on a registration speech sample received from the user; and performing speaker verification for the user based on the respective high-level voiceprint feature sequence registered for the user.", "Method and device for voiceprint recognition "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating representation of acoustic sequences. One of the methods includes: receiving an acoustic sequence, the acoustic sequence comprising a respective acoustic feature representation at each of a plurality of time steps; processing the acoustic feature representation at an initial time step using an acoustic modeling neural network; for each subsequent time step of the plurality of time steps: receiving an output generated by the acoustic modeling neural network for a preceding time step, generating a modified input from the output generated by the acoustic modeling neural network for the preceding time step and the acoustic representation for the time step, and processing the modified input using the acoustic modeling neural network to generate an output for the time step; and generating a phoneme representation for the utterance from the outputs for each of the time steps.", "Generating representations of acoustic sequences "]
["Embodiments may provide methods by which fusion of information may be applied to uncertainty reduction in the results of classifier-based data analysis. For example, a method for data analysis may comprise generating a plurality of sets of data samples, each set of data samples representing a portion of input data at plurality of scales, each data sample in a set may represent the portion of the input data at a different scale and location, generating a feature map from each data sample of at least one set of data samples by learning and aggregating features using a first multi-layer convolutional processing, each data sample may be processed with multi-layer convolutional processing separately from other data samples, and generating a feature map by combining the feature maps from the data samples of each set of data samples by performing multiple-scale-multiple-location label fusion using a second multi-layer convolutional processing.", "Scale-space label fusion using two-stage deep neural net "]
["In an example embodiment, a deep convolutional neural network (DCNN) is created to assign a professionalism score to an input image. The professionalism score indicates a perceived professionalism of a subject of the input image. The DCNN is designed to automatically learn features of images relevant to the professionalism through a training process.", "Deep convolutional neural network prediction of image professionalism "]
["Context-based priors are utilized in machine learning networks (e.g., neural networks) for detecting objects in images. The likely locations of objects are estimated based on context labels. A machine learning network identifies a context label of an entire image. Based on the, the network selects a set of likely regions for detecting objects of interest in the image.", "Context-based priors for object detection in images "]
["Systems and methods for processing a query include determining a plurality of sets of match candidates for a query using a processor, each of the plurality of sets of match candidates being independently determined from a plurality of diverse word lattice generation components of different type. The plurality of sets of match candidates is merged by generating a first score for each match candidate to provide a merged set of match candidates. A second score is computed for each match candidate of the merged set based upon features of that match candidate. The first score and the second score are combined to provide a final set of match candidates as matches to the query.", "Classifier-based system combination for spoken term detection "]
["Embodiments are described for minimizing a wait time for a rider after sending a ride request for a vehicle. An example computer-implemented method includes receiving a ride request, the request being for travel from a starting location to a zone in a geographic region during a specified timeslot. The method further includes predicting travel demand based on a number of ride requests in the zone during the specified timeslot. The method further includes requesting transport of one or more vehicles to the zone in response to the predicted number of ride requests when the travel demand is predicted to exceed a number of vehicles in the zone during the specified timeslot.", "Neural network computing systems for predicting vehicle requests "]
["This application provides a target detection method and device based on a neural network and training method and device of a neural network for target detection. The target detection method comprises: acquiring a to-be-detected image that contains a target;acquiring first feature information of the to-be-detected image by use of a first neural network, acquiring second feature information of the to-be-detected image by use of a second neural network;combining the first feature information and the second feature information to acquire combined feature information; and acquiring a target detection result by use of the second neural network and based on the combined feature information, wherein the number of layers of the second neural network is larger than the number of layers of the first neural network, the first feature information is heatmap feature information, and the second feature information is picture feature information.", "Target detection method and device, neural network training method and device "]
["Systems, devices, and methods are disclosed for determining the quality of traffic received from different web page publishers, and setting a pricing structure for the different traffic based on the determined quality of traffic. Accurately determining the quality of traffic and/or clicks from different publishers allows the network system described herein to offer a fair marketplace with just return on investments (ROI) for advertisers, and offer a robust and accurate traffic quality based pricing model for publishers. Internet based technology, and in particular deep learning techniques available through a neural network, are utilized to determine the pricing structure based on click and/or web page traffic quality measurements generated through the deep learning techniques.", "System and Method for Traffic Quality Based Pricing via Deep Neural Language Models "]
["The invention refers to a method and system for parsing a medical image, comprising the steps of:\n- Providing (61) a network, being a multi-task deep neural network\n- Providing (62) the image to be parsed\n- Pre-determining (63) image features derived from the image\n- Defining (64)\n- a main task for image parsing and\n- adjuvant tasks for reconstruction of the image features\n\n- Applying (65) a multi-task learning pipeline to train the network by simultaneously learning the deep neural multi-task network on main and adjuvant tasks in a supervised manner, and to perform multi-tasks prediction, wherein the adjuvant tasks act as regularization of the network during a training phase and are used for deriving an in-build, automatic confidence estimation during a prediction phase.", "Medical image segmentation with a multi-task neural network system "]
["A method and system detects actions of an object in a scene by first acquiring a video of the scene as a sequence of images, wherein each image includes pixels, wherein the video is partitioned into chunks. The object in the video is tracked. For each object and each chunk of the video, trajectories of the pixels within a bounding box located over the object are tracked, and cropped trajectories and cropped images for one or more images in the chunk are produced using the bounding box. Then, the cropped trajectories and cropped images are passed to a recurrent neural network (RNN) that outputs a relative score for each action of interest.", "Method and System for Detecting Actions in Videos "]
["A method for determining depth to basement from aeromagnetic data utilizes neural networks to automate the laborious process of profile interpretation. The neural networks provide consistency, accuracy and overall quality without bias of interpretation.", "Neural network interpretation of aeromagnetic data "]
["A learning method for a multilayer neural network, implemented by a computer, includes starting first learning with an initial value of a learning rate, and maintaining the learning rate at the initial value or reducing the learning rate from the initial value as the first learning progresses. The learning rate is increased after the first learning. Second learning is started with the increased learning rate, and the increased learning rate is reduced as the second learning progresses.", "Learning method and apparatus, and recording medium "]
[null, "Learning and distributed based on the depth semantic feature information extraction system and method for medical "]
["Techniques related to eye contact correction to provide a virtual user gaze aligned with a camera while the user views a display are discussed. Such techniques may include encoding an eye region of a source image using a pretrained neural network to generate compressed features, applying a pretrained classifier to the features to determine a motion vector field for the eye region, and warping and inserting the eye region into the source image to generate an eye contact corrected image.", "Eye contact correction in real time using neural network based machine learning "]
["An apparatus and method for gesture detection and recognition. The apparatus includes a processing element, a radar sensor, a depth sensor, and an optical sensor. The radar sensor, the depth sensor, and the optical sensor are coupled to the processing element, and the radar sensor, the depth sensor, and the optical sensor are configured for short range gesture detection and recognition. The processing element is further configured to detect and recognize a hand gesture based on data acquired with the radar sensor, the depth sensor, and the optical sensor.", "Multi-sensor based user interface "]
["Described are systems, methods, and computer-readable media for program generation in a domain-specific language based on input-output examples. In accordance with various embodiments, a neural-network-based program generation model conditioned on an encoded set of input-output examples is used to generate a program tree by iteratively expanding a partial program tree, beginning with a root node and ending when all leaf nodes are terminal.", "Neural network for program synthesis "]
["Optimized learning settings of neural networks are efficiently determined by an apparatus including a processor and one or more computer readable mediums collectively including instructions that, when executed by the processor, cause the processor to train a first neural network with a learning setting; extract tentative weight data from the first neural network with the learning setting; calculate an evaluation value of the first neural network with the learning setting; and generate a predictive model for predicting an evaluation value of a second neural network with a new setting based on tentative weight data of the second neural network by using a relationship between the tentative weight data of the first neural network and the evaluation value of the first neural network.", "Efficient determination of optimized learning settings of neural networks "]
["According to one embodiment, a system includes a sensor component and a detection component. The sensor component is configured to obtain a first stream of sensor data and a second stream of sensor data, wherein each of the first stream and second stream comprise a plurality of sensor frames. The detection component is configured to generate a concatenated feature map based on a sensor frame of a first type and a sensor frame of a second type. The detection component is configured to detect one or more objects based on the concatenated feature map. One or more of generating and detecting comprises generating or detecting using a neural network with a recurrent connection that feeds information about features or objects from previous frames.", "Object Detection Using Recurrent Neural Network And Concatenated Feature Map "]
["A method and apparatus of video coding incorporating Deep Neural Network are disclosed. A target signal is processed using DNN (Deep Neural Network), where the target signal provided to DNN input corresponds to the reconstructed residual, output from the prediction process, the reconstruction process, one or more filtering processes, or a combination of them. The output data from DNN output is provided for the encoding process or the decoding process. The DNN can be used to restore pixel values of the target signal or to predict a sign of one or more residual pixels between the target signal and an original signal. An absolute value of one or more residual pixels can be signalled in the video bitstream and used with the sign to reduce residual error of the target signal.", "Method and apparatus of neural network based processing in video coding "]
["Neural network specific hardware acceleration optimizations are disclosed, including an optimized multicast network and an optimized DRAM transfer unit to perform in constant or linear time. The multicast network is a set of switch nodes organized into layers and configured to operate as a Bene{hacek over (s)} network. Configuration data may be accessed by all switch nodes in the network. Each layer is configured to perform a Bene{hacek over (s)} network transformation of the -previous layer within a computer instruction. Since the computer instructions are pipelined, the entire network of switch nodes may be configured in constant or linear time. Similarly a DRAM transfer unit configured to access memory in strides organizes memory into banks indexed by prime or relatively prime number amounts. The index value is selected as not to cause memory address collisions. Upon receiving a memory specification, the DRAM transfer unit may calculate out strides thereby accessing an entire tile of a tensor in constant or linear time.", "Multicast network and memory transfer optimizations for neural network hardware acceleration "]
[null, "Traffic sign recognizing method based on multi-resolution convolution neural networks "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing speaker identification. In some implementations, an utterance vector that is derived from an utterance is obtained. Hash values are determined for the utterance vector according to multiple different hash functions. A set of speaker vectors from a plurality of hash tables is determined using the hash values, where each speaker vector was derived from one or more utterances of a respective speaker. The speaker vectors in the set are compared with the utterance vector. A speaker vector is selected based on comparing the speaker vectors in the set with the utterance vector.", "Speaker identification "]
["A method distinguishes components of an acoustic signal by processing the signal to estimate a set of analysis features, wherein each analysis feature defines an element of the signal and has feature values that represent parts of the signal, processing the signal to estimate input features of the signal, and processing the input features using a deep neural network to assign an associative descriptor to each element of the signal, wherein a degree of similarity between the associative descriptors of different elements is related to a degree to which the parts of the signal represented by the elements belong to a single component of the signal. The the similarities between associative descriptors are processed to estimate correspondences between the elements of the signal and the components in the signal. Then, the signal is processed using the correspondences to distinguish component parts of the signal.", "Method for distinguishing components of an acoustic signal "]
[null, "Method for detecting fault of electric power equipment based on deep neural network "]
["Methods, systems, and computer programs are provided for training a front-end neural network (\u201cfront-end NN\u201d) and a back-end neural network (\u201cback-end NN\u201d). The method includes: combining the back-end NN with the front-end NN so that an output layer of the front-end NN is also an input layer of the back-end NN to form a joint layer to thereby generate a combined NN; and training the combined NN for a speech recognition with a set of utterances as training data, a plurality of specific units in the joint layer being dropped during the training and the plurality of the specific units corresponding to one or more common frequency bands. The front-end NN may be configured to estimate clean frequency filter bank features from noisy input features; or, to estimate clean frequency filter bank features from noisy frequency filter bank input features in the same feature space.", "Training of front-end and back-end neural networks "]
["A convolutional neural network comprises a plurality of artificial neurons arranged in one or more convolution layers, each convolution layer comprising one or more output matrices, each output matrix comprising a set of output neurons, each output matrix being connected to an input matrix, comprising a set of input neurons, by artificial synapses associated with a convolution matrix. The convolution matrix comprises the weight coefficients associated with the output neurons of the output matrix, the output value of each output neuron being determined from the input neurons of the input matrix to which the output neuron is connected and the weight coefficients of the convolution matrix associated with the output matrix. Each synapse consists of a set of memristive devices comprising at least one memristive device, each set of memristive devices storing a weight coefficient of the convolution matrix. In response to a change of the output value of an input neuron of an input matrix, the neural network is capable of dynamically associating each set of memristive devices storing a coefficient of the convolution matrix with an output neuron connected to the input neuron. The neural network further comprises an accumulator for each output neuron, the accumulator being configured to accumulate the values of the weight coefficients stored in the sets of memristive devices dynamically associated with the output neuron, the output value of the output neuron being determined from the value accumulated in the accumulator.", "Convolutional neural network "]
[null, "Method for implementing artificial neural networks in neuromorphic hardware "]
["A neural network is structured to connect the input values of an input set, at each level, to that level's output using a linear bypass connection. The linear bypass connection passes the input values, to the output, without applying a non-linear function to them.", "Linearly augmented neural network "]
["A dermoscopic lesion area is identified by: Obtaining a dermoscopic image and running a convolutional neural network image classifier on the dermoscopic image to obtain pixelwise lesion prediction scores. Segmenting the dermoscopic image into super-pixels, and computing for each super-pixel an average of the pixelwise prediction scores for pixels within that super-pixel. Computing a mean prediction score across the plurality of super-pixels. Assigning a confidence indicator of \u201c1\u201d to each super-pixel with a prediction score equal or greater than the mean prediction score, and a confidence indicator of \u201c0\u201d to each super-pixel with a prediction score less than the mean prediction score. Constructing a super-pixel graph G=(V,E,W) wherein", "Skin lesion segmentation using deep convolution networks guided by local unsupervised learning "]
["A technique relates a resistive processing unit (RPU) array. A set of conductive column wires are configured to form cross-points at intersections between the set of conductive row wires and a set of conductive column wires. Two-terminal RPUs are hysteretic such that the two-terminal RPUs each have a conductance state defined by hysteresis, where a two-terminal RPU of the two-terminal RPUs is located at each of the cross-points.", "Resistive processing unit with hysteretic updates for neural network training "]
[null, "Deep wavelet neural network-based polarimetric SAR (synthetic aperture radar) image classification method "]
["Systems and methods that receive as input microscopy images, extract features, and apply layers of processing units to compute one or more set of cellular phenotype features, corresponding to cellular densities and/or fluorescence measured under different conditions. The system is a neural network architecture having a convolutional neural network followed by a multiple instance learning (MIL) pooling layer. The system does not necessarily require any segmentation steps or per cell labels as the convolutional neural network can be trained and tested directly on raw microscopy images in real-time. The system computes class specific feature maps for every phenotype variable using a fully convolutional neural network and uses multiple instance learning to aggregate across these class specific feature maps. The system produces predictions for one or more reference cellular phenotype variables based on microscopy images with populations of cells.", "System and method for classifying and segmenting microscopy images with deep multiple instance learning "]
["A system for estimating the location of a stationary or moving sound source includes multiple microphones, which need not be physically aligned in a linear array or a regular geometric pattern in a given environment, an auralizer that generates auralized multi-channel signals based at least on array-related transfer functions and room impulse responses of the microphones as well as signal labels corresponding to the auralized multi-channel signals, a feature extractor that extracts features from the auralized multi-channel signals for efficient processing, and a neural network that can be trained to estimate the location of the sound source based at least on the features extracted from the auralized multi-channel signals and the corresponding signal labels.", "Sound source estimation using neural networks "]
[null, "Chinese license plate recognition method based on convolutional neural network "]
[null, "Fine-grained convolutional neural network-based clothes recommendation method "]
["According to an aspect a method includes configuring a convolutional neural network (CNN) for classifying text based on word embedding features into a predefined set of classes identified by class labels. The predefined set of classes includes a class labeled none-of-the-above for text that does not fit into any of the other classes in the predefined set of classes. The CNN is trained based on a set of training data. The training includes learning parameters of class distributed vector representations (DVRs) of each of the predefined set of classes. The learning includes minimizing a pair-wise ranking loss function over the set of training data. A class embedding matrix of the class DVRs of the predefined set of classes that excludes a class embedding for the none-of-the-above class is generated. Each column in the class embedding matrix corresponds to one of the predefined classes.", "Text classification by ranking with convolutional neural networks "]
["Systems, devices, media, and methods are presented for identifying and categorically labeling objects within a set of images. The systems and methods receive an image depicting an object of interest, detect at least a portion of the object of interest within the image using a multilayer object model, determine context information, and identify the object of interest included in two or more bounding boxes.", "Neural network for object detection in images "]
["A method, computer readable medium, and system are disclosed for implementing a temporal ensembling model for training a deep neural network. The method for training the deep neural network includes the steps of receiving a set of training data for a deep neural network and training the deep neural network utilizing the set of training data by: analyzing the plurality of input vectors by the deep neural network to generate a plurality of prediction vectors, and, for each prediction vector in the plurality of prediction vectors corresponding to the particular input vector, computing a loss term associated with the particular input vector by combining a supervised component and an unsupervised component according to a weighting function and updating the target prediction vector associated with the particular input vector.", "Temporal ensembling for semi-supervised learning "]
[null, "Method for establishing syntactic analysis model using deep learning and apparatus for perforing the method "]
["Providing a framework for merging automatic speech recognition (ASR) systems having a shared deep neural network (DNN) feature transformation is provided. A received utterance may be evaluated to generate a DNN-derived feature from the top hidden layer of a DNN. The top hidden layer output may then be utilized to generate a network including a bottleneck layer and an output layer. Weights representing a feature dimension reduction may then be extracted between the top hidden layer and the bottleneck layer. Scores may then be generated and combined to merge the ASR systems which share the DNN feature transformation.", "Shared hidden layer combination for speech recognition systems "]
[null, "Multi-floor positioning method and server based on wifi "]
["A computer-implemented method includes receiving, by a computing device, input activations and determining, by a controller of the computing device, whether each of the input activations has either a zero value or a non-zero value. The method further includes storing, in a memory bank of the computing device, at least one of the input activations. Storing the at least one input activation includes generating an index comprising one or more memory address locations that have input activation values that are non-zero values. The method still further includes providing, by the controller and from the memory bank, at least one input activation onto a data bus that is accessible by one or more units of a computational array. The activations are provided, at least in part, from a memory address location associated with the index.", "Exploiting input data sparsity in neural network compute units "]
["A framework for supporting therapy planning is described herein. In accordance with one aspect, patient-specific characteristics are extracted from medical data associated with a given patient. The framework may then search a database for one or more other patients associated with personal characteristics that are similar to the patient-specific characteristics. Information associated with the one or more other patients may be presented to support therapy planning or diagnosis.", "Patient-Specific Therapy Planning Support Using Patient Matching "]
[null, "Method and Apparatus for deep learning based algorithm for speech intelligibility prediction of vocoders "]
["A method for producing a graph representation of an input image, the method including the procedures of applying convolutional layers of a trained convolutional neural network on the input image, defining a receptive field of a last convolutional layer of the trained convolutional neural network as a vertex of the graph representation, defining a vector of a three dimensional output matrix of the last convolutional layer that is mapped to the receptive field as a descriptor for the vertex and determining an edge between a pair of vertices of the graph representation by applying an operator on a pair of descriptors respective of the pair of vertices.", "Graph image representation from convolutional neural networks "]
["Deep machine learning methods and apparatus related to manipulation of an object by an end effector of a robot. Some implementations relate to training a semantic grasping model to predict a measure that indicates whether motion data for an end effector of a robot will result in a successful grasp of an object; and to predict an additional measure that indicates whether the object has desired semantic feature(s). Some implementations are directed to utilization of the trained semantic grasping model to servo a grasping end effector of a robot to achieve a successful grasp of an object having desired semantic feature(s).", "Deep machine learning methods and apparatus for robotic grasping "]
["Apparatuses and methods of manufacturing same, systems, and methods for performing network parameter quantization in deep neural networks are described. In one aspect, multi-dimensional vectors representing network parameters are constructed from a trained neural network model. The multi-dimensional vectors are quantized to obtain shared quantized vectors as cluster centers, which are fine-tuned. The fine-tuned and shared quantized vectors/cluster centers are then encoded. Decoding reverses the process.", "Method and apparatus for neural network quantization "]
[null, "Optimization of data center controllers using neural networks "]
[null, "Deep-learning based morpheme analysis device and method of operating morpheme analysis application "]
["A system receives monaural sound which includes speech and background noises. The received sound is divided by frequency and time into time-frequency units (TFUs). Each TFU is classified as speech or non-speech by a processing unit. The processing unit for each frequency range includes at least one of a deep neural network (DNN) or a linear support vector machine (LSVM). The DNN extracts and classifies the features of the TFU and includes a pre-trained stack of Restricted Boltzmann Machines (RBM), and each RBM includes a visible and a hidden layer. The LSVM classifies each TFU based on extracted features from the DNN, including those from the visible layer of the first RBM, and those from the hidden layer of the last RBM in the stack. The LSVM and DNN include training with a plurality of training noises. Each TFU classified as speech is output.", "Monaural speech filter "]
["A method for classifying images using a neural network is described. The method utilizes the neural network to generate a deep hash data structure. In one embodiment, the method includes receiving, at a neural network, first data corresponding to a plurality of images of a training image set. The method includes adjusting parameters of the neural network based on concurrent application at the neural network of multiple loss functions to second data corresponding to the plurality of images to generate adjusted parameters. The method includes generating a deep hash data structure based on the adjusted parameters of the neural network. The method further includes sending, via a transmitter to a device, third data corresponding to the deep hash data structure.", "Image hash codes generated by a neural network "]
["An object recognition system can be adapted to recognize subject matter having very few features or limited or no texture. A feature-sparse or texture-limited object can be recognized by complementing local features and/or texture features with color, region-based, shape-based, three-dimensional (3D), global, and/or composite features. Machine learning algorithms can be used to classify such objects, and image matching and verification can be adapted to the classification. Further, multiple modes of input can be integrated at various stages of the object recognition processing pipeline. These multi-modal inputs can include user feedback, additional images representing different perspectives of the object or specific regions of the object including a logo or text corresponding to the object, user behavior data, location, among others.", "Object recognition of feature-sparse or texture-limited subject matter "]
["The technical disclosure relates to artificial neural network. In particular, the technical disclosure relates to how to implement efficient data access control in the neural network hardware acceleration system. Specifically, it proposes an overall design of a device that can process data receiving, bit-width transformation and data storing. By employing the technical disclosure, neural network hardware acceleration system can avoid the data access process becomes the bottleneck in neural network computation.", "Efficient Data Access Control Device for Neural Network Hardware Acceleration System "]
["Object detection and across disparate fields of view are provided. A first image generated by a first recording device with a first field of view, and a second image generated by a second recording device with a second field of view can be obtained. An object detection component can detect a first object within the first field of view, and a second object within the second field of view. An object classification component can determine first and second level classification categories of the first object. Object components can correlate the first object with the second object based on the descriptor of the first object or a descriptor of the second object, and can determine a characteristic or the first object or the second object based on the correlation.", "Object detection and classification "]
["A method and system for classification of endoscopic images is disclosed. An initial trained deep network classifier is used to classify endoscopic images and determine confidence scores for the endoscopic images. The confidence score for each endoscopic image classified by the initial trained deep network classifier is compared to a learned confidence threshold. For endoscopic images with confidence scores higher than the learned threshold value, the classification result from the initial trained deep network classifier is output. Endoscopic images with confidence scores lower than the learned confidence threshold are classified using a first specialized network classifier built on a feature space of the initial trained deep network classifier.", "Method and system for classification of endoscopic images using deep decision networks "]
["Features are disclosed for improving the robustness of a neural network by using multiple (e.g., two or more) feature streams, combing data from the feature streams, and comparing the combined data to data from a subset of the feature streams (e.g., comparing values from the combined feature stream to values from one of the component feature streams of the combined feature stream). The neural network can include a component or layer that selects the data with the highest value, which can suppress or exclude some or all corrupted data from the combined feature stream. Subsequent layers of the neural network can restrict connections from the combined feature stream to a component feature stream to reduce the possibility that a corrupted combined feature stream will corrupt the component feature stream.", "Neural network processing of multiple feature streams using max pooling and restricted connectivity "]
[null, "Multi-layered neuron array for deep belief network and neuron array operating method "]
["A parallel convolutional neural network is provided. The CNN is implemented by a plurality of convolutional neural networks each on a respective processing node. Each CNN has a plurality of layers. A subset of the layers are interconnected between processing nodes such that activations are fed forward across nodes. The remaining subset is not so interconnected.", "System and method for parallelizing convolutional neural networks "]
["For image quality scoring of an image from a medical scanner, a generative model of an expected good quality image may be created using deep machine-learning. The deviation of an input image from the generative model is used as an input feature vector for a discriminative model. The discriminative model may also operate on another input feature vector derived from the input image. Based on these input feature vectors, the discriminative model outputs an image quality score.", "Image Quality Score Using A Deep Generative Machine-Learning Model "]
["A content-aware speaker recognition system includes technologies to, among other things, analyze phonetic content of a speech sample, incorporate phonetic content of the speech sample into a speaker model, and use the phonetically-aware speaker model for speaker recognition.", "Content-Aware Speaker Recognition "]
[null, "Modeling approach and modeling system of acoustic model used in speech recognition "]
["A method and a device for training a DNN model includes: at a device including one or more processors and memory: establishing an initial DNN model; dividing a training data corpus into a plurality of disjoint data subsets; for each of the plurality of disjoint data subsets, providing the data subset to a respective training processing unit of a plurality of training processing units operating in parallel, wherein the respective training processing unit applies a Stochastic Gradient Descent (SGD) process to update the initial DNN model to generate a respective DNN sub-model based on the data subset; and merging the respective DNN sub-models generated by the plurality of training processing units to obtain an intermediate DNN model, wherein the intermediate DNN model is established as either the initial DNN model for a next training iteration or a final DNN model in accordance with a preset convergence condition.", "Method and device for parallel processing in model training "]
["A system for applying video data to a neural network (NN) for online multi-class multi-object tracking includes a computer programed to perform an image classification method including the operations of receiving a video sequence; detecting candidate objects in each of a previous and a current video frame; transforming the previous and current video frames into a temporal difference input image; applying the temporal difference input image to a pre-trained neural network (NN) (or deep convolutional network) comprising an ordered sequence of layers; and based on a classification value received by the neural network, associating a pair of detected candidate objects in the previous and current frames as belonging to one of matching objects and different objects.", "Deep data association for online multi-class multi-object tracking "]
["A neural network apparatus (20) is provided with: a storage unit (24) that stores a neural network model; and an arithmetic unit (22) that inputs input information to the input layer of the neural network and outputs an output layer. A weight matrix (W) of an FC layer of the neural network model is configured with the product of a weight basis matrix (Mw) of integers and a weight coefficient matrix (Cw) of real numbers. The arithmetic unit (22) calculates, in the FC layer, the product of an input vector (x) and the weight matrix (W) by using an output vector from the preceding layer as the input vector (x) and by decomposing the input vector (x) into the product of a binary input basis matrix (Mx) and an input coefficient vector (cx) of a real number, and an input bias (bx).", "Neural network apparatus, vehicle control system, decomposition device, and program "]
["Systems and processes for language identification using recurrent neural networks are provided. An example method includes, at an electronic device, receiving a first typed character of a character sequence and determining a character context of the first typed character based on the first typed character and a second typed character of the character sequence. The method further includes determining a confidence level that the character sequence is associated with a language of a plurality of languages based on the character context of the first typed character, and determining whether the confidence level exceeds a threshold, in accordance with a determination that the confidence level exceeds the threshold, providing the language as a candidate language, and in accordance with a determination that the confidence level does not exceed the threshold, forgoing providing the language as a candidate language.", "Language identification using recurrent neural networks "]
[null, "System and method for evaluating multifaceted growth based on machine learning "]
[null, "Neural network training system and the neural network system "]
["A differential recurrent neural network (RNN) is described that handles dependencies that go arbitrarily far in time by allowing the network system to store states using recurrent loops without adversely affecting training. The differential RNN includes a state component for storing states, and a trainable transition and differential non-linearity component which includes a neural network. The trainable transition and differential non-linearity component takes as input, an output of the previous stored states from the state component along with an input vector, and produces positive and negative contribution vectors which are employed to produce a state contribution vector. The state contribution vector is input into the state component to create a set of current states. In one implementation, the current states are simply output. In another implementation, the differential RNN includes a trainable OUT component which includes a neural network that performs post-processing on the current states before outputting them.", "Differential recurrent neural network "]
[null, "Structure adaptive CNN (Convolutional Neural Network)-based face recognition method "]
["A method of maneuvering a vehicle in reverse for attachment to a trailer is disclosed. The method includes receiving one or more images from one or more cameras positioned on a back portion of the vehicle and identifying one or more trailers within the one or more images. The method also includes receiving an indication of a selected trailer from the one or more trailers. Additionally, the method includes determining a vehicle path from an initial position to a final position. The vehicle path includes maneuvers configured to direct the vehicle in a rearward direction along the vehicle path from the initial position to the final position. The method also includes executing one or more behaviors causing the vehicle to take an action to autonomously follow the vehicle path and execute the maneuvers.", "Autonomous Trailer Hitching Using Neural Network "]
["A method is disclosed herein that includes an act of causing a processor to receive a sample, wherein the sample is one of spoken utterance, an online handwriting sample, or a moving image sample. The method also comprises the act of causing the processor to decode the sample based at least in part upon an output of a combination of a deep structure and a context-dependent Hidden Markov Model (HMM), wherein the deep structure is configured to output a posterior probability of a context-dependent unit. The deep structure is a Deep Belief Network consisting of many layers of nonlinear units with connecting weights between layers trained by a pretraining step followed by a fine-tuning step.", "Deep belief network for large vocabulary continuous speech recognition "]
["A method for improving performance of a trained machine learning model includes adding a second classifier with a second objective function to a first classifier with a first objective function. Rather than minimizing a function of errors for the first classifier, the second objective function is used to directly reduce the number errors of the first classifier.", "Method for improving performance of a trained machine learning model "]
["A method, system, and computer program product for learning a recognition model for recognition processing. The method includes preparing one or more examples for learning, each of which includes an input segment, an additional segment adjacent to the input segment and an assigned label. The input segment and the additional segment are extracted from an original training data. A classification model is trained, using the input segment and the additional segment in the examples, to initialize parameters of the classification model so that extended segments including the input segment and the additional segment are reconstructed from the input segment. Then, the classification model is tuned to predict a target label, using the input segment and the assigned label in the examples, based on the initialized parameters. At least a portion of the obtained classification model is included in the recognition model.", "Learning a model for recognition processing "]
["A memory-centric neural network system and operating method thereof includes: a processing unit; semiconductor memory devices coupled to the processing unit, the semiconductor memory devices contain instructions executed by the processing unit; weight matrixes including a positive weight matrix and a negative weight matrix constructed with rows and columns of memory cells, inputs of the memory cells of a same row are connected to one of Axons, outputs of the memory cells of a same column are connected to one of Neurons; timestamp registers registering timestamps of the Axons and the Neurons; and a lookup table containing adjusting values indexed in accordance with the timestamps, the processing unit updates the weight matrixes in accordance with the adjusting values.", "Neural network hardware accelerator architectures and operating method thereof "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media for acoustic modeling of audio data. One method includes receiving audio data representing a portion of an utterance, providing the audio data to a trained recurrent neural network that has been trained to indicate the occurrence of a phone at any of multiple time frames within a maximum delay of receiving audio data corresponding to the phone, receiving, within the predetermined maximum delay of providing the audio data to the trained recurrent neural network, output of the trained neural network indicating a phone corresponding to the provided audio data using output of the trained neural network to determine a transcription for the utterance, and providing the transcription for the utterance.", "Latency constraints for acoustic modeling "]
["Methods and apparatus for extending a neural network, reducing its dimension and processing input data are provided. The method of extending a neural network involves selecting, with a processor, a node of a neural network, adding a new node in a layer that includes the selected node, and setting connection weights of the new node based on connection weights of the selected node.", "Method and apparatus for extending neural network "]
["A method and neural network system for human-computer interaction, and user equipment are disclosed. According to the method for human-computer interaction, a natural language question and a knowledge base are vectorized, and an intermediate result vector that is based on the knowledge base and that represents a similarity between a natural language question and a knowledge base answer is obtained by means of vector calculation, and then a fact-based correct natural language answer is obtained by means of calculation according to the question vector and the intermediate result vector. By means of this method, a dialog and knowledge base-based question-answering are combined by means of vector calculation, so that natural language interaction can be performed with a user, and a fact-based correct natural language answer can be given according to the knowledge base.", "Method and neural network system for human-computer interaction, and user equipment "]
[null, "Species binary convolution means and the corresponding binary convolutional neural network processor "]
["Systems, methods, and computer readable media related to information retrieval. Some implementations are related to training and/or using a relevance model for information retrieval. The relevance model includes an input neural network model and a subsequent content neural network model. The input neural network model and the subsequent content neural network model can be separate, but trained and/or used cooperatively. The input neural network model and the subsequent content neural network model can be \u201cseparate\u201d in that separate inputs are applied to the neural network models, and each of the neural network models is used to generate its own feature vector based on its applied input. A comparison of the feature vectors generated based on the separate network models can then be performed, where the comparison indicates relevance of the input applied to the input neural network model to the separate input applied to the subsequent content neural network model.", "Cooperatively training and/or using separate input and subsequent content neural networks for information retrieval "]
["A neural network recognition method includes obtaining a first neural network that includes layers and a second neural network that includes a layer connected to the first neural network, actuating a processor to compute a first feature map from input data based on a layer of the first neural network, compute a second feature map from the input data based on the layer connected to the first neural network in the second neural network, and generate a recognition result based on the first neural network from an intermediate feature map computed by applying an element-wise operation to the first feature map and the second feature map.", "Neural network based recognition apparatus and method of training neural network "]
["The present embodiments relate to denoising medical images. By way of introduction, the present embodiments described below include apparatuses and methods for machine learning sparse image representations with deep unfolding and deploying the machine learnt network to denoise medical images. Iterative thresholding is performed using a deep neural network by training each layer of the network as an iteration of an iterative shrinkage algorithm. The deep neural network is randomly initialized and trained independently with a patch-based approach to learn sparse image representations for denoising image data. The different layers of the deep neural network are unfolded into a feed-forward network trained end-to-end.", "Denoising medical images by learning sparse image representations with a deep unfolding approach "]
["The present invention proposes a highly parallel solution for implementing ANN by sharing both weights matrix of ANN and input activation vectors. It significantly reduces the memory access operations, the on-chip buffers. In addition, the present invention considers how to achieve a load balance among a plurality of on-chip processing units being operated in parallel. It also considers a balance between the I/O bandwidth and calculation capabilities of the processing units.", "Device and method for implementing a sparse neural network "]
[null, "Species binary convolutional neural network processor and method of use "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating acoustic models. In some implementations, a first neural network trained as an acoustic model using the connectionist temporal classification algorithm is obtained. Output distributions from the first neural network are obtained for an utterance. A second neural network is trained as an acoustic model using the output distributions produced by the first neural network as output targets for the second neural network. An automated speech recognizer configured to use the trained second neural network is provided.", "Generating acoustic models "]
[null, "A system for deep reinforcement learning for robotic manipulation "]
["Systems and methods provide a learned difference metric that operates in a wide artifact space. An example method includes initializing a committee of deep neural networks with labeled distortion pairs, iteratively actively learning a difference metric using the committee and psychophysics tasks for informative distortion pairs, and using the difference metric as an objective function in a machine-learned digital file processing task. Iteratively actively learning the difference metric can include providing an unlabeled distortion pair as input to each of the deep neural networks in the committee, a distortion pair being a base image and a distorted image resulting from application of an artifact applied to the base image, obtaining a plurality of difference metric scores for the unlabeled distortion pair from the deep neural networks, and identifying the unlabeled distortion pair as an informative distortion pair when the difference metric scores satisfy a diversity metric.", "Difference metric for machine learning-based processing systems "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes training a neural network using sharp discrepancy learning by providing training data to the neural network, calculating a gradient using a sharp discrepancy output layer objective function to classify the neural network parameters for correct and incorrect network model states, and training the neural network using the gradient to determine a probability that data received by the neural network has features similar to key features of one or more keywords or key phrases.", "Sharp discrepancy learning "]
["According to one embodiment, a first set of features is received, where each of the features in the first set being associated with a predetermined category. A bloom filter is applied to the first set of features to generate a second set of features. A neural network model is trained by applying the second set of features to a first layer of nodes of the neural network model to generate an output, the neural network model including a plurality of layers of nodes coupled to each other via a connection. The output of the neural network model is compared with a target value associated with the predetermined category to determine whether the neural network model satisfies a predetermined condition.", "Method and system for training and neural network models for large number of discrete features for information rertieval "]
["Systems and methods provide a deep neural network trained via active learning. An example method includes generating, from a set of labeled objects, a plurality of differing training sets, assigning each of the plurality of training sets to a respective deep neural network in a committee of networks, and initializing each of the deep neural networks in the committee by training the deep neural network using the respective assigned training set. The method further includes iteratively training the deep neural networks in the committee until convergence and using one of the deep neural networks to make predictions for unlabeled objects. The training may include identifying unlabeled objects with highest diversity in predictions from the plurality of deep neural networks, obtaining a respective label for each identified unlabeled object, and retraining the deep neural networks with the respective labels for the objects.", "Active learning system "]
["Method of speech enhancement using Neural Network-based combined signal starts with training neural network offline which includes: (i) exciting at least one accelerometer and at least one microphone using training accelerometer signal and training acoustic signal, respectively. The training accelerometer signal and the training acoustic signal are correlated during clean speech segments. Training neural network offline further includes (ii) selecting speech included in the training accelerometer signal and in the training acoustic signal, and (iii) spatially localizing the speech by setting a weight parameter in the neural network based on the selected speech included in the training accelerometer signal and in the training acoustic signal. The neural network that is trained offline is then used to generate a speech reference signal based on an accelerometer signal from the at least one accelerometer and an acoustic signal received from the at least one microphone. Other embodiments are described.", "System and method for performing speech enhancement using a neural network-based combined symbol "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating object detection predictions from a neural network. In some implementations, an input characterizing a first region of an environment is obtained. The input includes a projected laser image generated from a three-dimensional laser sensor reading of the first region, a camera image patch generated from a camera image of the first region, and a feature vector of features characterizing the first region. The input is processed using a high precision object detection neural network to generate a respective object score for each object category in a first set of one or more object categories. Each object score represents a respective likelihood that an object belonging to the object category is located in the first region of the environment.", "Pedestrian detection neural networks "]
["A big data processing method for a segment-based two-grade deep learning model. The method includes: step (1), constructing and training a segment-based two-grade deep learning model, wherein the model is divided into two grades in a longitudinal level: a first grade and a second grade, each layer of the first grade is divided into M segments in a horizontal direction, and the weight between neuron nodes of adjacent layers in different segments of the first grade is zero; step (2), dividing big data to be processed into M sub-sets according to the type of the data and respectively inputting same into M segments of a first layer of the segment-based two-grade deep learning model for processing; and step (3), outputting a big data processing result. The method of the present invention can increase the big data processing speed and shorten the processing time.", "Big data processing method for segment-based two-grade deep learning model "]
["Regularization of neural networks. Neural networks can be regularized by obtaining an original neural network having a plurality of first-in-first-out (FIFO) queues, each FIFO queue located between a pair of nodes among a plurality of nodes of the original neural network, generating at least one modified neural network, the modified neural network being equivalent to the original neural network with a modified length of at least one FIFO queue, evaluating each neural network among the original neural network and the at least one modified neural network, and determining which neural network among the original neural network and the at least one modified neural network is most accurate, based on the evaluation.", "Regularization of neural networks "]
["Provided is a convolutional neural network system including a data selector configured to output an input value corresponding to a position of a sparse weight from among input values of input data on a basis of a sparse index indicating the position of a nonzero value in a sparse weight kernel, and a multiply-accumulate (MAC) computator configured to perform a convolution computation on the input value output from the data selector by using the sparse weight kernel.", "Convolutional neural network system and operation method thereof "]
[null, "Equipment for deep machine learning for robot grasping "]
[null, "Based on deep species on Extreme Learning Machine hazard identification method "]
["Data indicative of a plurality of observations of an environment are received at a control system. Machine learning using deep reinforcement learning is applied to determine an action based on the observations. The deep reinforcement learning applies a convolutional neural network or a deep auto encoder to the observations and applies a training set to locate one or more regions having a higher reward. The action is applied to the environment. A reward token indicative of alignment between the action and a desired result is received. A policy parameter of the control system is updated based on the reward token. The updated policy parameter is applied to determine a subsequent action responsive to a subsequent observation.", "Control systems using deep reinforcement learning "]
["The present disclosure provides systems and methods that use machine-learned models, such as deep neural networks, to predict and prevent adverse conditions at structural assets. One example method includes obtaining data descriptive of a plurality of images that depict at least a portion of a geographic area that contains a first structural asset. The plurality of images include at least a first image captured at a first time and a second image captured at a second time that is different than the first time. The method includes inputting data descriptive of at least the first image, the first time, the second image, and the second time into a condition prediction model. The method includes receiving, as an output of the condition prediction model, at least one prediction regarding the occurrence of an adverse condition at the first structural asset during one or more future time periods.", "Deep Machine Learning to Predict and Prevent Adverse Conditions at Structural Assets "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for processing audio waveforms. In some implementations, a time-frequency feature representation is generated based on audio data. The time-frequency feature representation is input to an acoustic model comprising a trained artificial neural network. The trained artificial neural network comprising a frequency convolution layer, a memory layer, and one or more hidden layers. An output that is based on output of the trained artificial neural network is received. A transcription is provided, where the transcription is determined based on the output of the acoustic model.", "Processing audio waveforms "]
["Disclosed are a photovoltaic assembly accelerated degradation model established based on a deep approach of learning, and a method for predicting photovoltaic assembly lifetime. This method establishes a deep neural network (DNN) via a restricted boltzmann machine (RBM), takes different accelerated stress conditions (T i, H i and R ai) and the corresponding pseudo-failure lifetime distribution quantile function Q i(p) as input vectors, uses a CD fast learning algorithm to train the RBM and the DNN, seeks a model optimal parameter set \u03b8 *, and constructs a photovoltaic assembly accelerated degradation model, thereby predicting an expected working life of the photovoltaic assembly under normal stress conditions.", "Photovoltaic assembly accelerated degradation model established based on deep approach of learning, and method for predicting photovoltaic assembly lifetime "]
["An approach for performing mobile visual search uses deep variant coding of images to reduce the amount of data transmitted from mobile devices to a search server and to provide more efficient indexing and searching on the search server. The amount of data used to represent an image varies depending upon the content of the image and is less than conventional fixed bit length hashing approaches. Denser regions of a feature space are represented by more encoding bits and sparser regions of the feature space are represented by fewer encoding bits, so that the overall number of encoding bits for an image feature is reduced. The approach generally involves determining a set of hash functions that provide deep hashing with more evenly-distributed hash buckets. One or more additional hash functions may be selectively generated for particular hash buckets that contain more than a specified number of images.", "Mobile visual search using deep variant coding "]
[null, "Face verification method based on deep convolutional neural network and evidence K nearest neighbor "]
["A system includes one or more computers and one or more storage devices storing instructions that when executed by the one or more computers cause the computers to implement a combined machine learning model for processing an input including multiple features to generate a predicted output for the machine learning input. The combined model includes: a deep machine learning model configured to process the features to generate a deep model output; a wide machine learning model configured to process the features to generate a wide model output; and a combining layer configured to process the deep model output generated by the deep machine learning model and the wide model output generated by the wide machine learning model to generate the predicted output, in which the deep model and the wide model have been trained jointly on training data to generate the deep model output and the wide model output.", "Wide and deep machine learning models "]
["An apparatus for achieving an accelerator of a sparse convolutional neural network is provided. The apparatus comprises a convolution and pooling unit, a full connection unit and a control unit. Convolution parameter information and input data and intermediate calculation data are read based on control information, and weight matrix position information of a full connection layer is also read. Then a convolution and pooling operation for a first iteration number of times is performed on the input data in accordance with the convolution parameter information, and then a full connection calculation for a second iteration number of times is performed in accordance with the weight matrix position information of the full connection layer. Each input data is divided into a plurality of sub-blocks, and the convolution and pooling unit and the full connection unit perform operations on the plurality of sub-blocks in parallel, respectively.", "Apparatus and Method for Achieving Accelerator of Sparse Convolutional Neural Network "]
["Described herein are systems and methods that receive as input a DNA or RNA sequence, extract features, and apply layers of processing units to compute one ore more condition-specific cell variables, corresponding to cellular quantities measured under different conditions. The system may be applied to a sequence containing a genetic variant, and also to a corresponding reference sequence to determine how much the condition-specific cell variables change because of the variant. The change in the condition-specific cell variables are used to compute a score for how deleterious a variant is, to classify a variant's level of deleteriousness, to prioritize variants for subsequent processing, and to compare a test variant to variants of known deleteriousness. By modifying the variant or the extracted features so as to incorporate the effects of DNA editing, oligonucleotide therapy, DNA- or RNA-binding protein therapy or other therapies, the system may be used to determine if the deleterious effects of the original variant can be reduced.", "Systems and methods for classifying, prioritizing and interpreting genetic variants and therapies using a deep neural network "]
["Embodiments disclose systems and methods that aid in screening, diagnosis and/or monitoring of medical conditions. The systems and methods may allow, for example, for automated identification and localization of lesions and other anatomical structures from medical data obtained from medical imaging devices, computation of image-based biomarkers including quantification of dynamics of lesions, and/or integration with telemedicine services, programs, or software.", "Systems and methods for automated interest region detection in retinal images "]
["Vehicles can be equipped to operate in both autonomous and occupant piloted mode. While operating in either mode, an array of sensors can be used to pilot the vehicle including stereo cameras and 3D sensors. Stereo camera and 3D sensors can also be employed to assist occupants while piloting vehicles. Deep convolutional neural networks can be employed to determine estimated depth maps from stereo images of scenes in real time for vehicles in autonomous and occupant piloted modes.", "Depth map estimation with stereo images "]
["Neural networks for object detection in images are used with a spatial pyramid pooling (SPP) layer. Using the SPP network structure, a fixed-length representation is generated regardless of image size and scale. The feature maps are computed from the entire image once, and the features are pooled in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. Thus, repeated computation of the convolutional features is avoided while accuracy is enhanced.", "Generic object detection in images "]
["Compressing a machine learning network, such as a neural network, includes replacing one layer in the neural network with compressed layers to produce the compressed network. The compressed network may be fine-tuned by updating weight values in the compressed layer(s).", "Model compression and fine-tuning "]
["A method and apparatus for automated vertebra localization and identification in a 3D computed tomography (CT) volumes is disclosed. Initial vertebra locations in a 3D CT volume of a patient are predicted for a plurality of vertebrae corresponding to a plurality of vertebra labels using a trained deep image-to-image network (DI2IN). The initial vertebra locations for the plurality of vertebrae predicted using the DI2IN are refined using a trained recurrent neural network, resulting in an updated set of vertebra locations for the plurality of vertebrae corresponding to the plurality of vertebrae labels. Final vertebra locations in the 3D CT volume for the plurality of vertebrae corresponding to the plurality of vertebra labels are determined by refining the updated set of vertebra locations using a trained shape-basis deep neural network.", "Deep Image-to-Image Recurrent Network with Shape Basis for Automatic Vertebra Labeling in Large-Scale 3D CT Volumes "]
["Systems, apparatus and methods are described including operations for a flexible neural network accelerator.", "Flexible neural network accelerator and methods therefor "]
["Systems and methods for eye image segmentation and image quality estimation are disclosed. In one aspect, after receiving an eye image, a device such as an augmented reality device can process the eye image using a convolutional neural network with a merged architecture to generate both a segmented eye image and a quality estimation of the eye image. The segmented eye image can include a background region, a sclera region, an iris region, or a pupil region. In another aspect, a convolutional neural network with a merged architecture can be trained for eye image segmentation and image quality estimation. In yet another aspect, the device can use the segmented eye image to determine eye contours such as a pupil contour and an iris contour. The device can use the eye contours to create a polar image of the iris region for computing an iris code or biometric authentication.", "Neural network for eye image segmentation and image quality estimation "]
["A system and method are provided for performing saliency detection on an image or video. The method includes training and creating deep features using deep neural networks, such that an input image is transformed into a plurality of regions, which minimizes intra-class variance, and maximizes inter-class variance, according to one or more active contour energy constraints. The method also includes providing and output associated with the deep features.", "System and Method for Performing Saliency Detection Using Deep Active Contours "]
["A method and apparatus are provided. The method includes receiving an image, detecting an object in the image, determining, by a primary object detector, a primary confidence detection score of the object, determining, by a classification network, a confidence scaling factor of the object, and adjusting the primary confidence detection score based on multiplying the primary confidence detection score by the confidence scaling factor.", "System and method for deep network fusion for fast and robust object detection "]
["A dosimetry system and method characterized by use a plurality of radiation sensitive elements to monitor exposure to a radiation field composed of one or more types of radiation at one or more different energies; reading the radiation sensitive elements in a reader after irradiation by the radiation field to obtain element outputs; and supplying the element outputs to a trained neural network computer apparatus wherein the element outputs are analyzed to provide an output indicative of the radiation field.", "Multi-element dosimetry system using neural network "]
["Techniques for adapting a trained neural network acoustic model, comprising using at least one computer hardware processor to perform: generating initial speaker information values for a speaker; generating first speech content values from first speech data corresponding to a first utterance spoken by the speaker; processing the first speech content values and the initial speaker information values using the trained neural network acoustic model; recognizing, using automatic speech recognition, the first utterance based, at least in part on results of the processing; generating updated speaker information values using the first speech data and at least one of the initial speaker information values and/or information used to generate the initial speaker information values; and recognizing, based at least in part on the updated speaker information values, a second utterance spoken by the speaker.", "System and methods for adapting neural network acoustic models "]
["Systems and methods for automated segmentation of anatomical structures (e.g., heart). Convolutional neural networks (CNNs) may be employed to autonomously segment parts of an anatomical structure represented by image data, such as 3D MRI data. The CNN utilizes two paths, a contracting path and an expanding path. In at least some implementations, the expanding path includes fewer convolution operations than the contracting path. Systems and methods also autonomously calculate an image intensity threshold that differentiates blood from papillary and trabeculae muscles in the interior of an endocardium contour, and autonomously apply the image intensity threshold to define a contour or mask that describes the boundary of the papillary and trabeculae muscles. Systems and methods also calculate contours or masks delineating the endocardium and epicardium using the trained CNN model, and anatomically localize pathologies or functional characteristics of the myocardial muscle using the calculated contours or masks.", "Automated segmentation utilizing fully convolutional networks "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using embedded function with a deep network. One of the methods includes receiving an input comprising a plurality of features, wherein each of the features is of a different feature type; processing each of the features using a respective embedding function to generate one or more numeric values, wherein each of the embedding functions operates independently of each other embedding function, and wherein each of the embedding functions is used for features of a respective feature type; processing the numeric values using a deep network to generate a first alternative representation of the input, wherein the deep network is a machine learning model composed of a plurality of levels of non-linear operations; and processing the first alternative representation of the input using a logistic regression classifier to predict a label for the input.", "Using embedding functions with a deep network "]
["A self-organizable neural network expressing unit includes a plurality of neuron units electronically expressing nerve cell bodies, and a plurality of synapse expressing units electronically expressing synapses for coupling neuron units through programmed coupling strengths represented by synapse load values, and a control circuit for supplying a pattern of random number data as an educator data. When the pattern of random number data is generated, the neural network expressing unit carries out correction of synapse load values as in a learning mode of operation using the pattern of random number data as an educator data. The memorized internal states in the neural network expressing unit is reinforced based on a faded memory thereof, and the synapse load values are precisely maintained for a long time, resulting in a reliable neural network expressing unit.", "Neural network expressing apparatus including refresh of stored synapse load value information "]
["Disclosed herein is a convolutional neural network (CNN) operation apparatus, including at least one channel hardware set suitable for performing a feature extraction layer operation and a classification layer operation based on input data and weight data, and a controller coupled to the channel hardware set. The controller may control the channel hardware set to perform the feature extraction layer operation and perform a classification layer operation when the feature extraction layer operation is completed.", "Operation apparatus and method for convolutional neural network "]
[null, "Method and device for classifying images on basis of convolutional neural network "]
["Apparatus and methods describe herein, for example, a process that can include receiving a potentially malicious file, and dividing the potentially malicious file into a set of byte windows. The process can include calculating at least one attribute associated with each byte window from the set of byte windows for the potentially malicious file. In such an instance, the at least one attribute is not dependent on an order of bytes in the potentially malicious file. The process can further include identifying a probability that the potentially malicious file is malicious, based at least in part on the at least one attribute and a trained threat model.", "Methods and apparatus for machine learning based malware detection "]
["The evolution of a skin condition over time can be useful in its assessment. In an illustrative arrangement, a user captures skin images at different times, using a smartphone. The images are co-registered, color-corrected, and presented to the user (or a clinician) for review, e.g., in a temporal sequence, or as one image presented as a ghosted overlay atop another. Image registration can employ nevi, hair follicles, wrinkles, pores, and pigmented regions as keypoints. With some imaging spectra, keypoints from below the outermost layer of skin can be used. Hair may be removed for image registration, and restored for image review. Transformations in addition to rotation and affine transforms can be employed. Diagnostic correlations with reference image sequences can be made, employing machine learning in some instances. A great variety of other features and arrangements are also detailed.", "Longitudinal dermoscopic study employing smartphone-based image registration "]
["A neural network computing device, system and method that operate with a synchronization circuit in which all components are synchronized with a system clock and include a distributed memory structure for storing artificial neural network data and a calculation structure for time-division processing of all neurons on a pipeline circuit. The neural network computing device may include: a control unit for controlling the neural network computing device; a plurality of memory units for outputting an output value of a front-end neuron of a connection line by using a dual port memory; and a calculation sub-system for calculating an output value of a rear-end neuron of a new connection line by using the output value of the front-end neuron of the connection line input from each of the plurality of memory units and for feeding the output value back to each of the plurality of memory units.", "Neural network computing device, system and method "]
["A system and method of image processing using neural networks to control image processing elements. Neural network parameters are defined by genotypes consisting of network vectors. Genotypes may be selectively mutated and cross-bred to provide a mechanism for modifying the behavior of the neural networks, or phenotypes. Genetic modeling processes are used to perform such mutation and cross-over. User feedback concerning output images, is used to select particular genotypes for further mutation and exploration. Preconditioning is employed to extract structural information from source images prior to network processing. Genetic morphing and subnet fusion are also available, to provide additional variations on image processing operations.", "Image processing using genetic mutation of neural network parameters "]
["This invention is an image retrieval method based on bit-scalable deep hashing learning. According to the method, the training images is used to generate a batch of image triples, wherein each of the triples contains two images with the same label and one image with a different label. The purpose of model training is to maximize a margin between matched image pairs and unmatched image pairs in the Hamming space. The deep convolutional neural network is utilized to train the model in an end-to-end fasion, where discriminative images features and has functions are simultaneously optimized. Furthermore, each bit of the hashing codes is unequally weighted so that we can manipulate the code length by truncating the insignificant bits. It is also shown that the generated bit-scalable hashing codes well preserve the discriminative powers with sorter code lengths.", "Image Retrieval Method Based on Variable-Length Deep Hash Learning "]
["There is disclosed a medical system comprising one or more sensors associated with one or more actuators. Various embodiments describe sensors and/or actuators, logic circuits, user interfaces, association schemes, communication schemes, security schemes, cryptographic schemes, medical management rules, social mechanisms, energy management schemes, time and/or space schemes, body analytes and/or biomarkers, blood glucose and/or interstitial glucose sensors, drug delivery devices, continuous glucose monitoring devices, as well as flash glucose monitoring devices. Methods, software and other hardware aspects are described.", "Medical systems, devices and methods "]
["Systems, methods, and non-transitory computer readable media can align face images, classify face images, and verify face images by employing a deep neural network (DNN). A 3D-aligned face image can be generated from a 2D face image. An identity of the 2D face image can be classified based on provision of the 3D-aligned face image to the DNN. The identity of the 2D face image can comprise a feature vector.", "Systems and methods for facial representation "]
["A system is disclosed for statistical modelling, interpolation, and user-feedback based inference of head-related transfer functions (HRTF) includes a processor performing operations that include using a collection of previously measured head related transfer functions for audio signals corresponding to multiple directions for at least one subject; and performing Gaussian process hyper-parameter training on the collection of audio signals. A method is disclosed for statistical modelling, interpolation, measurement and anthropometry based prediction of head-related transfer functions (HRTF) for a virtual audio system that includes collecting audio signals in transform domain for at least one subject; applying head related transfer functions (HRTF) measurement directions in multiple directions to the collected audio signals; and performing Gaussian hyper-parameter training on the collection of audio signals to generate at least one predicted HRTF.", "Statistical modelling, interpolation, measurement and anthropometry based prediction of head-related transfer functions "]
["Systems and methods for applying feature-space maximum likelihood linear regression (fMLLR) to correlated features are provided. A method for applying fMLLR to correlated features, comprises mapping the correlated features into an uncorrelated feature space, applying fMLLR in the uncorrelated feature space to obtain fMLLR transformed features, and mapping the fMLLR transformed features back to a correlated feature space.", "Systems and methods for applying speaker adaption techniques to correlated features "]
["An operation method of a convolutional neural network system includes executing convolution loops to determine a correlation between at least one kernel and an input feature map; determining a maximum position on the input feature map, the maximum position corresponding to a maximum value of an output feature produced based on the convolution loops; and processing first data of a first area of the input feature map through a convolution loop using the at least one kernel, the first area being associated with the maximum position. The processing of the first data includes skipping a convolution operation of second data of a second area of the input feature map, the second area being unassociated with the maximum position.", "Convolutional neural network system and operation method thereof "]
["Training speech recognizers, e.g., their language or acoustic models, using actual user data is useful, but retaining personally identifiable information may be restricted in certain environments due to regulations. Accordingly, a method or system is provided for enabling training of an acoustic model which includes dynamically shredding a speech corpus to produce text segments and depersonalized audio features corresponding to the text segments. The method further includes enabling a system to train an acoustic model using the text segments and the depersonalized audio features. Because the data is depersonalized, actual data may be used, enabling speech recognizers to keep up-to-date with user trends in speech and usage, among other benefits.", "Data shredding for speech recognition acoustic model training under data retention restrictions "]
[null, "Acoustic model building method and device for multi-language voice identification "]
["An artificial neural network (ANN) decoding system decodes a convolutionally-encoded data stream at high speed and with high efficiency. The ANN decoding system implements the Viterbi algorithm and is significantly faster than comparable digital-only designs due to its fully parallel architecture. Several modifications to the fully analog system are described, including an analog/digital hybrid design that results in an extremely fast and efficient Viterbi decoding system. A complexity and analysis shows that the modified ANN decoding system is much simpler and easier to implement than its fully digital counterpart. The structure of the ANN decoding system of the invention provides a natural fit for VLSI implementation. Simulation results show that the performance of the ANN decoding system exactly matches that of an ideal Viterbi decoding system.", "Artificial neural network viterbi decoding system and method "]
["A system, method, and computer program product for assigning an aesthetic score to an image. A method of the present invention includes receiving an image. The method further includes executing a neural network on the image to generate learned features. The method further includes applying a machine-learned model to assign an aesthetic score to the image, where a more aesthetically-pleasing image is given a higher aesthetic score and a less aesthetically-pleasing image is given a lower aesthetic score. The learned features are inputs to the machine-learned model.", "Systems, methods, and computer program products for searching and sorting images by aesthetic quality "]
["A neural network conversion method and a recognition apparatus that implements the method are provided. A method of converting an analog neural network (ANN) to a spiking neural network (SNN) normalizes first parameters of a trained ANN based on a reference activation that is set to be proximate to a maximum activation of artificial neurons included in the ANN, and determines second parameters of an SNN based on the normalized first parameters.", "Method of converting neural network and recognition apparatus using the same "]
["Systems and methods are provided for generating a DNN classifier by \u201clearning\u201d a \u201cstudent\u201d DNN model from a larger more accurate \u201cteacher\u201d DNN model. The student DNN may be trained from un-labeled training data because its supervised signal is obtained by passing the un-labeled training data through the teacher DNN. In one embodiment, an iterative process is applied to train the student DNN by minimize the divergence of the output distributions from the teacher and student DNN models. For each iteration until convergence, the difference in the output distributions is used to update the student DNN model, and output distributions are determined again, using the unlabeled training data. The resulting trained student model may be suitable for providing accurate signal processing applications on devices having limited computational or storage resources such as mobile or wearable devices. In an embodiment, the teacher DNN model comprises an ensemble of DNN models.", "Learning Student DNN Via Output Distribution "]
["A system, method and computer-readable storage devices for providing unsupervised normalization of noisy text using distributed representation of words. The system receives, from a social media forum, a word having a non-canonical spelling in a first language. The system determines a context of the word in the social media forum, identifies the word in a vector space model, and selects an \u201cn-best\u201d vector paths in the vector space model, where the n-best vector paths are neighbors to the vector space path based on the context and the non-canonical spelling. The system can then select, based on a similarity cost, a best path from the n-best vector paths and identify a word associated with the best path as the canonical version.", "System and method for unsupervised text normalization using distributed representation of words "]
[null, "Face feature extraction method based on face feature point shape drive depth model "]
["Phoneme boundaries may be determined from a signal corresponding to recorded audio by extracting auditory attention features from the signal and extracting phoneme posteriors from the signal. The auditory attention features and phoneme posteriors may then be combined to detect boundaries in the signal.", "Combining auditory attention cues with phoneme posterior scores for phone/vowel/syllable boundary detection "]
["A system and method for selecting a training data set from a set of multidimensional geophysical input data samples for training a model to predict target data. The input data may be data sets produced by a pulsed neutron logging tool at multiple depth points in a cases well. Target data may be responses of an open hole logging tool. The input data is divided into clusters. Actual target data from the training well is linked to the clusters. The linked clusters are analyzed for variance, etc. and fuzzy inference is used to select a portion of each cluster to include in a training set. The reduced set is used to train a model, such as an artificial neural network. The trained model may then be used to produce synthetic open hole logs in response to inputs of cased hole log data.", "Neural network training data selection using memory reduced cluster analysis for field model development "]
["The availability of high quality imagers on smartphones and other portable devices facilitates creation of a large, crowd-sourced, image reference library that depicts skin rashes and other dermatological conditions. Some of the images are uploaded with, or later annotated with, associated diagnoses or other information (e.g., \u201cthis rash went away when I stopped drinking milk\u201d). A user uploads a new image of an unknown skin condition to the library. Image analysis techniques are employed to identify salient similarities between features of the uploaded image, and features of images in this reference library. Given the large dataset, statistically relevant correlations emerge that identify to the user certain diagnoses that may be considered, other diagnoses that may likely be ruled-out, and/or anecdotal information about similar skin conditions from other users. Similar arrangements can employ audio and/or other physiologically-derived signals. A great variety of other features and arrangements are also detailed.", "Physiologic data acquisition and analysis "]
["A method for executing a mobile speech recognition software application based on a multi-layer neural network model includes providing to a hardware accelerator in the mobile device to classify one or more frames of an audio signal. The hardware accelerator includes a multiplier-accumulator (MAC) unit to perform matrix multiplication operations involved in computing the neural network output.", "Mobile speech recognition hardware accelerator "]
["A convolutional neural network is trained to analyze input data in various different manners. The convolutional neural network includes multiple layers, one of which is a convolution layer that performs a convolution, for each of one or more filters in the convolution layer, of the filter over the input data. The convolution includes generation of an inner product based on the filter and the input data. Both the filter of the convolution layer and the input data are binarized, allowing the inner product to be computed using particular operations that are typically faster than multiplication of floating point values. The possible results for the convolution layer can optionally be pre-computed and stored in a look-up table. Thus, during operation of the convolutional neural network, rather than performing the convolution on the input data, the pre-computed result can be obtained from the look-up table", "Convolutional Neural Network Using a Binarized Convolution Layer "]
["A closed loop Deep Brain Stimulation (DBS) system constituted of: a physiological sensor; a multi-electrode DBS lead; an adaptive control system in communication with the physiological sensor; and an implantable pulse generator (IPG) responsive to the adaptive control system, the adaptive control system comprising a learning module operable to learn to find the optimal stimulation parameters, classify and associate patient conditions responsive to the physiological sensor with optimal stimulation parameters in a plurality of patient conditions. The adaptive DBS device control system learns to deliver the optimal stimulation parameters based on Watkins and Dayan Q learning recursive formula, the closed loop adaptive DBS control system thus finds the optimal stimulation parameters online.", "Optimal deep brain stimulation therapy with q learning "]
[null, "Deep belief network image recognition method based on Bayesian regularization "]
["A method is disclosed herein that includes an act of causing a processor to access a deep-structured, layered or hierarchical model, called deep convex network, retained in a computer-readable medium, wherein the deep-structured model comprises a plurality of layers with weights assigned thereto. This layered model can produce the output serving as the scores to combine with transition probabilities between states in a hidden Markov model and language model scores to form a full speech recognizer. The method makes joint use of nonlinear random projections and RBM weights, and it stacks a lower module's output with the raw data to establish its immediately higher module. Batch-based, convex optimization is performed to learn a portion of the deep convex network's weights, rendering it appropriate for parallel computation to accomplish the training. The method can further include the act of jointly substantially optimizing the weights, the transition probabilities, and the language model scores of the deep-structured model using the optimization criterion based on a sequence rather than a set of unrelated frames.", "Deep convex network with joint use of nonlinear random projection, restricted boltzmann machine and batch-based parallelizable optimization "]
[null, "Super-resolution face recognition method based on deep belief networks "]
["A speech recognition system for resolving impaired utterances can have a speech recognition engine configured to receive a plurality of representations of an utterance and concurrently to determine a plurality of highest-likelihood transcription candidates corresponding to each respective representation of the utterance. The recognition system can also have a selector configured to determine a most-likely accurate transcription from among the transcription candidates. As but one example, the plurality of representations of the utterance can be acquired by a microphone array, and beamforming techniques can generate independent streams of the utterance across various look directions using output from the microphone array.", "Multi-Microphone Speech Recognition Systems and Related Techniques "]
["A system and method for a motorized land vehicle that detects objects obstructing a driver's view of an active road, includes an inertial measurement unit-enabled global position system (GPS/IMU) subsystem for obtaining global position system (GPS) position and heading data of a land vehicle operated by the driver as the vehicle travels along a road, a street map subsystem for obtaining street map data of the GPS position of the vehicle using the GPS position and heading data as the vehicle travels along the road, and a three-dimensional (3D) object detector subsystem for detecting objects ahead of the vehicle and determining a 3D position and 3D size data of each of the detected objects ahead of the vehicle. The street map subsystem merges the street map data, the GPS position and heading data of the vehicle and the 3D position data and 3D size data of the detected objects, to create real-time two-dimensional (2D) top-view map representation of a traffic scene ahead of the vehicle. The street map subsystems finds active roads ahead of the vehicle in the traffic scene, and finds each active road segment of the active roads ahead of the vehicle that is obstructed by one of the detected objects. A driver alert subsystem notifies a driver of the vehicle of each of the active road segments that is obstructed by one of the detected objects.", "System and Method for Detecting Objects Obstructing a Driver's View of a Road "]
["The technology described herein can be embodied in a method that includes receiving an audio signal encoding a portion of an utterance, and providing, to a first neural network, data corresponding to the audio signal. The method also includes generating, by a processor, data representing a transcription for the utterance based on an output of the first neural network. The first neural network is trained using features of multiple context-dependent states, the context-dependent states being derived from a plurality of context-independent states provided by a second neural network.", "Context-dependent state tying using a neural network "]
["Neural network image curation techniques are described. In one or more implementations, curation is controlled of images that represent a repository of images. A plurality of images of the repository are curated by one or more computing devices to select representative images of the repository. The curation includes calculating a score based on image and face aesthetics, jointly, for each of the plurality of images through processing by a neural network, ranking the plurality of images based on respective said scores, and selecting one or more of the plurality of images as one of the representative images of the repository based on the ranking and a determination that the one or more said images are not visually similar to images that have already been selected as one of the representative images of the repository.", "Neural Network Image Curation Control "]
["An unmanned aerial vehicle (UAV) can include one or more cameras for capturing image data within a field of view that depends in part upon the location and orientation of the UAV. At least a portion of the image data can be processed on the UAV to locate objects of interest, such as people or cars, and use that information to determine where to fly the drone in order to capture higher quality image data of those or other such objects. Once identified, the objects of interest can be counted, and the density, movement, location, and behavior of those objects identified. This can help to determine occurrences such as traffic congestion or unusual patterns of pedestrian movement, as well as to locate persons, fires, or other such objects. The data can also be analyzed by a remote system or service that has additional resources to provide more accurate results.", "Object detection and analysis via unmanned aerial vehicle "]
[null, "Neural network and fuzzy control fused electrical fire intelligent alarm method "]
["Methods of creating and using robust neural network ensembles are disclosed. Some embodiments take the form of computer-based methods that comprise receiving a set of available inputs; receiving training data; training at least one neural network for each of at least two different subsets of the set of available inputs; and providing at least two trained neural networks having different subsets of the available inputs as components of a neural network ensemble configured to transform the available inputs into at least one output. The neural network ensemble may be applied as a log synthesis method that comprises: receiving a set of downhole logs; applying a first subset of downhole logs to a first neural network to obtain an estimated log; applying a second, different subset of the downhole logs to a second neural network to obtain an estimated log; and combining the estimated logs to obtain a synthetic log.", "Ensembles of neural networks with different input sets "]
["The present invention extends to methods, systems, and computer program products for detecting, classifying, and tracking abnormal data in a data stream. Embodiments include an integrated set of algorithms that enable an analyst to detect, characterize, and track abnormalities in real-time data streams based upon historical data labeled as predominantly normal or abnormal. Embodiments of the invention can detect, identify relevant historical contextual similarity, and fuse unexpected and unknown abnormal signatures with other possibly related sensor and source information. The number, size, and connections of the neural networks all automatically adapted to the data. Further, adaption appropriately and automatically integrates unknown and known abnormal signature training within one neural network architecture solution automatically. Algorithms and neural networks architecture are data driven, resulting more affordable processing. Expert knowledge can be incorporated to enhance the process, but sufficient performance is achievable without any system domain or neural networks expertise.", "Detecting, classifying, and tracking abnormal data in a data stream "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scoring concept terms using a deep network. One of the methods includes receiving an input comprising a plurality of features of a resource, wherein each feature is a value of a respective attribute of the resource; processing each of the features using a respective embedding function to generate one or more numeric values; processing the numeric values using one or more neural network layers to generate an alternative representation of the features, wherein processing the floating point values comprises applying one or more non-linear transformations to the floating point values; and processing the alternative representation of the input using a classifier to generate a respective category score for each category in a pre-determined set of categories, wherein each of the respective category scores measure a predicted likelihood that the resource belongs to the corresponding category.", "Classifying Resources Using a Deep Network "]
["The present application relates to an environment control system. The environment control system is capable of detecting variations of natural environment and artificial environment, and control the use of electronic devices automatically or semi-automatically. Based on collected information stored in a built-in storage module, the environment control system may calculate and learn the user's habit of use with respect to the electronic devices using network connection.", "Environment control system "]
["A system and method for generating a neural network ensemble. Conventional algorithms are used to train a number of neural networks having error diversity, for example by having a different number of hidden nodes in each network. A genetic algorithm having a multi-objective fitness function is used to select one or more ensembles. The fitness function includes a negative error correlation objective to insure diversity among the ensemble members. A genetic algorithm may be used to select weighting factors for the multi-objective function. In one application, a trained model may be used to produce synthetic open hole logs in response to inputs of cased hole log data.", "Genetic algorithm based selection of neural network ensemble for processing well logging data "]
["A two-level hierarchical approach for process fault diagnosis is an operating system employs a function-oriented approach at a first level and a component characteristic-oriented approach at a second level, where the decision-making procedure is structured in order of decreasing intelligence with increasing precision. At the first level, the diagnostic method is general and has knowledge of the overall process including a wide variety of plant transients and the functional behavior of the process components. An expert system classifies malfunctions by function to narrow the diagnostic focus to a particular set of possible faulty components that could be responsible for the detected functional misbehavior of the operating system. At the second level, the diagnostic method limits its scope to component malfunctions, using more detailed knowledge of component characteristics. Trained artificial neural networks are used to further narrow the diagnosis and to uniquely identify the faulty component by classifying the abnormal condition data as a failure of one of the hypothesized components through component characteristics. Once an anomaly is detected, the hierarchical structure is used to successively narrow the diagnostic focus from a function misbehavior, i.e., a function oriented approach, until the fault can be determined, i.e., a component characteristic-oriented approach.", "Combined expert system/neural networks method for process fault diagnosis "]
["A system that is capable of controlling multiple entertainment systems and/or speakers using voice commands. The system receives voice commands and may determine audio sources and speakers indicated by the voice commands. The system may generate audio data from the audio sources and may send the audio data to the speakers using multiple interfaces. For example, the system may send the audio data directly to the speakers using a network address, may send the audio data to the speakers via a voice-enabled device or may send the audio data to the speakers via a speaker controller. The system may generate output zones including multiple speakers and may associate input devices with speakers within the output zones. For example, the system may receive a voice command from an input device in an output zone and may reduce output audio generated by speakers in the output zone.", "Processing spoken commands to control distributed audio outputs "]
[null, "Training convolutional neural network on graphics processing units "]
["A method and system for training a neural network of a visual recognition computer system, extracts at least one feature of an image or video frame with a feature extractor; approximates the at least one feature of the image or video frame with an auxiliary output provided in the neural network; and measures a feature difference between the extracted at least one feature of the image or video frame and the approximated at least one feature of the image or video frame with an auxiliary error calculator. A joint learner of the method and system adjusts at least one parameter of the neural network to minimize the measured feature difference.", "Transfer Learning Methods and systems for Feed-Forward Visual Recognition Systems "]
["A neural network is used to process a set of ranking features in order to determine the relevancy ranking for a set of documents or other items. The neural network calculates a predicted relevancy score for each document and the documents can then be ordered by that score. Alternate embodiments apply a set of data transformations to the ranking features before they are input to the neural network. Training can be used to adapt both the neural network and certain of the data transformations to target environments.", "Enterprise relevancy ranking using a neural network "]
["Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scoring concept terms using a deep network. One of the methods includes receiving an input comprising a plurality of features of a resource, wherein each feature is a value of a respective attribute of the resource; processing each of the features using a respective embedding function to generate one or more numeric values; processing the numeric values to generate an alternative representation of the features of the resource, wherein processing the floating point values comprises applying one or more non-linear transformations to the floating point values; and processing the alternative representation of the input to generate a respective relevance score for each concept term in a pre-determined set of concept terms, wherein each of the respective relevance scores measures a predicted relevance of the corresponding concept term to the resource.", "Scoring Concept Terms Using a Deep Network "]
["In some examples, a computing device includes at least one processor; and at least one module, operable by the at least one processor to: output, for display at an output device, a graphical keyboard; receive an indication of a gesture detected at a location of a presence-sensitive input device, wherein the location of the presence-sensitive input device corresponds to a location of the output device that outputs the graphical keyboard; determine, based on at least one spatial feature of the gesture that is processed by the computing device using a neural network, at least one character string, wherein the at least one spatial feature indicates at least one physical property of the gesture; and output, for display at the output device, based at least in part on the processing of the at least one spatial feature of the gesture using the neural network, the at least one character string.", "Neural network for keyboard input decoding "]
["A computer numerical control unit with learning ability solves the problem of automatic and intelligent generating of numerical control programs for computer numerical control machining centers for milling, drilling and similar operations. The key module of the computer numerical control unit is a neural network (NN) device that learns to generate the numerical control programs through an neural network teaching module. Upon completion of learning process the neural network device can generate automatically, without any intervention of the operator, merely on the basis of the CAD 2D, 2,5D or 3D part models, taken from a conventional CAD/CAM system, various new numerical control programs for different parts, which have not been in the machining process before. The computer numerical control control unit with learning ability is suitable especially for machining centers intended for milling, including face milling (rough), contour milling (rough), final milling following the contour and in Z-plane, final contour 3D milling, contour final milling, milling in Z-plane, final contour milling on the equidistant, and milling of pockets; drilling, including normal drilling, deep drilling, and center drilling; and reaming, sinking and threading.", "CNC control unit with learning ability for machining centers "]
["Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.", "Cognitive memory and auto-associative neural network based search engine for computer and network located images and photographs "]
[null, "Conversion method for sound of speaker "]
["Methods of directly analyzing wireline well logging data to derive pore types, pore volumes and capillary pressure curves from the wireline logs are disclosed. A trained and validated neural network is applied to wireline log data on porosity, bulk density and shallow, medium and deep conductivity to derive synthetic pore type proportions as a function of depth. These synthetic data are then applied through a derived and validated capillary pressure curve data model to derive pore volume and pressure data as a function of borehole depth.", "Generating pore types and synthetic capillary pressure curves from wireline logs using neural networks "]
[null, "Human being and vehicle classification method based on deep belief net "]
["A system and method are disclosed for recognizing and tracking a user's skeletal joints with a NUI system. The system includes one or more experts for proposing one or more skeletal hypotheses each representing a user pose within a given frame. Each expert is generally computationally inexpensive. The system further includes an arbiter for resolving the skeletal hypotheses from the experts into a best state estimate for a given frame. The arbiter may score the various skeletal hypotheses based on different methodologies. The one or more skeletal hypotheses resulting in the highest score may be returned as the state estimate for a given frame. It may happen that the experts and arbiter are unable to resolve a single state estimate with a high degree of confidence for a given frame. It is a further goal of the present system to capture any such uncertainty as a factor in how a state estimate is to be used.", "System for fast, probabilistic skeletal tracking "]
["An object, such as a robot, is located at an initial state in a finite state space area and moves under the control of the unsupervised neural network model of the invention. The network instructs the object to move in one of several directions from the initial state. Upon reaching another state, the model again instructs the object to move in one of several directions. These instructions continue until either: a) the object has completed a cycle by ending up back at a state it has been to previously during this cycle, or b) the object has completed a cycle by reaching the goal state. If the object ends up back at a state it has been to previously during this cycle, the neural network model ends the cycle and immediately begins a new cycle from the present location. When the object reaches the goal state, the neural network model learns that this path is productive towards reaching the goal state, and is given delayed reinforcement in the form of a \"reward\". Upon reaching a state, the neural network model calculates a level of satisfaction with its progress towards reaching the goal state. If the level of satisfaction is low, the neural network model is more likely to override what has been learned thus far and deviate from a path known to lead to the goal state to experiment with new and possibly better paths.", "Neural network model for reaching a goal state "]
[null, "Ultrashort-term wind power prediction method "]
["A method for analyzing data is provided. The method includes generating, using a processing device, a graph from raw data, the graph including a plurality of nodes and edges, deriving, using the processing device, at least one label for each node using a deep belief network, and identifying, using the processing device, a predetermined pattern in the graph based at least in part on the labeled nodes.", "Systems and methods for analyzing data using deep belief networks (DBN) and identifying a pattern in a graph "]
["A method is described for providing an estimate of the state of a stationary or moving contact in a three dimensional ocean. The method comprises the steps of collecting information about a location of an observer during a sequence of time, information from at least one sensor about a position of the contact relative to the observer during the time sequence, and a knowledge vector. Transforming the information into a series of three dimensional geographical grids. Examining the grids to identify hypothesized contact paths and analyzing the hypothesized contact paths to produce an estimate of the state of the contact with respect to the location of the observer. A device for providing the estimate of the state of a stationary or moving contact includes a grid stimulation block for transforming the collected information into the three dimensional geographical grids. A fusion block where grids corresponding to similar time intervals are combined or fused. A correlation block for identifying possible contact paths and for producing path likelihood vectors and an estimation block for providing the estimate of the state of the moving contact. The device further includes a controller for providing knowledge to the aforementioned blocks.", "Neural network based contact state estimator "]
["A method is described for providing an estimate of the state of a moving  tact in a three dimensional ocean. The method comprises the steps of providing a device for estimating the state of the contact, inputting into the device information about a location of an observer during a sequence of time, information from at least one sensor about the position of the contact relative to the observer during the time sequence, and a knowledge vector, transforming the inputted information into a series of three dimensional geographical grids, and analyzing the geographical grids to produce an estimate of the state of the contact with respect to the location of the observer. The device for providing the estimate of the state of the moving contact is a neurally inspired contact estimation device. The device includes a grid stimulation block for transforming the inputted information into the three dimensional geographical grids, a fusion block where grids corresponding to similar time intervals are combined or fused, a correlation block for providing constraints such as constant speed and heading and for producing a path likelihood vector, and an estimate block for providing the estimate of the state of the moving contact. The device further includes a controller for providing knowledge to the aforementioned blocks.", "Neural network based three dimensional ocean modeler "]
["Systems and methods for selecting an appropriate caching algorithm to be used when temporarily storing data accessed by an executing application using a neural network may dynamically and/or iteratively replace an initial caching algorithm being used for the application. An input layer of the neural network may gather values of performance related parameters, such as cache hit rates, data throughput rates, or memory access request response times. The neural network may detect a pattern or change in a pattern of accesses, or a change in a workload, a hardware component, or an operating system parameter. Dependent on these and/or other inputs, the neural network may select and apply a caching algorithm likely to improve performance of the application. Other inputs to the neural network may include values of hardware configuration parameters and/or operating system parameters. The neural network may perform a training exercise or may be self-training, e.g., using reinforcement learning.", "System and Method for Effective Caching Using Neural Networks "]
["A system and method is disclosed that facilitates the processing of a sound signal. In embodiments, an input sound signal can be processed according to a computational model using predetermined parameters. A sound signal originating from a musical instrument can be processed according to coefficients that are generated using a learning model.", "Musical Instrument Pickup Signal Processor "]
["A coprocessor and method for processing convolutional neural networks includes a configurable input switch coupled to an input. A plurality of convolver elements are enabled in accordance with the input switch. An output switch is configured to receive outputs from the set of convolver elements to provide data to output branches. A controller is configured to provide control signals to the input switch and the output switch such that the set of convolver elements are rendered active and a number of output branches are selected for a given cycle in accordance with the control signals.", "Dynamically configurable, multi-ported co-processor for convolutional neural networks "]
["Seismic facies are identified in a volume of seismic data, wherein, first, a plurality of initial textural attributes representative of the volume of seismic data are calculated. Next, a probabilistic neural network is constructed from the calculated initial textural attributes. Then, final textural attributes are calculated throughout the volume of seismic data. Finally, the calculated final textural attributes are classified using the constructed probabilistic neural network.", "Method for seismic facies interpretation using textural analysis and neural networks "]
["A Neural Network using interconnecting weights each with two values, one of which is selected for use, can be taught to map a set of input vectors to a set of output vectors.", "Discrete weight neural network "]
["A method and apparatus for speeding and enhancing the \"learning\" function of a computer configured as a multilayered, feed format artificial neural network using logistic functions as an activation function. The enhanced learning method provides a linear probing method for determining local minima values computed first along the gradient of the weight space and then adjusting the slope and direction of a linear probe line after determining the likelihood that a \"ravine\" has been encountered in the terrain of the weight space.", "Method and apparatus for learning in a neural network "]
["The present invention is a method and apparatus for collecting EEG data, reducing the EEG data into coefficients, and correlating those coefficients with a depth of unconsciousness or anesthetic depth, and which obtains a bounded first derivative of anesthetic depth to indicate trends. The present invention provides a developed artificial neural network based method capable of continuously analyzing EEG data to discriminate between awake and anesthetized states in an individual and continuously monitoring anesthetic depth trends in real-time. The present invention enables an anesthesiologist to respond immediately to changes in anesthetic depth of the patient during surgery and to administer the correct amount of anesthetic.", "Neurometric assessment of intraoperative anesthetic "]
["Within the frameworks of hierarchical neural feed-forward architectures for performing real-world 3D invariant object recognition a technique is proposed that shares components like weight-sharing (2), and pooling stages (3, 5) with earlier approaches, but focuses on new methods for determining optimal feature-detecting units in intermediate stages (4) of the hierarchical network. A new approach for training the hierarchical network is proposed which uses statistical means for (incrementally) learning new feature detection stages and significantly reduces the training effort for complex pattern recognition tasks, compared to the prior art. The incremental learning is based on detecting increasingly statistically independent features in higher stages of the processing hierarchy. Since this learning is unsupervised, no teacher signal is necessary and the recognition architecture can be pre-structured for a certain recognition scenario. Only a final classification step must be trained with supervised learning, which reduces significantly the effort for the adaptation to a recognition task.", "Pattern recognition with hierarchical networks "]
["One aspect of the present invention relates to a method of dual damascene processing, involving forming a plurality of via openings in the insulation structure containing a single layer of a dielectric material; and simultaneously (i) forming a plurality of trenches in the insulation structure, each trench positioned along the substantially straight line of a group of via openings, and (ii) monitoring the formation of trenches using a scatterometry system to determine trench depth, and terminating forming the trenches when a desired trench depth is attained.", "Dual damascene trench depth monitoring "]
["A method for training a probabilistic neural network to map seismic attributes or similar quantities.", "Method for mapping seismic attributes using neural networks "]
["A method for configuring long short-term memory (LSTM) in a spiking neural network includes decoding input spikes into analog values within the LSTM. The method further includes implementing the LSTM based on an encoded representation of the analog values. The implementing can include encoding the analog values using base expansive coding, rate coding, latency coding or synaptic weight coding.", "Long short-term memory using a spiking neural network "]
["Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.", "System and method for cognitive memory and auto-associative neural network based pattern recognition "]
["A mask neutral network for processing that allows an external source of control to continuously direct state transition of the neural network toward selected states and away from other states. The network, through externally controlled masking, can focus attention on selected attributes of observed data, solutions or results. The masking is appliciable across three major categories of networks in that it facilitates augmented recall, directed learning and constrained optimization.", "Mask controled neural networks "]
["High-speed, analog, fully-parallel and asynchronous building blocks are cascaded for larger sizes and enhanced resolution. A hardware-compatible algorithm permits hardware-in-the-loop learning despite limited weight resolution. A computation-intensive feature classification application has been demonstrated with this flexible hardware and new algorithm at high speed. This result indicates that these building block chips can be embedded as application-specific-coprocessors for solving real-world problems at extremely high data rates.", "Cascaded VLSI neural network architecture for on-line learning "]
["Identifying objects in images is a difficult problem, particularly in cases an original image is noisy or has areas narrow in color or grayscale gradient. A technique employing a convolutional network has been identified to identify objects in such images in an automated and rapid manner. One example embodiment trains a convolutional network including multiple layers of filters. The filters are trained by learning and are arranged in successive layers and produce images having at least a same resolution as an original image. The filters are trained as a function of the original image or a desired image labeling; the image labels of objects identified in the original image are reported and may be used for segmentation. The technique can be applied to images of neural circuitry or electron microscopy, for example. The same technique can also be applied to correction of photographs or videos.", "Method and apparatus for image processing "]
["Neural networks provide efficient, robust and precise filtering techniques for compensating linear and non-linear distortion of an audio transducer such as a speaker, amplified broadcast antenna or perhaps a microphone. These techniques include both a method of characterizing the audio transducer to compute the inverse transfer functions and a method of implementing those inverse transfer functions for reproduction. The inverse transfer functions are preferably extracted using time domain calculations such as provided by linear and non-linear neural networks, which more accurately represent the properties of audio signals and the audio transducer than conventional frequency domain or modeling based approaches. Although the preferred approach is to compensate for both linear and non-linear distortion, the neural network filtering techniques may be applied independently.", "Neural network filtering techniques for compensating linear and non-linear distortion of an audio transducer "]
[null, "Method for detecting leakage of pipeline based on artificial neural network "]
["The sequencer (14) is part of a computational system (10) which includes a computational circuit component, or processor node array (16); the sequencer, or controller component (14); and a boundary interface (34) between the computational circuit component (16) and the controller component (14). The controller component (14) provides three main functions in the system: (one) it sequences computations in a computational component (16), which includes an array of processor nodes (74, 76, 78, 80, 82, 84); (two) it provides I/O processing (20) from several disparate sources between the processor node array (16) and a host processor (12); and (three) it synchronizes data flow from a substantially asynchronous portion of the system (12) with a substantially synchronous data flow in the processor node array portion of the system (16).", "Neural network sequencer and interface apparatus "]
["An analog-digital crosspoint-network includes a plurality of rows and columns, a plurality of synaptic nodes, each synaptic node of the plurality of synaptic nodes disposed at an intersection of a row and column of the plurality of rows and columns, wherein each synaptic node of the plurality of synaptic nodes includes a weight associated therewith, a column controller associated with each column of the plurality of columns, wherein each column controller is disposed to enable a weight change at a synaptic node in communication with said column controller, and a row controller associated with each row of the plurality of rows, wherein each row controller is disposed to control a weight change at a synaptic node in communication with said row controller.", "Hardware analog-digital neural networks "]
["Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for providing a representation based on structured data in resources. The methods, systems, and apparatus include actions of receiving target acoustic features output from a neural network that has been trained to predict acoustic features given linguistic features. Additional actions include determining a distance between the target acoustic features and acoustic features of a stored acoustic sample. Further actions include selecting the acoustic sample to be used in speech synthesis based at least on the determined distance and synthesizing speech based on the selected acoustic sample.", "Deep networks for unit selection speech synthesis "]
["An exemplary methodology, procedure, system, method and computer-accessible medium can be provided for receiving physiological data for the subject, extracting one or more patterns of features from the physiological data, and classifying the at least one state of the subject using a spatial structure and a temporal structure of the one or more patterns of features, wherein at least one of the at least one state is an ictal state.", "Method, system, and computer-accessible medium for classification of at least one ictal state "]
[null, "Intelligent gearbox fault diagnosis method based on mixed inference and neural network "]
["Logging systems and methods are disclosed to reduce usage of radioisotopic sources. Some embodiments comprise collecting at least one output log of a training well bore from measurements with a radioisotopic source; collecting at least one input log of the training well bore from measurements by a non-radioisotopic logging tool; training a neural network to predict the output log from the at least one input log; collecting at least one input log of a development well bore from measurements by the non-radioisotopic logging tool; and processing the at least one input log of the development well bore to synthesize at least one output log of the development well bore. The output logs may include formation density and neutron porosity logs.", "Neural network based well log synthesis with reduced usage of radioisotopic sources "]
["A signal phase pattern sensitive neural network system can discern  persist patterns of phase in a time varying or oscillatory signal. The system employs duplicate inputs from each of its sensors to the processing elements of a first layer of its neural network, with the exception that one input is phase shifted relative to the other. The system also employs a modification of a conventional Kohonen competitive learning rule which is applied by the processing and learning elements of a second layer of its neural network.", "Signal phase pattern sensitive neural network system and method "]
["A neural network for processing sensory information. The network comprise one or more layers including interconnecting cells having individual states. Each cell is connected to one or more neighboring cells. Sensory signals and signals from interconnected neighboring cells control a current or a conductance within a cell to influence the cell's state. In some embodiments, the current or conductance of a cell can be controlled by a signal arising externally of the layer. Each cell can comprise an electrical circuit which receives an input signal and causes a current corresponding to the signal to pass through a variable conductance. The conductance is a function of the states of the one or more interconnecting neighboring cells. Proper interconnection of the cells on a layer can produce a neural network which is sensitive to predetermined patterns or the passage of such patterns across a sensor array whose signals are input into the network. The layers in the network can be made sensitive to distinct sensory parameters, so that networks which are sensitive to different wavelengths or polarizations of light energy can be produced.", "Optoelectronic sensory neural network "]
["Network interactions within a Boundary Contour (BC) System, a Feature Contour (FC) System, and an Object Recognition (OR) System are employed to provide a computer vision system capable of recognizing emerging segmentations. The BC System is defined by a hierarchy of orientationally tuned interactions, which can be divided into two successive subsystems called the OC filter and the CC loop. The OC filter contains oriented receptive fields or masks, which are sensitive to different properties of image contrasts. The OC filter generates inputs to the CC loop, which contains successive stages of spatially shore-range competitive interactions and spatially long-range cooperative interactions. Feedback between the competitive and cooperative stages synthesizes a global context-sensitive segmentation from among the many possible groupings of local featural elements.", "Neural networks for machine vision "]
["An apparatus for detecting Deep Vein Thrombosis (DVT) in a patient includes a computer based device, a device disposed on a predetermined position on a calf of the patient for measuring blood volume, another device for measuring temperature of the calf and still another device for measuring calf size. A cuff is operably connected to the computer based device and envelops a portion of a thigh of the patient and is controllably restrictable by the computer based device to produce a controlled venous occlusion of the patient's deep veins for a predetermined period. A method for detecting DVT using the device is also provided.", "Apparatus and method for detecting deep vein thrombosis "]
["A robotic vehicle may be operated by a learning controller comprising a trainable convolutional network configured to determine control signal based on sensory input. An input network layer may be configured to transfer sensory input into a hidden layer data using a filter convolution operation. Input layer may be configured to transfer sensory input into hidden layer data using a filter convolution. Output layer may convert hidden layer data to a predicted output using data segmentation and a fully connected array of efficacies. During training, efficacy of network connections may be adapted using a measure determined based on a target output provided by a trainer and an output predicted by the network. A combination of the predicted and the target output may be provided to the vehicle to execute a task. The network adaptation may be configured using an error back propagation method. The network may comprise an input reconstruction.", "Trainable convolutional network apparatus and methods for operating a robotic vehicle "]
["In a method and system for developing a neural system adapted to perform a specified task, a population of neural systems is selected, each neural system comprising an array of interconnected neurons, and each neural system is encoded into a representative genome. For a given genome, a processing gene encodes a neural output function for each neuron, and the connections from each neuron are encoded by one or more connection genes, each connection gene including a weight function. The given neural system is operated to perform the specified task during a trial period, and performance is continually monitored during the trial period. Reinforcement signals determined from the continually monitored performance are applied as inputs to the functions respectively associated with each of the processing genes and connection genes of the given neural system. At the conclusion of the trial period, the fitness of the given neural system for performing the specified task is determined, usefully as a function of the reinforcement signals applied during the trial period. A set of genomes, respectively representing the neural systems of the population that have been determined to have the highest fitness values, are selected for use in forming a new generation of neural systems.", "System and method for developing artificial intelligence "]
["The system and method for provisioning resources in a network provides real time, parallel evaluation of the best path within the network using neural network principles. Elements of the network having a plurality of paths are assigned relative values according to a network user's requirements. Attributes may include factors such as reliability, cost, speed, distance, expandability, etc., and may be static or dynamic. Selection of a best path from the plurality of paths comprises application of fuzzy logic, using a threshold function to identify a best relative path value by providing an input to the function which is a combination of the attribute values of the elements within each path. The input to the function is the sum of weighted attribute values, where each attribute value is multiplied by a weight which is a relative value determined in accordance with the network user's priorities; the higher the priority, the greater the weight applied to that attribute. Computation of the threshold function is performed for each path and the resulting values are compared to a pre-determined threshold value to determine if the threshold has been crossed. If a single optimal path has not been identified during this step, the weights of the various attributes are adjusted in order of their priority; upward if no paths have crossed the threshold and downward if multiple paths have crossed the threshold. The process is continued with increasingly smaller incremental changes in the weights until a single combination of elements provides a path value which crosses the threshold, indicating the best path for meeting the network user's criteria. The threshold function may be any algorithm which provides a threshold, including sigmoid, linear, exponential and quadratic functions.", "System and method for management of connection oriented networks "]
["A method of designing an interplanetary communications network with an Artificial Neural Network (ANN) at each node. Object functions are generated that relate network characteristics and performance. Each object function is driven to an extreme (min or max) to provide an optimum network configuration. The optimum network configuration includes the number of nodes and the number of antennas for each node, node placement, specific node storage capacity and communications capacity for nodes and for links between nodes.", "Method of optimizing an interplanetary communications network "]
["A system with multimodality instrument for tissue identification includes a computer-controlled motor driven heuristic probe with a multisensory tip. For neurosurgical applications, the instrument is mounted on a stereotactic frame for the probe to penetrate the brain in a precisely controlled fashion. The resistance of the brain tissue being penetrated is continually monitored by a miniaturized strain gauge attached to the probe tip. Other modality sensors may be mounted near the probe tip to provide real-time tissue characterizations and the ability to detect the proximity of blood vessels, thus eliminating errors normally associated with registration of pre-operative scans, tissue swelling, elastic tissue deformation, human judgement, etc., and rendering surgical procedures safer, more accurate, and efficient. A neural network program adaptively learns the information on resistance and other characteristic features of normal brain tissue during the surgery and provides near real-time modeling. A fuzzy logic interface to the neural network program incorporates expert medical knowledge in the learning process. Identification of abnormal brain tissue is determined by the detection of change and comparison with previously learned models of abnormal brain tissues. The operation of the instrument is controlled through a user friendly graphical interface. Patient data is presented in a 3D stereographics display. Acoustic feedback of selected information may optionally be provided. Upon detection of the close proximity to blood vessels or abnormal brain tissue, the computer-controlled motor immediately stops probe penetration.", "Multimodality instrument for tissue characterization "]
["State-dependent supervised learning framework in artificial neuron networks may be implemented. A framework may be used to describe plasticity updates of neuron connections based on a connection state term and a neuron state term. Connection states may be updated based on inputs and outputs to and/or from neurons. The input connections of a neuron may be updated using input traces comprising a time-history of inputs provided via the connection. Weight of the connection may be updated and connection state may be time varying. The updated weights may be determined using a rate of change of the input trace and a term comprising a product of a per-neuron contribution and a per-connection contribution configured to account for the state time-dependency. Using event-dependent connection change components, connection updates may be executed on a per neuron basis, as opposed to a per-connection basis.", "Apparatus and methods for state-dependent learning in spiking neuron networks "]
["A method and an apparatus are disclosed for processing a measurement process to estimate a signal process. The method synthesizes realizations of a signal process and a measurement process into a primary filter for estimating the signal process and, if required, an ancillary filter for providing the primary filter's estimation error statistics. Both the primary and the ancillary filters are made out of artificial recurrent neural networks (RNNs). Their implementation results in the filtering apparatus. The synthesis is performed through training RNNs. The weights/parameters and initial dynamic state of an RNN are determined by minimizing a training criterion by the variation of the same. The training criterion, which is constructed on the basis of a selected estimation error criterion, incorporates the aforementioned realizations. An alternative way to determine the initial dynamic state of an RNN is to simply set it equal to a canonical initial dynamic state. After adequate training, both the primary and the ancillary filters are recursive filters optimal for the given respective RNN architectures with the lagged feedbacks carrying the optimal conditional statistics. If appropriate RNN paradigms and estimation error criteria are selected, the primary and the ancillary filters of such paradigms are proven to approximate the respective optimal filters in performance (with respect to the selected estimation error criteria) to any desired degree of accuracy, provided that the RNNs that constitute the primary and ancillary filters are of sufficient sizes.", "Optimal filtering by recurrent neural networks "]
["A neural network based optical character recognition technique is presented for identifying characters in a moving web. Image acquisition means defines an imaging window through which the moving web passes such that the characters printed thereon can be imaged. Classification data is extracted and accumulated for each printed web character passing through the imaging window. A light source provides transmissive illumination of the web as it is being imaged. A neural network accelerator is coupled to the image acquisition means for intelligent processing of the accumulated classification data to produce therefrom printed character classification information indicative of each corresponding character imaged. A processor is coupled to the accelerator for converting the classification information into the appropriate ASCII character code. The technique is particularly useful for reading dot-matrix-type characters on a noisy, semi-transparent background at fast real-time rates. A neural network algorithm based recognition method is also described.", "Neural network optical character recognition system and method for classifying characters in a moving web "]
["Apparatus that solves the problem of pattern recognition in a temporal signal that is subject to distortions and time warp. The arrangement embodying the invention comprises a neural network, an input interconnection network, and a plurality of signal modification circuits. A plurality of input leads delivers a preselected characteristic stimulus to associated signal modification units, and in response to an applied stimulus, each signal modification unit develops a plurality of output signals that begins at the time of stimulus application, rises to a peak, and decays thereafter. The mean time delay of each output (time to reach the peak) is different for each of the modification unit output signals. The outputs of the signal modification units are applied to the input interconnection unit wherein connections are made in accordance with the sequences that are to be recognized.", "Neural computation by time concentration "]
["The invention provides a machine fault diagnostic system to help ensure effective equipment maintenance. The major technique used for fault diagnostics is a fault diagnostic network (FDN) which is based on a modified ARTMAP neural network architecture. A hypothesis and test procedure based on fuzzy logic and physical bearing models is disclosed to operate with the FDN for detecting faults that cannot be recognized by the FDN and for analyzing complex machine conditions. The procedure described herein is able to provide accurate fault diagnosis for both one and multiple-fault conditions. Furthermore, a transputer-based parallel processing technique is used in which the FDN is implemented on a network of four T800-25 transputers.", "Machine fault diagnostics system and method "]
["An automated screening tool for the exclusion of deep venous thrombosis generally comprises a sensor array for gathering thermal data from the lower limbs of a patient suspected of DVT; a processor for automated analysis of the gathered data; and a display device for reporting the exclusion or non-exclusion of DVT. In the preferred embodiment of the present invention, a microprocessor based system is utilized to control the gathering of thermal data and, thereafter, the reporting of the gathered data to the processor. According to the preferred method for use of the present invention, the gathered thermal data is utilized, alone or in combination with other indicators, as a factor for exclusion of DVT based upon an implemented algorithm.", "Method for automated exclusion of deep venous thrombosis "]
["A device includes a memory, a receiver, a processor, and a display. The memory is configured to store a speaker model. The receiver is configured to receive an input audio signal. The processor is configured to determine a first confidence level associated with a first portion of the input audio signal based on the speaker model. The processor is also configured to determine a second confidence level associated with a second portion of the input audio signal based on the speaker model. The display is configured to present a graphical user interface associated with the first confidence level or associated with the second confidence level.", "Speaker verification "]
["Deep computing techniques are employed to mine statistical data bases and patient specific data files contributed from multiple sources, including implantable medical devices (IMDs) and external medical devices and other sources, to formulate patient-specific monitoring, diagnostic, therapeutic and educational information and to deliver the patient-specific diagnostic, therapeutic and educational information to the patient and/or patient health care provider. The present invention advantageously provides patient-specific information for IMD bearing patients that draws upon worldwide expertise and knowledge of IMDs of the type implanted, the patient's disease etiology, the drugs prescribed to the patient, the knowledge of experts in the field, and the optimal modes of operating the IMD to monitor physiologic conditions or apply therapies as reported by experts and medical device manufacturers. Patient data is supplied to a patient file at a centralized information database, the patient data including IMD developed patient data. Statistical data from public domain databases and governmental and international health agency databases is accessed. Deep computing techniques are applied to mine the accessed statistical data to associate pertinent statistical data with the patient data in the patient file to form a patient specific medical profile. Based upon the patient specific medical profile, patient specific information is formulated and delivered to one or more of the patient and the health care provider providing care to the patient.", "Deep computing applications in medical device systems "]
["In general, the invention is directed to a technique for selection of parameter configurations for a neurostimulator using neural networks. The technique may be employed by a programming device to allow a clinician to select parameter configurations, and then program an implantable neurostimulator to deliver therapy using the selected parameter configurations. The parameter configurations may include one or more of a variety of parameters, such as electrode configurations defining electrode combinations and polarities for an electrode set implanted in a patient. The electrode set may be carried by one or more implanted leads that are electrically coupled to the neurostimulator. In operation, the programming device executes a parameter configuration search algorithm to guide the clinician in the selection of parameter configurations. The search algorithm relies on a neural network that identifies potential optimum parameter configurations.", "Selection of neurostimulator parameter configurations using neural network "]
["Characteristics of the plasma in a plasma-based manufacturing process step are monitored directly and in real time by observing the spectrum which it produces. An artificial neural network analyzes the plasma spectrum and generates control signals to control one or more of the process input parameters in response to any deviation of the spectrum beyond a narrow range. In an embodiment, a plasma reaction chamber forms a plasma in response to input parameters such as gas flow, pressure and power. The chamber includes a window through which the electromagnetic spectrum produced by a plasma in the chamber, just above the subject surface, may be viewed. The spectrum is conducted to an optical spectrometer which measures the intensity of the incoming optical spectrum at different wavelengths. The output of optical spectrometer is provided to an analyzer which produces a plurality of error signals, each indicating whether a respective one of the input parameters to the chamber is to be increased or decreased. The microcontroller provides signals to control respective controls, but these lines are intercepted and first added to the error signals, before being provided to the controls for the chamber. The analyzer can include a neural network and an optional spectrum preprocessor to reduce background noise, as well as a comparator which compares the parameter values predicted by the neural network with a set of desired values provided by the microcontroller.", "Closed loop adaptive control of spectrum-producing step using neural networks "]
["A renewable energy resource management system manages a delivery of a power requirement from a multi-resource offshore renewable energy installation to an intelligent power distribution network. The installation includes multiple renewable energy resource components and is capable of variably and independently generating power from each to microgrids comprising the intelligent power distribution network so that the entire power requirement is satisfied from renewable energy resources. An electricity grid infrastructure is also disclosed in which power production is balanced with power consumption so that power storage requirements are minimized.", "Energy management system for power transmission to an intelligent electricity grid from a multi-resource renewable energy installation "]
["A method for performance envelope boundary cueing for a vehicle control system comprises the steps of formulating a prediction system for a neural network and training the neural network to predict values of limited parameters as a function of current control positions and current vehicle operating conditions. The method further comprises the steps of applying the neural network to the control system of the vehicle, where the vehicle has capability for measuring current control positions and current vehicle operating conditions. The neural network generates a map of current control positions and vehicle operating conditions versus the limited parameters in a pre-determined vehicle operating condition. The method estimates critical control deflections from the current control positions required to drive the vehicle to a performance envelope boundary. Finally, the method comprises the steps of communicating the critical control deflection to the vehicle control system; and driving the vehicle control system to provide a tactile cue to an operator of the vehicle as the control positions approach the critical control deflections.", "Neural network based automatic limit prediction and avoidance system and method "]
["A method and system for intelligent control of external devices using a mammalian brain-like structure having three parts. The method and system include a computer-implemented neural network system which is an extension of the model-based adaptive critic design and is applicable to real-time control (e.g., robotic control) and real-time distributed control. Additional uses include data visualization, data mining, and other tasks requiring complex analysis of inter-relationships between data.", "3-brain architecture for an intelligent decision and control system "]
["The following disclosure describes several methods and apparatus for intracranial electrical stimulation to treat or otherwise effectuate a change in neural-functions of a patient. Several embodiments of methods in accordance with the invention are directed toward enhancing or otherwise inducing a lasting change in neural activity to effectuate a particular neural-function. Such lasting change in neural activity is defined as \u201cneuroplasticity.\u201d The methods in accordance with the invention can be used to treat brain damage (e.g., stroke, trauma, etc.), brain disease (e.g., Alzheimer's, Pick's, Parkinson's, etc.), and/or brain disorders (e.g., epilepsy, depression, etc.). The methods in accordance with the invention can also be used to enhance neural-function of normal, healthy brains (e.g., learning, memory, etc.), or to control sensory functions (e.g., pain). Certain embodiments of methods in accordance with the invention electrically stimulate the brain at a stimulation site where neuroplasticity is occurring. The stimulation site may be different than the region in the brain where neural activity is typically present to perform the particular neural function according to the functional organization of the brain. In one embodiment in which neuroplasticity related to the neural-function occurs in the brain, the method can include identifying the location where such neuroplasticity is present. In an alternative embodiment in which neuroplasticity is not occurring in the brain, an alternative aspect is to induce neuroplasticity at a stimulation site where it is expected to occur. Several embodiments of these methods that are expected to produce a lasting effect on the intended neural activity at the stimulation site use electrical pulses that increase the resting membrane potential of neurons at the stimulation site to a subthreshold level.", "Methods and apparatus for effectuating a change in a neural-function of a patient "]
["The invention provides a micro-control neuroprosthetic device and methods for predicting and controlling epileptic neuronal activity. The device includes a detection system that detects and collects electrophysiological information comprising action potentials from single neurons and ensembles of neurons in a neural structure such as an epileptogenic region of the brain in a subject. An analysis system included in the neuroprosthetic device evaluates the electrophysiological information and performs a real-time extraction of neuron firing features from which the system determines when stimulus intervention is required. The neuroprosthetic device further comprises a stimulation intervention system that provides stimulus output signals having a desired stimulation frequency and stimulation intensity directly to the neural structure in which abnormal neuronal activity is detected. The analysis system further analyzes collected electrophysiological information during or following stimulus intervention to assess the effects of the stimulation intervention and to provide outputs to maintain or modify the stimulation intervention.", "Closed-loop micro-control system for predicting and preventing epilectic seizures "]
["The present invention involves methods and systems for treatment of brain disorders using neuromodulation that is provided to modulate structures of brain networks. Treatment occurs using electrical, optical, magnetic, and/or chemical stimulation of one or more brain networks associated with a brain disorder. The methods involve using a brain modulation system (BMS) to increase, decrease, or otherwise modulate characteristics of the regions of the network, such as relative levels of electrical activity or neurotransmitter levels. Treatment can be initiated and adjusted based upon evaluation of functional neuroimaging data for the network and brain network modeling. Linking rules may guide in adjusting the treatment protocol used to provide neuromodulation of multiple regions of a brain network. Novel methods are described for addressing issues of compensation, adaptation, and unintentional modulation due to indirect stimulation that can arise due to connectivity between structures within brain networks.", "Systems and Methods for Treating Disorders of the Central Nervous System by Modulation of Brain Networks "]
["A closed loop brain-machine interface is disclosed. The closed loop brain-machine interface translates one or more neural signals into a movement, or a series of movements, performed by a machine. The close-loop brain-machine interface also provides sensory feedback to the subject. Methods of employing the closed loop brain-machine interface are also disclosed.", "Closed loop brain machine interface "]
["An optical proximity corrected mask design is generated from a given a target mask design by processing the target mask design through a feature trained neural network, configured to perform an optical proximity correction of geometric features, to obtain a representation of a first corrected mask design. The target mask design is processed in parallel through a rule processor, configured to perform placement of sub-resolution geometric features relative to geometric features in the target mask design, to obtain a representation of a second corrected mask design. A layout reassembler operates to generate a corrected mask design through an overlaid composition of said first and second corrected mask designs.", "Neural network-based system and methods for performing optical proximity correction "]
["The present disclosure suggests methods of selecting a stimulation site for stimulating a patient's brain or methods of effectuating a neural-function of a patient associated with an impaired body function. In one exemplary implementation, such a neural function may be effectuated by selecting a stimulation site, positioning at least a first electrode at the stimulation site, and applying an electrical potential to pass a current through the first electrode. If one aspect, this stimulation site may be selected by a) identifying a second body function that is a corollary to the impaired body function, and b) determining a corollary location of the patient's brain that is associated with the second body function and is ipsilateral to the impaired body function.", "Methods and apparatus for effectuating a lasting change in a neural-function of a patient "]
["An adaptive, or neural, network and a method of operating the same is disclosed which is particularly adapted for performing first break analysis for seismic shot records. The adaptive network is first trained according to the generalized delta rule. The disclosed training method includes selection of the seismic trace with the highest error, where the backpropagation is performed according to the error of this worst trace. The learning and momentum factors in the generalized delta rule are adjusted according to the value of the worst error, so that the learning and momentum factors increase as the error decreases. The training method further includes detection of slow convergence regions, and methods for escaping such regions including restoration of previously trimmed dormant links, renormalization of the weighting factor values, and the addition of new layers to the network. The network, after the addition of a new layer, includes links between nodes which skip the hidden layer. The error value used in the backpropagation is reduced from that actually calculated, by adjusting the desired output value, in order to reduce the growth of the weighting factors. After the training of the network, data corresponding to an average of the graphical display of a portion of the shot record, including multiple traces over a period of time, is provided to the network. The time of interest of the data is incremented until such time as the network indicates that the time of interest equals the first break time. The analysis may be repeated for all of the traces in the shot record.", "Adaptive network for automated first break picking of seismic refraction events and method of operating the same "]
["The present invention provides an Internet search engine system and method that improves searching for documents or pages by processing the characteristics of a pool of data through a neural network governed by a set of rules and fuzzy logic applications. The rules and applications may be implemented at the input (or low) level or the computational/output (or high) level. Search terms and personal and situational data may activate various rule sets, and learning from human and machine feedback adjust and recombine the rule sets to improve accuracy for future searches as well as reduce computation time.", "Search engine with neural network weighting based on parametric user data "]
["Systems and methods for varying electromagnetic and adjunctive neural therapies are disclosed. A method in accordance with one embodiment includes applying electromagnetic signals to a target neural population of a patient over a first period of time in accordance with a first mode (e.g., including signal delivery to the central nervous system or peripheral nervous system, via implanted or non-implanted devices). The method can further include applying electromagnetic stimulation to the patient over a second period of time in accordance with a second mode different than the first mode. Varying the mode between the first period of time and second period of time can increase the efficacy and/or longevity of the stimulation. Systems in accordance with other embodiments can support multiple signal delivery devices.", "Systems and methods for varying electromagnetic and adjunctive neural therapies "]
["The following disclosure describes several methods and apparatus for intracranial electrical stimulation to treat or otherwise effectuate a change in neural-functions of a patient. Certain embodiments of methods in accordance with the invention electrically stimulate the brain at a stimulation site where neuroplasticity is occurring or is expected to occur. The stimulation site may be different than the region in the brain where neural activity is typically present to perform the particular neural function according to the functional organization of the brain. In one embodiment in which neuroplasticity related to the neural-function occurs in the brain, the method can include identifying the location where such neuroplasticity is present or expected to occur. In an alternative embodiment in which neuroplasticity is not occurring in the brain, an alternative aspect is to induce neuroplasticity at a stimulation site where it is expected to occur. Several embodiments of these methods that are expected to produce a lasting effect on the intended neural activity at the stimulation site use electrical pulses that increase the resting membrane potential of neurons at the stimulation site to a subthreshold level.", "Methods and apparatus for effectuating a lasting change in a neural-function of a patient "]
["Disclosed is a method for improving cognitive function or for improving coordination of function across a patient's cortical regions. The method includes applying electrical stimulation to at least a portion of the patient's subcortical structures involved in the generation and control of generalized efference copy signals. Internally generated movement of the patient is then detected and, in response to such internally generated movement, application of electrical stimulation is controlled. The method of the present invention has a number of benefits, including increasing flexibility in identifying targets for stimulation, improving the probability of successfully treating brain injury, and permitting patient biofeedback and self-regulation.", "Feedback mechanism for deep brain stimulation "]
["A method of allocating, restricting or refusing communication resources to media sessions in accordance with individual session or session type, comprises: categorizing passing packets using packet traffic characteristics such as packet length or inter-arrival period; grouping together those packets having similar traffic characteristics, and analyzing the grouped packets for session characteristics, thereby to identify a session type and allocate resources to the session or provisioning or like actions or services.", "Media session identification method for ip networks "]
["The following disclosure describes several methods and apparatus for intracranial electrical stimulation to treat or otherwise effectuate a change in neural-functions of a patient. Several embodiments of methods in accordance with the invention are directed toward enhancing or otherwise inducing a lasting change in neural activity to effectuate a particular neural-function. Such lasting change in neural activity is defined as \u201cneuroplasticity.\u201d The methods in accordance with the invention can be used to treat brain damage (e.g., stroke, trauma, etc.), brain disease (e.g., Alzheimer's, Pick's, Parkinson's, etc.), and/or brain disorders (e.g., epilepsy, depression, etc.). The methods in accordance with the invention can also be used to enhance neural-function of normal, healthy brains (e.g., learning, memory, etc.), or to control sensory functions (e.g., pain). Certain embodiments of methods in accordance with the invention electrically stimulate the brain at a stimulation site where neuroplasticity is occurring. The stimulation site may be different than the region in the brain where neural activity is typically present to perform the particular neural function according to the functional organization of the brain. In one embodiment in which neuroplasticity related to the neural-function occurs in the brain, the method can include identifying the location where such neuroplasticity is present. In an alternative embodiment in which neuroplasticity is not occurring in the brain, an alternative aspect is to induce neuroplasticity at a stimulation site where it is expected to occur. Several embodiments of these methods that are expected to produce a lasting effect on the intended neural activity at the stimulation site use electrical pulses that increase the resting membrane potential of neurons at the stimulation site to a subthreshold level.", "Methods and apparatus for effectuating a lasting change in a neural-function of a patient "]
["A mezzanine adapter based data processing facility provides in-depth data analysis that is presented as a digest of advanced statistics and network measures including latency data, content analysis, bidirectional flow related characteristics, multiple flow related statistics over a count of connections or over a period of time, and the like.", "Mezzazine in-depth data analysis facility "]
["Methods and apparatus for treating an impaired neural function in a brain of a patient. In one embodiment, a method for treating a neural function in a brain of a patient includes determining a therapy period during which a plurality of therapy sessions are to be performed to recover functional ability corresponding to the neural function. The method continues by identifying a stimulation site in or on the brain of the patient associated with the neural function, and positioning an electrode at least proximate to the identified stimulation site. The patient is then treated by providing electrical stimulation treatments to the stimulation site. The treatment can comprise delivering electrical stimulation signals to the electrode during the therapy sessions. After expiration of the therapy period, the method includes preventing electrical stimulation signals from being delivered to the stimulation site.", "Methods and apparatus for effectuating a lasting change in a neural-function of a patient "]
["The following disclosure describes several methods and apparatus for intracranial electrical stimulation to treat or otherwise effectuate a change in neural-functions of a patient. Several embodiments of methods in accordance with the invention are directed toward enhancing or otherwise inducing a lasting change in neural activity to effectuate a particular neural-function. Such lasting change in neural activity is defined as \u201cneuroplasticity.\u201d The methods in accordance with the invention can be used to treat brain damage (e.g., stroke, trauma, etc.), brain disease (e.g., Alzheimer's, Pick's, Parkinson's, etc.), and/or brain disorders (e.g., epilepsy, depression, etc.). The methods in accordance with the invention can also be used to enhance neural-function of normal, healthy brains (e.g., learning, memory, etc.), or to control sensory functions (e.g., pain). Certain embodiments of methods in accordance with the invention electrically stimulate the brain at a stimulation site where neuroplasticity is occurring. The stimulation site may be different than the region in the brain where neural activity is typically present to perform the particular neural function according to the functional organization of the brain. In one embodiment in which neuroplasticity related to the neural-function occurs in the brain, the method can include identifying the location where such neuroplasticity is present. In an alternative embodiment in which neuroplasticity is not occurring in the brain, an alternative aspect is to induce neuroplasticity at a stimulation site where it is expected to occur. Several embodiments of these methods that are expected to produce a lasting effect on the intended neural activity at the stimulation site use electrical pulses that increase the resting membrane potential of neurons at the stimulation site to a subthreshold level.", "Methods and apparatus for effectuating a lasting change in a neural-function of a patient "]
["The following disclosure describes several methods and apparatus for intracranial electrical stimulation to treat or otherwise effectuate a change in neural-functions of a patient. Certain embodiments of methods in accordance with the invention electrically stimulate the brain at a stimulation site where neuroplasticity is occurring or is expected to occur. The stimulation site may be different than the region in the brain where neural activity is typically present to perform the particular neural function according to the functional organization of the brain. In one embodiment in which neuroplasticity related to the neural-function occurs in the brain, the method can include identifying the location where such neuroplasticity is present or expected to occur. In an alternative embodiment in which neuroplasticity is not occurring in the brain, an alternative aspect is to induce neuroplasticity at a stimulation site where it is expected to occur. Several embodiments of these methods that are expected to produce a lasting effect on the intended neural activity at the stimulation site use electrical pulses that increase the resting membrane potential of neurons at the stimulation site to a subthreshold level.", "Methods and apparatus for effectuating a lasting change in a neural-function of a patient "]
["A method and an apparatus for predicting and detecting epileptic seizure onsets within a unified multiresolution probabilistic framework, enabling a portion of the device to automatically deliver a progression of multiple therapies, ranging from benign to aggressive as the probabilities of seizure warrant. Based on novel computational intelligence algorithms, a realistic posterior probability function P(ST|x) representing the probability of one or more seizures starting within the next T minutes, given observations x derived from IEEG or other signals, is periodically synthesized for a plurality of prediction time horizons. When coupled with optimally determined thresholds for alarm or therapy activation, probabilities defined in this manner provide anticipatory time-localization of events in a synergistic logarithmic-like array of time resolutions, thus effectively circumventing the performance vs. prediction-horizon tradeoff of single-resolution systems. The longer and shorter prediction time scales are made to correspond to benign and aggressive therapies respectively. The imminence of seizure events serves to modulate the dosage and other parameters of treatment during open-loop or feedback control of seizures once activation is triggered. Fast seizure onset detection is unified within the framework as a degenerate form of prediction at the shortest, or even negative, time horizon. The device is required to learn in order to find the probabilistic prediction and control strategies that will increase the patient's quality of life over time. A quality-of-life index (QOLI) is used as an overall guide in the optimization of patient-specific signal features, the multitherapy activation decision logic, and to document if patients are actually improving.", "Unified probabilistic framework for predicting and detecting seizure onsets in the brain and multitherapeutic device "]
["Light weight personal handheld home monitoring and managing device, which includes a Sound Sensor network/array of Sound Sensor networks combined with an Artificial Neural Network (ANN) and a build in system and methods, making this device an intelligent and portable apparatus to address specific health issues. The combined apparatus is used for managing and/or guidance and/or diagnosing and/or controlling and managing purposes. This present version of the apparatus will address pulmonary disorders and diseases or similar ailments.", "Handheld Home Monitoring Sensors Network Device "]
[null, "Method and system for network flow anomaly detection "]
["An intelligent query system for processing voiced-based queries is disclosed, which uses a combination of both statistical and semantic based processing to identify the question posed by the user by understanding the meaning of the user's utterance. Based on identifying the meaning of the utterance, the system selects a single answer that best matches the user's query. The answer that is paired to this single question is then retrieved and presented to the user. The system, as implemented, accepts environmental variables selected by the user and is scalable to provide answers to a variety and quantity of user-initiated queries.", "Speech based learning/training system using semantic decoding "]
["A patient state is detected with at least one classification boundary generated by a supervised machine learning technique, such as a support vector machine. In some examples, the patient state detection is used to at least one of control the delivery of therapy to a patient, to generate a patient notification, to initiate data recording, or to evaluate a patient condition. In addition, an evaluation metric can be determined based on a feature vector, which is determined based on characteristics of a patient parameter signal, and the classification boundary. Example evaluation metrics can be based on a distance between at least one feature vector and the classification boundary and/or a trajectory of a plurality of feature vectors relative to the classification boundary over time.", "Patient state detection based on supervised machine learning based algorithm "]
["Methods and apparatus for effectuating a lasting change in a neural function of a patient, including via mechanical force on neural tissue, are disclosed. An apparatus in accordance with one embodiment includes an implantable force delivery device that is changeable between a first state in which the force delivery device applies a first mechanical force to neural tissue, and the second state in which the force delivery device applies no mechanical force or a second mechanical force less than the first mechanical force to the neural tissue, while the force delivery device is implanted. An actuator can be coupled to the force delivery device with a communication link to change the state of the force delivery device, and a controller can be operably coupled to the actuator to automatically direct the force delivery device to change repeatedly between the first and second states while the force delivery device is implanted.", "Methods and Apparatus for Effectuating a Lasting Change in a Neural Function of a Patient, Including Via Mechanical Force on Neural Tissue "]
["Systems and methods are disclosed for powering a processor and a wireless transceiver in a sole having a sole plate and one or more spring elements disposed in a forefoot area of the sole plate, each of said spring elements including a piezoelectric generator coupled thereto, wherein each of the plurality of spring elements has one free end not directly connected to the sole plate.", "Personally powered appliance "]
["Apparatus, systems, and methods may operate to collect neuro data from an organ, such as a brain. Spikes may be detected using raw neuro data collected from the organ. The spikes may be sorted. Underlying neuronal firing rates may be estimated using the sorted spikes. The neuronal firing rates may be transmitted outside the organ for real time decoding.", "Multiscale intra-cortical neural interface system "]
["An autonomous pavement assessment system may receive depth data indicative of the depth of pixels that collectively comprise multiple defective areas of pavement. For each defective area, the system may fit a plane to it; generate a histogram that indicates the frequency of its pixels at different depths; dynamically determine a depth noise threshold for it; generate a binary image of it based on its noise threshold; and generate a depth map of it containing only the pixels that have a depth that meets or exceeds its depth noise threshold. The system may prioritize the multiple defective areas for repair and/or generate optimized rehabilitation routes. Crowd sourcing may be used to gather the depth data, as well as location information for each defective area.", "Autonomous pavement condition assessment "]
["A health care monitoring system for a person includes one or more wireless nodes forming a wireless mesh network; a wearable appliance having a sound transducer coupled to the wireless transceiver; and a bioelectric impedance (BI) sensor coupled to the wireless mesh network to communicate BI data over the wireless mesh network to detect a heart attack or a stroke attack.", "Mesh network monitoring appliance "]
["A method of transforming geologic data relating to a subsurface region between a geophysical depth domain and a geologic age domain is disclosed. A set of topologically consistent surfaces is obtained that correspond to seismic data. The surfaces are enumerated in the depth domain. An age is assigned to each surface in the depth domain. The age corresponds to an estimated time of deposition of the respective surface. An age mapping volume is generated. An extent of the age domain is chosen. A depth mapping volume is generated. Both the age mapping volume and the depth mapping volume are used to transform geophysical, geologic, or engineering data or interpretations between the depth domain and the age domain and vice versa. The geophysical, geologic, or engineering data or interpretations transformed by at least one of the age mapping volume and the depth mapping volume are outputted.", "Method For Geophysical and Geological Interpretation of Seismic Volumes In The Domains of Depth, Time, and Age "]
["Method for transforming geologic data relating to a subsurface region between a geophysical depth domain and a geologic age domain. A set of topologically consistent surfaces (252 a) is obtained that correspond to seismic data (252). The surfaces are enumerated in the depth domain. An age is assigned to each surface in the depth domain (255). The age corresponds to an estimated time of deposition of the respective surface. An age mapping volume is generated (256). An extent of the age domain is chosen. A depth mapping volume is generated (260). Both the age mapping volume and the depth mapping volume are used to transform geophysical, geologic, or engineering data or interpretations (258, 263) between the depth domain and the age domain (268) and vice versa (269). The geophysical, geologic, or engineering data or interpretations transformed by at least one of the age or depth mapping volume are outputted.", "Method For Geophysical and Geological Interpretation of Seismic Volumes In The Domains of Depth, Time, and Age "]
["The present invention provides compositions and methods for light-activated cation channel proteins and their uses within cell membranes and subcellular regions. The invention provides for proteins, nucleic acids, vectors and methods for genetically targeted expression of light-activated cation channels to specific cells or defined cell populations. In particular the invention provides millisecond-timescale temporal control of cation channels using moderate light intensities in cells, cell lines, transgenic animals, and humans. The invention provides for optically generating electrical spikes in nerve cells and other excitable cells useful for driving neuronal networks, drug screening, and therapy.", "Light-activated cation channel and uses thereof "]
["A health care monitoring system for a person includes one or more wireless nodes forming a wireless mesh network; a wearable appliance having a sound transducer coupled to the wireless transceiver; and a heart attack or stroke attack sensor coupled to the wireless mesh network to communicate patient data over the wireless mesh network to detect a heart attack or a stroke attack.", "Mesh network stroke monitoring appliance "]
["A monitoring system includes one or more wireless nodes forming a wireless mesh network; a user activity sensor including a wireless mesh transceiver adapted to communicate with the one or more wireless nodes using the wireless mesh network; and a digital monitoring agent coupled to the wireless transceiver through the wireless mesh network to request assistance from a third party based on the user activity sensor.", "Mesh network personal emergency response appliance "]
["A machine-implemented social networking system builds up and repeatedly refreshes a hierarchy tree containing topic nodes. New nodes are added as new topics emerge in online public forums. Each topic node can link to an on-topic real time chat room whose occupants are currently discussing the topic of the node. A chat room can be pointed to by more than one node if the room is discussing multiple topics. Rooms can migrate from node to node as room topic dynamically changes. A system user who explicitly or inferentially wishes to be invited into a chat room which is on-topic with what the user is currently focused upon can do so by use of a node-seeking automated process. The process operates in the background and seeks out nodes of the hierarchy tree that currently have topics appearing to be the same as or similar to what topics the user appears to have in mind. Content browsing experience of the user is enhanced by addition of an invitations displaying subsystem that automatically invites him or her to co-compatible chat rooms currently discussing the topic(s) the user appears to have in mind. One of the many topics that a user may inferentially have in mind is that of being at a given location as reported by the user's GPS and wondering what best to do at that location and time.", "social network driven indexing system for instantly clustering people with concurrent focus on same topic into on-topic chat rooms and/or for generating on-topic search results tailored to user preferences regarding topic "]
