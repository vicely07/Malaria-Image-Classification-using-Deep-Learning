{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Using Trained Model\n",
    "\n",
    "The purpose of this noteobook is to use the trained word level model in order to make predictions. We can look at using both the model trained with pre-trained embeddings and the model with embeddings that were trained from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import HTML\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "RANDOM_STATE = 50\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_model, find_closest, get_sequences, create_train_valid,  generate_output, guess_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trained with Own Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         1619200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16192)             2088768   \n",
      "=================================================================\n",
      "Total params: 3,758,528\n",
      "Trainable params: 3,758,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, embeddings, word_idx, idx_word = get_model('train-embeddings-rnn')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: the\n",
      "\n",
      "Word: the             Cosine Similarity: 1.0\n",
      "Word: a               Cosine Similarity: 0.8156999945640564\n",
      "Word: The             Cosine Similarity: 0.7764999866485596\n",
      "Word: this            Cosine Similarity: 0.7674000263214111\n",
      "Word: its             Cosine Similarity: 0.7583000063896179\n",
      "Word: third           Cosine Similarity: 0.7434999942779541\n",
      "Word: any             Cosine Similarity: 0.7361999750137329\n",
      "Word: their           Cosine Similarity: 0.7300999760627747\n",
      "Word: second          Cosine Similarity: 0.7290999889373779\n",
      "Word: entire          Cosine Similarity: 0.7247999906539917\n"
     ]
    }
   ],
   "source": [
    "find_closest('the', embeddings, word_idx, idx_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: a\n",
      "\n",
      "Word: a               Cosine Similarity: 1.0\n",
      "Word: the             Cosine Similarity: 0.8156999945640564\n",
      "Word: A               Cosine Similarity: 0.7390999794006348\n",
      "Word: any             Cosine Similarity: 0.7271000146865845\n",
      "Word: this            Cosine Similarity: 0.7246000170707703\n",
      "Word: no              Cosine Similarity: 0.6948000192642212\n",
      "Word: another         Cosine Similarity: 0.6919999718666077\n",
      "Word: promising       Cosine Similarity: 0.6887999773025513\n",
      "Word: its             Cosine Similarity: 0.6744999885559082\n",
      "Word: unprecedented   Cosine Similarity: 0.6743000149726868\n"
     ]
    }
   ],
   "source": [
    "find_closest('a', embeddings, word_idx, idx_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: .\n",
      "\n",
      "Word: .               Cosine Similarity: 1.0\n",
      "Word: .‚Äù              Cosine Similarity: 0.755299985408783\n",
      "Word: while           Cosine Similarity: 0.7282000184059143\n",
      "Word: .&#8221         Cosine Similarity: 0.7235000133514404\n",
      "Word: ##EQU2##        Cosine Similarity: 0.7148000001907349\n",
      "Word: 10.             Cosine Similarity: 0.7027000188827515\n",
      "Word: 74.             Cosine Similarity: 0.6988000273704529\n",
      "Word: 7.              Cosine Similarity: 0.6833000183105469\n",
      "Word: 18.             Cosine Similarity: 0.6807000041007996\n",
      "Word: ?               Cosine Similarity: 0.675599992275238\n"
     ]
    }
   ],
   "source": [
    "find_closest('.', embeddings, word_idx, idx_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: neural\n",
      "\n",
      "Word: neural          Cosine Similarity: 1.0\n",
      "Word: neuronal        Cosine Similarity: 0.6409000158309937\n",
      "Word: Said            Cosine Similarity: 0.6399999856948853\n",
      "Word: 3G              Cosine Similarity: 0.6276000142097473\n",
      "Word: TCP/IP          Cosine Similarity: 0.6082000136375427\n",
      "Word: Source          Cosine Similarity: 0.6029000282287598\n",
      "Word: brain           Cosine Similarity: 0.566100001335144\n",
      "Word: ARTMAP          Cosine Similarity: 0.5600000023841858\n",
      "Word: search/sort     Cosine Similarity: 0.5591999888420105\n",
      "Word: LTM             Cosine Similarity: 0.5540000200271606\n"
     ]
    }
   ],
   "source": [
    "find_closest('neural', embeddings, word_idx, idx_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK has no pre-trained embedding.\n"
     ]
    }
   ],
   "source": [
    "find_closest('UNK', embeddings, word_idx, idx_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16192 unique words.\n",
      "There are 318563 training sequences.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/neural_network_patent_query.csv')\n",
    "abstracts = list(data['patent_abstract'])\n",
    "features, labels, sequences = get_sequences(abstracts, model_name = 'training-rnn')\n",
    "X_train, X_test, y_train, y_test = create_train_valid(features, labels, num_words = len(word_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95569, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95569, 16192)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics: log loss and accuracy\n",
      "95569/95569 [==============================] - 10s 108us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.737925765920241, 0.2671891513580688]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model metrics: log loss and accuracy')\n",
    "model.evaluate(X_test, y_test, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">the input data and one or more conditions. One method of analyzing such data is by the use of neural networks which are non-linear statistical data modelling tools, the structure of which may be changed based on information that is passed through the network during a training phase</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > that identifies the texture signal from the ensemble in a deep neural network, including a presence of objects, general effects of query signals. A corresponding user having an increased component is repeatedly classified to be not adapted to said well-trained CNN. Each user is configured to</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- >. A known problem that affects neural networks is the issue of overtraining which arises in overcomplex or overspecified systems when the capacity of the network significantly exceeds the needed parameters. The present invention provides a method of analyzing data using a neural network with a constrained architecture that</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_html, gen_html, a_html = generate_output(model, sequences, idx_word)\n",
    "HTML(seed_html)\n",
    "HTML(gen_html)\n",
    "HTML(a_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">for recognizing input gestures. A neural network is trained using example inputs and backpropagation to recognize specified input patterns. Input gesture data is representative of movements in contact on a multi-touch input display surface relative to one or more axes over time. Example inputs used for training</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > and image profiles are small from both around time needed patterns, avoiding use, or other networks. The neural network sets comprises comparator-net and a trained feed-forward model of a nonadaptive learning process to causes data. The adaptation controller is then organized to automatically adjust those basic</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > the neural network to recognize a specified input pattern can be created from sampling input gesture data for example input gestures known to represent the specified input pattern. Trained neural networks can subsequently be used to recognize input gestures that are similar to known input gestures as the specified</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_html, gen_html, a_html = generate_output(model, sequences, idx_word)\n",
    "HTML(seed_html)\n",
    "HTML(gen_html)\n",
    "HTML(a_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output from Human or Machine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_human(model, sequences, training_length=50, new_words=50):\n",
    "    \"\"\"Produce 2 RNN sequences and play game to compare to actaul.\n",
    "       Diversity is randomly set between 0.5 and 1.25\"\"\"\n",
    "    \n",
    "    diversity = np.random.uniform(0.5, 1.25)\n",
    "    sequence, gen_list, actual = generate_output(model, sequences, training_length, \n",
    "                                                 diversity=diversity, return_output=True, n_gen = 2)\n",
    "    gen_0, gen_1 = gen_list\n",
    "    \n",
    "    output = {'sequence': remove_spaces(' '.join(sequence)),\n",
    "              'c0': remove_spaces(' '.join(gen_0)),\n",
    "              'c1': remove_spaces(' '.join(gen_1)),\n",
    "              'h': remove_spaces(' '.join(actual))}\n",
    "    \n",
    "    print(f\"Seed Sequence: {output['sequence']}\\n\")\n",
    "    \n",
    "    choices = ['h', 'c0', 'c1']\n",
    "          \n",
    "    selected = []\n",
    "    i = 0\n",
    "    while len(selected) < 3:\n",
    "        choice = random.choice(choices)\n",
    "        selected.append(choice)\n",
    "        print('\\n')\n",
    "        print(f'Option {i + 1} {output[choice]}')\n",
    "        choices.remove(selected[-1])\n",
    "        i += 1\n",
    "    \n",
    "    print('\\n')\n",
    "    guess = int(input('Enter option you think is human (1-3): ')) - 1\n",
    "    print('\\n')\n",
    "    \n",
    "    if guess == np.where(np.array(selected) == 'h')[0][0]:\n",
    "        print('Correct')\n",
    "        print('Correct Ordering', selected)\n",
    "    else:\n",
    "        print('Incorrect')\n",
    "        print('Correct Ordering', selected)\n",
    "          \n",
    "    print('Diversity', round(diversity, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_spaces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c1856926f6a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguess_human\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-f767fd007f17>\u001b[0m in \u001b[0;36mguess_human\u001b[0;34m(model, sequences, training_length, new_words)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgen_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     output = {'sequence': remove_spaces(' '.join(sequence)),\n\u001b[0m\u001b[1;32m     11\u001b[0m               \u001b[0;34m'c0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremove_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0;34m'c1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremove_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_spaces' is not defined"
     ]
    }
   ],
   "source": [
    "guess_human(model, sequences, idx_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_human(model, sequences, idx_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Injecting Diversity into Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversify(arr, diversity, plot = False):\n",
    "    div = np.log(arr) / diversity\n",
    "    exp_preds = np.exp(div)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    if plot:\n",
    "        plt.figure(figsize = (10, 8));\n",
    "        plt.subplot(2, 1, 1);\n",
    "        sns.distplot(arr); plt.title('Original Distribution');\n",
    "        plt.subplot(2, 1, 2);\n",
    "        sns.distplot(preds); plt.title(f'Distribution with {diversity} diversity')\n",
    "    probas = np.random.multinomial(1, preds, 1);\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = diversify([0.1, 0.2, 0.4, 0.8, 0.9, 0.1, 0.3, 0.4], 0.5, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = diversify([0.1, 0.2, 0.4, 0.8, 0.9, 0.1, 0.3, 0.4], 2, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = diversify([0.1, 0.2, 0.4, 0.8, 0.9, 0.1, 0.3, 0.4], 10, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
